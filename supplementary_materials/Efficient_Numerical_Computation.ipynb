{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Numerical Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the critical skills for being a data scientist is understanding computation and algorithms.  Below is a (cursory) guide meant to whet your appetite for the computational techniques that I found useful as a data scientist.  Remember, there’s a lifetime of things to learn and these are just some highlights:\n",
    "\n",
    "**Vectorized Linear Algebra:**  Let’s say you want to dot product (http://en.wikipedia.org/wiki/Dot_product) two very large vectors.  You could use a for loop, but that’s slow.  Instead, consider using vectorized linear algebra that calls out to professional numerical libraries like BLAS (http://www.netlib.org/blas/) or LAPACK (http://www.netlib.org/lapack/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('z1: ', 349.11451587016472)\n",
      "('z2: ', 349.11451587016381)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.randn(1000000)\n",
    "y = np.random.randn(1000000)\n",
    "\n",
    "z1 = sum(x[i] * y[i] for i in xrange(len(x)))  # elapsed time: 1.2176 seconds\n",
    "z2 = np.dot(x, y)  # elapsed time: 0.0045 seconds\n",
    "print(\"z1: \", z1)\n",
    "print(\"z2: \", z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run both samples and see which one takes longer (try using python’s **timeit** module (https://docs.python.org/2/library/timeit.html) if you are not already familiar with it). In our example, for loops are 600 times slower.  You can learn more about numerical computation from the numpy and scipy websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 533 ms, sys: 99.1 ms, total: 632 ms\n",
      "Wall time: 557 ms\n",
      "CPU times: user 967 µs, sys: 23 µs, total: 990 µs\n",
      "Wall time: 886 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "349.11451587016381"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "from timeit import time\n",
    "%time(sum(x[i] * y[i] for i in xrange(len(x))))\n",
    "%time(np.dot(x, y))  # elapsed time is a little smaller for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulation.** The simplest workhorse when trying to get a handle on a complex system is simulation.  For example, consider the problem:You flip a fair coin n times.  What is the expected number of heads?  What is the standard deviation of the number of heads?\n",
    "\n",
    "Obviously, this is just a **Bernoulli Distribution** (http://en.wikipedia.org/wiki/Bernoulli_distribution) and does not require simulation but we will use it to didactically illustrate what one might do in more complex situations.  The simulation code might be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4987\n",
      "0.499998309997\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "samples = np.random.randint(0,2,10000)\n",
    "print samples.mean() # 0.4987\n",
    "print samples.std() # 0.499998309997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how much faster vectorized linear algebra is compared with running python for loops.  Obviously, the field can get very complex, with Dynamical Systems (http://en.wikipedia.org/wiki/Dynamical_system), Monte Carlo (http://en.wikipedia.org/wiki/Monte_Carlo_method), Gibbs Sampling (http://en.wikipedia.org/wiki/Gibbs_sampling), Importance Sampling (http://en.wikipedia.org/wiki/Importance_sampling), and MCMC (http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo). Don’t forget to use bootstrapping (http://en.wikipedia.org/wiki/Bootstrapping_%28statistics%29) to estimate error bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursion.**  Of course, simulations can never give you an exact answer.  One technique to get an exact answer that works in many cases is recursion.  The simplest example of recursion (http://en.wikipedia.org/wiki/Recursion_%28computer_science%29) comes from implementing the Fibonacci sequence (http://en.wikipedia.org/wiki/Fibonacci_number):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 3 µs, total: 12 µs\n",
      "Wall time: 14.8 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fib(n):\n",
    "  if n < 2:\n",
    "    return 1\n",
    "  else:\n",
    "    return fib(n-1) + fib(n-2)\n",
    "%time(fib(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try timing the runs to guess the running time (http://en.wikipedia.org/wiki/Time_complexity) of the Fibonacci sequence (spoiler alert: it’s exponential).  You may be surprised by how slow it is (can you guess why?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.21 ms, sys: 3.96 ms, total: 10.2 ms\n",
      "Wall time: 7.05 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6765"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time(fib(19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how we might use this to solve the last problem, notice that on the n-th draw, we can either increase or decrease the average number of heads by 1/n from the n-th draw, and that each occurs with probability 1/2. Here is the recursive code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.2 ms, sys: 10.2 ms, total: 58.4 ms\n",
      "Wall time: 51.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average_heads(n):\n",
    "  if n == 1:\n",
    "    return 0.5\n",
    "  else:\n",
    "    return np.mean([average_heads(n-1) + 1./n, average_heads(n-1) - 1./n])\n",
    "%time(average_heads(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Think a little about how you might compute the standard deviation using this technique (hint: it may help to review alternative formulas for variance, https://en.wikipedia.org/wiki/Variance#Definition).  Another popular use of recursion is in graph traversal algorithms (https://en.wikipedia.org/wiki/Graph_traversal).  Consider the question:\n",
    "\n",
    "How many possible ways are there to draw US coins that sum up to 50 cents?\n",
    "\n",
    "For the sake of definiteness, we will say that order of the drawn coins matters.  You can solve this problem by traversing the “graph” of all possible draws until we reach exactly 50 cents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.6 s, sys: 911 ms, total: 17.5 s\n",
      "Wall time: 16.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1931846"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coins = [1, 5, 10, 25, 50]\n",
    "def count(remainder):\n",
    "  if remainder < 0:\n",
    "    return 0\n",
    "  if remainder == 0:\n",
    "    return 1\n",
    "  return sum(count(remainder - coin) for coin in coins)\n",
    "count(50)\n",
    "%time(count(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just the tip of the iceberg of what you can do with recursion.  If you are interested, try looking up algorithms like Depth-First Search (https://en.wikipedia.org/wiki/Depth-first_search), Breadth-First Search (http://en.wikipedia.org/wiki/Breadth-first_search), or tail recursion (http://en.wikipedia.org/wiki/Tail_call#Tail_recursion_modulo_cons).\n",
    "\n",
    "**Memoization and Dynamic Programming.**  Notice that in both the above examples, we make multiple calls to the recursive function for the same input, which seems inefficient.  A common way to speed this up is to remember (or memoize) the results of previous computations.  As a simple example, take a look at the python memoized class (https://wiki.python.org/moin/PythonDecoratorLibrary#Memoize) which uses python decorator syntax (https://www.python.org/dev/peps/pep-0318/). Here it is in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 152 µs, sys: 95 µs, total: 247 µs\n",
      "Wall time: 218 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6765"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import functools\n",
    "\n",
    "class memoized(object):\n",
    "    '''Decorator. Caches a function's return value each time it is called.\n",
    "    If called later with the same arguments, the cached value is returned\n",
    "    (not reevaluated).\n",
    "    '''\n",
    "    def __init__(self, func):\n",
    "         self.func = func\n",
    "         self.cache = {}\n",
    "    def __call__(self, *args):\n",
    "         if not isinstance(args, collections.Hashable):\n",
    "            # uncacheable. a list, for instance.\n",
    "            # better to not cache than blow up.\n",
    "            return self.func(*args)\n",
    "         if args in self.cache:\n",
    "            return self.cache[args]\n",
    "         else:\n",
    "            value = self.func(*args)\n",
    "            self.cache[args] = value\n",
    "            return value\n",
    "    def __repr__(self):\n",
    "         '''Return the function's docstring.'''\n",
    "         return self.func.__doc__\n",
    "    def __get__(self, obj, objtype):\n",
    "         '''Support instance methods.'''\n",
    "         return functools.partial(self.__call__, obj)\n",
    "@memoized\n",
    "def fib(n):\n",
    "  if n < 2:\n",
    "    return 1\n",
    "  else:\n",
    "    return fib(n-1) + fib(n-2)\n",
    "%time(fib(19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has now effectively turned a recursive program into one using Dynamic Programming (http://en.wikipedia.org/wiki/Dynamic_programming).  Try using timing to guess the running time of the Fibonacci sequence (spoiler alert: it’s linear).  It’s amazing how much of a difference a single line makes!\n",
    "\n",
    "**Divide and Conquer.**  Another common approach is to break up a large problem into smaller subproblems.  A classic example of this is Merge Sort (http://en.wikipedia.org/wiki/Merge_sort).  For the Fibonacci sequence, consider using the Matrix Form (https://en.wikipedia.org/wiki/Fibonacci_number#Matrix_form) of the Fibonacci sequence:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.67 ms, sys: 2.28 ms, total: 3.95 ms\n",
      "Wall time: 274 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6765"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.matrix([[1, 1], [1, 0]])\n",
    "\n",
    "def fib(n):\n",
    "  if n < 2:\n",
    "    return 1\n",
    "  MProd = M.copy()\n",
    "  for _ in xrange(n-2):\n",
    "    MProd *= M\n",
    "  return MProd[0,0] + MProd[0,1]\n",
    "%time(fib(19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the code relies on repeated matrix multiplication, it is very amenable to Divide and Conquer (http://en.wikipedia.org/wiki/Divide_and_conquer_algorithms) techniques (hint: M^8=(((M^2)^2)^2)). We’ll let you write down the algorithm and time it to verify that it is a log algorithm.  (Isn’t it amazing that this can be done in sub-linear time!)\n",
    "\n",
    "**Coda:** This is it for this tutorial but if you know a little bit about matrix factorization (http://en.wikipedia.org/wiki/Matrix_decomposition#Eigendecomposition), try working out a (pseudo-)constant time answer.  Why isn’t this really constant time?  (Spoiler alert: read a little bit about Arbitrary Precision Arithmetic (http://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic#Implementation_issues).)  We’re not going to emphasize it because the technique isn’t really all that generalizable but it is still fun to think about.\n",
    "Of course, this is just a very high-level overview that is meant to pique your interest rather than give you a full exposition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
