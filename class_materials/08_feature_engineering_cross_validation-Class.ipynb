{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 8 Agenda:\n",
    "  * **Feature Engineering: Standard Scaling/MinMaxScaling**\n",
    "  * **Feature Engineering: Handling Categorical Features**\n",
    "  * **Feature Engineering: Handling Missing Values**\n",
    "  * **Feature Engineering: Creating Derived Features - Polynomial Features**\n",
    "  * **Cross Validation vs. Train/Test Split**\n",
    "  * **Cross Validation for Parameter Tuning**\n",
    "  * **Searching over Parameters using GridSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to make a big step today in the sophistication and kinds of models we will be capable of building. We will talk about several common feature transformations that you can/should perform when preparing most data for machine learning models.\n",
    "\n",
    "We're also going to learn how to improve the evaluation of the performance of any supervised machine learning models we build using a much better (more accurate) method than train-test split, one that gives more reliable estimates of error on unseen data.\n",
    "\n",
    "#### Outcomes\n",
    "By the end of this lesson you will be able to:\n",
    "- articulate why feature scaling is important, and be able to do it using sklearn\n",
    "- use a variety of transformation methods to reduce non-normality in features\n",
    "- handle categorical features when building a machine learning model\n",
    "- handle null/missing values when building a machine learning model\n",
    "- use cross validation to accurately estimate model performance\n",
    "- articulate the strengths and weaknesses of basic cross validation\n",
    "- use cross validation to choose optimal model parameters by searching across many models simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "When we talk about feature engineering, we are really talking about two things:\n",
    "* transforming the values at our disposal into a representation that a given machine learning algorithm can use and understand\n",
    "* creating new, derived features from the available features (using domain expertise) and use them when training a model\n",
    "* dealing with missing values, as most ML algorithms can't handle unknown values. They must be filled in.\n",
    "\n",
    "We will begin with the first case, transformation, and talk about the three most common transformations necessary to get data into a state where it can be used to train most ML models:\n",
    "* **feature scaling**: making it so that all columns (features) range over the same values is very helpful for many (but not all) machine learning models. In some cases, scaling along samples is useful, as well.\n",
    "* **turning categorical values into numerical values**: machine learning algorithms only understand numbers, not categories.\n",
    "* **handling missing values**: Models break when you give them `NaN`s, what are some strategies to replace `NaN`s with \"good\" (i.e. useful) numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the basics (those things we've seen in the past) like always, and generate some fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division  # Python 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data handling, model creation/evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split  -- note that this pops up elsewhere\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "#make it so that we only show first 4 decimals for floats\n",
    "np.set_printoptions(precision=4,suppress=True)\n",
    "\n",
    "# visualization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   length  mass  rings\n",
      "0    0.59  0.79   54.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>mass</th>\n",
       "      <th>rings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  mass  rings  target\n",
       "0     0.9   0.1     40       0\n",
       "1     0.3   0.2     50       1\n",
       "2     0.6   0.8     60       2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fake data -- we're creating fake data here\n",
    "train = pd.DataFrame({'target':[0,1,2], 'length':[0.9,0.3,0.6], 'mass':[0.1,0.2,0.8], 'rings':[40,50,60]})\n",
    "test = pd.DataFrame({'length':[0.59], 'mass':[0.79], 'rings':[54.9]})\n",
    "print(test)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "## Standardization:\n",
    "Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "For instance, many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) assume that all features are centered around zero and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\n",
    "\n",
    "\n",
    "### Scaling to a range: MinMax Scaler\n",
    "simplest method is to rescale the feature range to [0,1] or [-1, 1]  \n",
    "\\begin{equation}\n",
    "X^\\prime = \\frac{X - min(X)}{max(X) - min(X)}\n",
    "\\end{equation}\n",
    "\n",
    "### Scaling to zero mean, unit variance: Standard Scaler \n",
    "calculating the z-score rescale to zero mean and unit variance\n",
    "\\begin{equation}\n",
    "X^\\prime = \\frac{X - \\bar{X}}{\\sigma}\n",
    "\\end{equation}\n",
    "\n",
    "### Scaling to unit length: Normalization\n",
    "rescale to unit length: useful in vector space models\n",
    "\\begin{equation}\n",
    "X^\\prime = \\frac{X}{\\left|\\left| X \\right| \\right|}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Note: save the scaler object that was applied on the training set, to be later re-applied on the testing set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to predict the `id` of each sample using the `length`, `mass`, and `rings` columns without doing any feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   length  mass  rings\n",
      "0     0.9   0.1     40\n",
      "1     0.3   0.2     50\n",
      "2     0.6   0.8     60\n",
      "----------\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# define X and y\n",
    "feature_cols = ['length', 'mass', 'rings']\n",
    "X = train[feature_cols]\n",
    "y = train.target\n",
    "print(X)\n",
    "print('----------')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate this, we are going to be using a different classifier from the one's we've learned about so far. \n",
    "\n",
    "This algorithm is called [K-nearest-neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) and simply selects either the category (classification) or average of the K closest samples to it (computed using Euclidean distance).\n",
    "\n",
    "We are going to use K-nearest-neighbors where k=1 (the single nearest neighbor, so it will simply assume the output of that sample):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "    length  mass  rings  target\n",
      "0     0.9   0.1     40       0\n",
      "1     0.3   0.2     50       1\n",
      "2     0.6   0.8     60       2 \n",
      "\n",
      "Single test sample:\n",
      "    length  mass  rings\n",
      "0    0.59  0.79   54.9\n"
     ]
    }
   ],
   "source": [
    "# KNN with k=1\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "\n",
    "print(\"Training data:\\n\",train,\"\\n\")\n",
    "print(\"Single test sample:\\n\",test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**what id \"should\" the classifier predict?**\n",
    "\n",
    "Hopefully, you said id 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction: \",knn.predict(test))   # we're trying to get a prediction value; uses the distance using the 'rings'\n",
    "                                          # feature\n",
    "# i.e., it seems to be predicting\n",
    "#    length  mass  rings  target\n",
    "# 1     0.3   0.2     50       1\n",
    "\n",
    "# instead of (which we would expect)\n",
    "#    length  mass  rings  target\n",
    "# 2     0.6   0.8     60       2 \n",
    "\n",
    "# The classifier predicts id 1 instead of id 2 because the portion of the distance in the rings column dominates all \n",
    "# of the other distances (it varies over ~10 units, whereas both of the other features vary over ~1 unit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier predicts id `1` instead of id `2` because the portion of the distance in the `rings` column **dominates** all of the other distances (it varies over ~10 units, whereas both of the other features vary over ~1 unit).\n",
    "\n",
    "How to get around this?\n",
    "\n",
    "**You scale all of the features so that they all range over the same values.**\n",
    "\n",
    "There are lots of ways to do this, we will talk about/use **Standard Scaling**. \n",
    "\n",
    "We simply compute the mean and standard deviation of each column, and for every value, subtract the mean of that column from the value, and divide by the standard deviation:\n",
    "$$zscore(x_i)=\\frac {x_i-\\mu}{\\sigma}$$\n",
    "\n",
    "Let's do that using `sklearn`'s `StandardScaler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original values:\n",
      " [[  0.9   0.1  40. ]\n",
      " [  0.3   0.2  50. ]\n",
      " [  0.6   0.8  60. ]] \n",
      "\n",
      "scaled values:\n",
      " [[ 1.2247 -0.8627 -1.2247]\n",
      " [-1.2247 -0.5392  0.    ]\n",
      " [ 0.      1.4018  1.2247]] \n",
      "\n",
      "Mean of each column:\n",
      " [  0.6      0.3667  50.    ] \n",
      "\n",
      "standard deviation of each column:\n",
      " [ 0.2449  0.3091  8.165 ] \n",
      "\n",
      "Z-scoring the values by hand to make sure we arent crazy:\n",
      " [[ 1.2247 -0.8627 -1.2247]\n",
      " [-1.2247 -0.5392  0.    ]\n",
      " [ 0.      1.4018  1.2247]]\n",
      "Final Means of scaled data, per column:\n",
      " [ 0. -0.  0.]\n",
      "Final SD's of scaled data, per column:\n",
      " [ 1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler    # can also use minmax scalar\n",
    "\n",
    "scaler = StandardScaler() # create a scaler object\n",
    "scaler.fit(X) # fit the scaler    -- we fit our data : learn the standard deviation, etc., i.e., we learn the data...\n",
    "X_scaled = scaler.transform(X) #transform the data with it\n",
    "\n",
    "# compare original to standardized\n",
    "print(\"original values:\\n\",X.values,\"\\n\")\n",
    "print(\"scaled values:\\n\",X_scaled,\"\\n\")\n",
    "\n",
    "# figure out how the standardization worked\n",
    "print(\"Mean of each column:\\n\",scaler.mean_,\"\\n\")\n",
    "print(\"standard deviation of each column:\\n\",scaler.scale_,\"\\n\")\n",
    "print(\"Z-scoring the values by hand to make sure we arent crazy:\\n\",(X.values - scaler.mean_) / scaler.scale_)\n",
    "print(\"Final Means of scaled data, per column:\\n\",X_scaled.mean(axis=0))\n",
    "print(\"Final SD's of scaled data, per column:\\n\",X_scaled.std(axis=0))\n",
    "# We see that the ring no longer dominates the data space\n",
    "# Note: we've scaled the data to have 0 mean and unit variance (i.e., standard deviation = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also scale the data to an arbitrary range of values (instead of scaling them to have 0 mean and unit variance), we specify the minimum and maximum values that the column can take on, using `MinMaxScaler`. By default, `MinMaxScaler` scales the data to the range (0,1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original values:\n",
      " [[  0.9   0.1  40. ]\n",
      " [  0.3   0.2  50. ]\n",
      " [  0.6   0.8  60. ]] \n",
      "\n",
      "scaled values:\n",
      " [[ 1.      0.      0.    ]\n",
      " [ 0.      0.1429  0.5   ]\n",
      " [ 0.5     1.      1.    ]] \n",
      "\n",
      "min and max of scaled values:\n",
      " 0.0 \n",
      " 1.0\n",
      "Mean of min/max scaled columns:\n",
      " [ 0.5    0.381  0.5  ]\n",
      "Std of min/max scaled columns:\n",
      " [ 0.4082  0.4416  0.4082]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler   # same approach\n",
    "minmax= MinMaxScaler()    # instantiate the scalar\n",
    "\n",
    "minmax.fit(X) #fit the scaler\n",
    "X_scaled_minmax = minmax.transform(X) #transform the data with it\n",
    "# Make sure you scale your test data using the same scalar function\n",
    "# compare original to standardized\n",
    "print(\"original values:\\n\",X.values,\"\\n\")\n",
    "print(\"scaled values:\\n\",X_scaled_minmax,\"\\n\")\n",
    "\n",
    "print(\"min and max of scaled values:\\n\",X_scaled_minmax.min(),\"\\n\",X_scaled_minmax.max())\n",
    "print(\"Mean of min/max scaled columns:\\n\", X_scaled_minmax.mean(axis=0))\n",
    "print(\"Std of min/max scaled columns:\\n\", X_scaled_minmax.std(axis=0))\n",
    "# Everything in between gets value between 0 and 1\n",
    "# For a tree-based model you may not use scaling. You might (need to) use it for linear regression, however"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other scaling approaches may be more appropriate in different circumstances, you can read about them here: [preprocessing and scaling data in scikit-learn](http://scikit-learn.org/stable/modules/preprocessing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that is very important to keep in mind when scaling: \n",
    "\n",
    "**When you're creating a scaling object, you should first \"fit\" it to the training data, then transform both the training and testing data using the \"fit\" scaler. If you try to fit the training and testing data separately, you will get inaccurate results.**\n",
    "\n",
    "(Why?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCI Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class label  Alcohol  Malic acid\n",
       "0            1    14.23        1.71\n",
       "1            1    13.20        1.78\n",
       "2            1    13.16        2.36\n",
       "3            1    14.37        1.95\n",
       "4            1    13.24        2.59"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.io.parsers.read_csv(\n",
    "    'http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',\n",
    "     header=None,\n",
    "     usecols=[0,1,2]\n",
    "    )\n",
    "\n",
    "df.columns=['Class label', 'Alcohol', 'Malic acid']\n",
    "\n",
    "df.head()   # these are the different wine classes\n",
    "\n",
    "# -- These data are the results of a chemical analysis of\n",
    "#      wines grown in the same region in Italy but derived from three\n",
    "#      different cultivars ( -- is this where the 3 classes come from?)\n",
    "#      The analysis determined the quantities of 13 constituents\n",
    "#      found in each of the three types of wines. \n",
    "\n",
    "# The attributes are:\n",
    "# 1) Alcohol\n",
    "# 2) Malic acid\n",
    "# 3) Ash\n",
    "# 4) Alcalinity of ash  \n",
    "# 5) Magnesium\n",
    "# 6) Total phenols\n",
    "# 7) Flavanoids\n",
    "# 8) Nonflavanoid phenols\n",
    "# 9) Proanthocyanins\n",
    "# 10)Color intensity\n",
    "# 11)Hue\n",
    "# 12)OD280/OD315 of diluted wines\n",
    "# 13)Proline            \n",
    "\n",
    "# Number of Instances:\n",
    "# class 1: 59\n",
    "# class 2: 71\n",
    "# class 3: 48\n",
    "# The 3 classes are tied to the 3 types of wines\n",
    "\n",
    "# Number of Attributes: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the table above, the features **Alcohol (percent/volumne)** and **Malic acid (g/l)** are measured on different scales, so that **Feature Scaling** is necessary and an important prior to any comparison or combination of these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(df[['Alcohol', 'Malic acid']])  # we build 2 different scalars\n",
    "df_std = std_scale.transform(df[['Alcohol', 'Malic acid']])\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler().fit(df[['Alcohol', 'Malic acid']])\n",
    "df_minmax = minmax_scale.transform(df[['Alcohol', 'Malic acid']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean after standardization:\n",
      "Alcohol=-0.00, Malic acid=-0.00\n",
      "\n",
      "Standard deviation after standardization:\n",
      "Alcohol=1.00, Malic acid=1.00\n"
     ]
    }
   ],
   "source": [
    "print('Mean after standardization:\\nAlcohol={:.2f}, Malic acid={:.2f}'\n",
    "      .format(df_std[:,0].mean(), df_std[:,1].mean()))\n",
    "print('\\nStandard deviation after standardization:\\nAlcohol={:.2f}, Malic acid={:.2f}'\n",
    "      .format(df_std[:,0].std(), df_std[:,1].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGpCAYAAABvZSezAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118586250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot():\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    plt.scatter(df['Alcohol'], df['Malic acid'],\n",
    "            color='green', label='input scale', alpha=0.5)\n",
    "\n",
    "    plt.scatter(df_std[:,0], df_std[:,1], color='red',\n",
    "            label='Standardized [$ N  (\\mu=0, \\; \\sigma=1) $]', alpha=0.3)\n",
    "    \n",
    "    plt.scatter(df_minmax[:,0], df_minmax[:,1],\n",
    "        color='blue', label='min-max scaled [min=0, max=1]', alpha=0.3)\n",
    "\n",
    "    plt.title('Alcohol and Malic Acid content of the wine dataset')\n",
    "    plt.xlabel('Alcohol')\n",
    "    plt.ylabel('Malic Acid')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time!!!\n",
    "\n",
    "* load in the wine data located [here](http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data). The columns for the data are as follows:\n",
    "    1. Label\n",
    "    2. Alcohol\n",
    "    3. Malic acid\n",
    "    4. Ash\n",
    "    5. Alcalinity of ash  \n",
    "    6. Magnesium\n",
    "\t7. Total phenols\n",
    "    8. Flavonoids\n",
    "    9. Nonflavanoid phenols\n",
    "    10. Proanthocyanins\n",
    "    11. Color intensity\n",
    "    12. Hue\n",
    "    13. OD280/OD315 of diluted wines\n",
    "    14. Proline\n",
    "    \n",
    "* build a knn model with 3 nearest neighbors to predict the wine's `label` from the remaining columns. Don't scale the data, and check the test error when using 80/20 train/test split. (use `KNeighborsClassifier(n_neighbors=3)`)\n",
    "* now, build the same model, with the same train/test split, but scale the data using `StandardScaler` and `MinMaxScaler`. What is the test error for each of these scaled datasets (for `train_test_split use random_state=1234` for reproducibility)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic', 'ash', 'ash_alcalinity', 'magnesium', 'total_phenols', 'flavonoids', 'nonflavonoids', 'proanth', 'color', 'hue', 'dilute', 'proline']\n",
      "label\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic</th>\n",
       "      <th>ash</th>\n",
       "      <th>ash_alcalinity</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavonoids</th>\n",
       "      <th>nonflavonoids</th>\n",
       "      <th>proanth</th>\n",
       "      <th>color</th>\n",
       "      <th>hue</th>\n",
       "      <th>dilute</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  alcohol  malic   ash  ash_alcalinity  magnesium  total_phenols  \\\n",
       "0      1    14.23   1.71  2.43            15.6        127           2.80   \n",
       "1      1    13.20   1.78  2.14            11.2        100           2.65   \n",
       "2      1    13.16   2.36  2.67            18.6        101           2.80   \n",
       "3      1    14.37   1.95  2.50            16.8        113           3.85   \n",
       "4      1    13.24   2.59  2.87            21.0        118           2.80   \n",
       "\n",
       "   flavonoids  nonflavonoids  proanth  color   hue  dilute  proline  \n",
       "0        3.06           0.28     2.29   5.64  1.04    3.92     1065  \n",
       "1        2.76           0.26     1.28   4.38  1.05    3.40     1050  \n",
       "2        3.24           0.30     2.81   5.68  1.03    3.17     1185  \n",
       "3        3.49           0.24     2.18   7.80  0.86    3.45     1480  \n",
       "4        2.69           0.39     1.82   4.32  1.04    2.93      735  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "column_names = [\"label\",\"alcohol\",\"malic\",\"ash\",\"ash_alcalinity\",\"magnesium\",\"total_phenols\",\n",
    "                \"flavonoids\",\"nonflavonoids\",\"proanth\",\"color\",\"hue\",\"dilute\",\"proline\"]\n",
    "wine_features = column_names[1:]\n",
    "wine_target = column_names[0]\n",
    "wine_data = pd.read_csv(url,names=column_names)\n",
    "print(wine_features)\n",
    "print(wine_target)\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alcohol  malic   ash  ash_alcalinity  magnesium  total_phenols  flavonoids  \\\n",
      "0    14.23   1.71  2.43            15.6        127           2.80        3.06   \n",
      "1    13.20   1.78  2.14            11.2        100           2.65        2.76   \n",
      "2    13.16   2.36  2.67            18.6        101           2.80        3.24   \n",
      "3    14.37   1.95  2.50            16.8        113           3.85        3.49   \n",
      "4    13.24   2.59  2.87            21.0        118           2.80        2.69   \n",
      "\n",
      "   nonflavonoids  proanth  color   hue  dilute  proline  \n",
      "0           0.28     2.29   5.64  1.04    3.92     1065  \n",
      "1           0.26     1.28   4.38  1.05    3.40     1050  \n",
      "2           0.30     2.81   5.68  1.03    3.17     1185  \n",
      "3           0.24     2.18   7.80  0.86    3.45     1480  \n",
      "4           0.39     1.82   4.32  1.04    2.93      735  \n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: label, dtype: int64\n",
      "(178, 13) (178,)\n"
     ]
    }
   ],
   "source": [
    "#your code below here\n",
    "X = wine_data[wine_features]  # We create a matrix X here that holds our features\n",
    "y = wine_data.label    # We create a vector y that holds our response variables across all the observatons in our dataset.\n",
    "# X_train, X\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     alcohol  malic   ash  ash_alcalinity  magnesium  total_phenols  \\\n",
      "54     13.74   1.67  2.25            16.4        118           2.60   \n",
      "144    12.25   3.88  2.20            18.5        112           1.38   \n",
      "27     13.30   1.72  2.14            17.0         94           2.40   \n",
      "40     13.56   1.71  2.31            16.2        117           3.15   \n",
      "173    13.71   5.65  2.45            20.5         95           1.68   \n",
      "\n",
      "     flavonoids  nonflavonoids  proanth  color   hue  dilute  proline  \n",
      "54         2.90           0.21     1.62   5.85  0.92    3.20     1060  \n",
      "144        0.78           0.29     1.14   8.21  0.65    2.00      855  \n",
      "27         2.19           0.27     1.35   3.95  1.02    2.77     1285  \n",
      "40         3.29           0.34     2.34   6.13  0.95    3.38      795  \n",
      "173        0.61           0.52     1.06   7.70  0.64    1.74      740  \n",
      "----------\n",
      "     alcohol  malic   ash  ash_alcalinity  magnesium  total_phenols  \\\n",
      "111    12.52   2.43  2.17            21.0         88           2.55   \n",
      "123    13.05   5.80  2.13            21.5         86           2.62   \n",
      "63     12.37   1.13  2.16            19.0         87           3.50   \n",
      "88     11.64   2.06  2.46            21.6         84           1.95   \n",
      "141    13.36   2.56  2.35            20.0         89           1.40   \n",
      "\n",
      "     flavonoids  nonflavonoids  proanth  color   hue  dilute  proline  \n",
      "111        2.27           0.26     1.22   2.00  0.90    2.78      325  \n",
      "123        2.65           0.30     2.01   2.60  0.73    3.10      380  \n",
      "63         3.10           0.19     1.87   4.45  1.22    2.87      420  \n",
      "88         1.69           0.48     1.35   2.80  1.00    2.75      680  \n",
      "141        0.50           0.37     0.64   5.60  0.70    2.47      780  \n",
      "----------\n",
      "54     1\n",
      "144    3\n",
      "27     1\n",
      "40     1\n",
      "173    3\n",
      "Name: label, dtype: int64\n",
      "----------\n",
      "111    2\n",
      "123    2\n",
      "63     2\n",
      "88     2\n",
      "141    3\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1234)\n",
    "print(X_train.head())\n",
    "print(\"----------\")\n",
    "print(X_test.head())\n",
    "print(\"----------\")\n",
    "print(y_train.head())\n",
    "print(\"----------\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 3 1 1 3 3 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 3 2 1 2 2 1\n",
      " 1 2 2 3 1 2 2 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 3 2 3 2 2 2 2 2 2 2 2 2 2 2 3\n",
      " 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 2 3 3 1 3 3 3 3 2 3\n",
      " 3 3 3 2 2 3 3 3 3 2 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3]\n",
      "0.870786516854\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(X, y)\n",
    "y_pred = knn_model.predict(X)\n",
    "print(y_pred)\n",
    "print(metrics.accuracy_score(y, y_pred))\n",
    "# print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler   # same approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13)\n",
      "(36, 13)\n",
      "(36,)\n",
      "(178,)\n",
      "(142,)\n",
      "(178,)\n",
      "(36, 13)\n",
      "(36,)\n",
      "0.944444444444\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler_wine = MinMaxScaler()\n",
    "min_max_scaler_wine.fit(X_train)\n",
    "# %debug\n",
    "# %pdb\n",
    "# X_train_scaled = min_max_scaler_wine.fit_transform(X_train)\n",
    "X_train_scaled = min_max_scaler_wine.transform(X_train)\n",
    "knn_model_wine = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model_wine.fit(X_train_scaled, y_train)\n",
    "X_test_scaled = min_max_scaler_wine.transform(X_test)\n",
    "# y_scaled = min_max_scaler.transform(y)\n",
    "y_pred_scaled = knn_model_wine.predict(X_test_scaled)\n",
    "\n",
    "# work on this more ....\n",
    "print(X_train.shape)\n",
    "print(X_test_scaled.shape)\n",
    "print(y_pred_scaled.shape)\n",
    "print(y.shape)\n",
    "print(y_train.shape)\n",
    "print(y_pred.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "# %debug\n",
    "# print(metrics.accuracy_score(y, y_pred_scaled))\n",
    "print(metrics.accuracy_score(y_test, y_pred_scaled))     # Is this is the test error?  Is this correct?\n",
    "# print(metrics.accuracy_score(y_scaled, y_pred_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical Features\n",
    "\n",
    "scikit-learn expects all features to be numeric. So how do we include categorical columns (features) in our model? Before we decide how to encode categorical features, we need to understand the kind of categorical features we have:\n",
    "\n",
    "- **Ordered categories:** transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
    "- **Unordered categories:** use dummy encoding\n",
    "\n",
    "We will look at one case of unordered categorical columns here:\n",
    "- **unordered categories with more than 2 levels**\n",
    "\n",
    "Let's work with another dataset from the UCI ML repository, the [abalone dataset](http://archive.ics.uci.edu/ml/datasets/Abalone), which contains 9 columns:\n",
    "1. **Sex:** M, F, and I (infant)\n",
    "2. **Length:** Longest shell measurement\n",
    "3. **Diameter:** Perpendicular to length\n",
    "4. **Height:** Height with with meat in shell\n",
    "5. **Whole weight:** Whole abalone weight\n",
    "6. **Shucked weight:** Weight of meat only\n",
    "7. **Viscera weight:** Gut weight (after bleeding)\n",
    "8. **Shell weight:** Weight after being dried\n",
    "9. **Rings:** This value +1.5 gives the abalone's age in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diam</th>\n",
       "      <th>height</th>\n",
       "      <th>whole</th>\n",
       "      <th>shucked</th>\n",
       "      <th>viscera</th>\n",
       "      <th>shell</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex  length   diam  height   whole  shucked  viscera  shell  age\n",
       "0   M   0.455  0.365   0.095  0.5140   0.2245   0.1010  0.150   15\n",
       "1   M   0.350  0.265   0.090  0.2255   0.0995   0.0485  0.070    7\n",
       "2   F   0.530  0.420   0.135  0.6770   0.2565   0.1415  0.210    9\n",
       "3   M   0.440  0.365   0.125  0.5160   0.2155   0.1140  0.155   10\n",
       "4   I   0.330  0.255   0.080  0.2050   0.0895   0.0395  0.055    7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"sex\",\"length\",\"diam\",\"height\",\"whole\",\"shucked\",\"viscera\",\"shell\",\"age\"]\n",
    "abalone_data = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\",names=columns)\n",
    "abalone_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we include an unordered categorical feature with more than two levels, like **sex**? We can't simply encode it as F=1, I=2, M=3, because that would imply an **ordered relationship** in which I is somehow \"double\" F and M is somehow \"triple\" F.\n",
    "\n",
    "Instead, we create **additional dummy variables** and append them to the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>I</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F  I  M\n",
       "0  0  0  1\n",
       "1  0  0  1\n",
       "2  1  0  0\n",
       "3  0  0  1\n",
       "4  0  1  0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_dummies = pd.get_dummies(abalone_data.sex).astype(int)\n",
    "\"\"\"Signature: pd.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "Docstring:\n",
    "Convert categorical variable into dummy/indicator variables\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "data : array-like, Series, or DataFrame\n",
    "prefix : string, list of strings, or dict of strings, default None\n",
    "    String to append DataFrame column names\n",
    "    Pass a list with length equal to the number of columns\n",
    "    when calling get_dummies on a DataFrame. Alternativly, `prefix`\n",
    "    can be a dictionary mapping column names to prefixes.\n",
    "prefix_sep : string, default '_'\n",
    "    If appending prefix, separator/delimiter to use. Or pass a\n",
    "    list or dictionary as with `prefix.`\n",
    "dummy_na : bool, default False\n",
    "    Add a column to indicate NaNs, if False NaNs are ignored.\n",
    "columns : list-like, default None\n",
    "    Column names in the DataFrame to be encoded.\n",
    "    If `columns` is None then all the columns with\n",
    "    `object` or `category` dtype will be converted.\n",
    "sparse : bool, default False\n",
    "    Whether the dummy columns should be sparse or not.  Returns\n",
    "    SparseDataFrame if `data` is a Series or if all columns are included.\n",
    "    Otherwise returns a DataFrame with some SparseBlocks.\n",
    "\n",
    "    .. versionadded:: 0.16.1\n",
    "drop_first : bool, default False\n",
    "    Whether to get k-1 dummies out of n categorical levels by removing the\n",
    "    first level.\n",
    "\n",
    "    .. versionadded:: 0.18.0\n",
    "Returns\n",
    "-------\n",
    "dummies : DataFrame or SparseDataFrame\"\"\"\n",
    "sex_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we actually only need **two dummy variables, not three**. Why? Because two dummies capture all of the \"information\" about the **sex** feature, and implicitly defines M as the **baseline level** (0 for both F and I implies M):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F  I\n",
       "0  0  0\n",
       "1  0  0\n",
       "2  1  0\n",
       "3  0  0\n",
       "4  0  1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_dummies = sex_dummies[[\"F\",\"I\"]]\n",
    "sex_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we interpret the encoding:\n",
    "\n",
    "- F is encoded as F=1 and I=0\n",
    "- I is encoded as F=0 and I=1\n",
    "- M is encoded as F=0 and I=0\n",
    "\n",
    "If this is confusing, think about why we only needed one dummy variable for a hypothetical binary categorical variable, not two dummy variables. In general, if you have a categorical feature with **k levels** (k distinct values that it takes on), you create **k-1 dummy variables**.\n",
    "\n",
    "Let's reappend these features to the original abalone dataset and drop the original `sex` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diam</th>\n",
       "      <th>height</th>\n",
       "      <th>whole</th>\n",
       "      <th>shucked</th>\n",
       "      <th>viscera</th>\n",
       "      <th>shell</th>\n",
       "      <th>age</th>\n",
       "      <th>F</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length   diam  height   whole  shucked  viscera  shell  age  F  I\n",
       "0   0.455  0.365   0.095  0.5140   0.2245   0.1010  0.150   15  0  0\n",
       "1   0.350  0.265   0.090  0.2255   0.0995   0.0485  0.070    7  0  0\n",
       "2   0.530  0.420   0.135  0.6770   0.2565   0.1415  0.210    9  1  0\n",
       "3   0.440  0.365   0.125  0.5160   0.2155   0.1140  0.155   10  0  0\n",
       "4   0.330  0.255   0.080  0.2050   0.0895   0.0395  0.055    7  0  1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_data = pd.concat([abalone_data,sex_dummies],axis=1) #remember that concatenating columns means axis=1!\n",
    "abalone_data.drop(\"sex\",inplace=True,axis=1)\n",
    "abalone_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    "scikit-learn models expect that all values are **numeric types** and **hold some meaning**. Thus, missing values are not allowed by scikit-learn (or by most machine learning algorithms).\n",
    "\n",
    "Let's use an example dataset that contains missing values to explore some strategies for how they can be handled. This dataset is called the [Chronic Kidney Disease Dataset](https://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease) and can be used to create a model that predicts whether someone has CKD (chronic kidney disease) or not.\n",
    "\n",
    "The columns in the dataset are as follows:\n",
    "\n",
    "* **age**: subject age, numeric\n",
    "* **bp**: blood pressure,  numeric\n",
    "* **sg**: specific gravity, numeric but discrete\n",
    "* **al**: albumin, numeric but discrete\n",
    "* **su**: sugar, numeric but discrete\n",
    "* **rbc**: red blood cells, categorical\n",
    "* **pc**: pus cell, categorical \n",
    "* **pcc**: pus cell clumps, categorical\n",
    "* **ba**: bacteria, categorical\n",
    "* **bgr**: blood glucose random, numeric\n",
    "* **bu**: blood urea, numeric\n",
    "* **sc**: serum creatinine, numeric \n",
    "* **sod**: sodium, numeric \n",
    "* **pot**: potassium, numeric \n",
    "* **hemo**: hemoglobin, numeric\n",
    "* **pcv**: packed cell volume, numeric\n",
    "* **wc**: white blood cell count, numeric\n",
    "* **rc**: red blood cell count, numeric\n",
    "* **htn**: hypertension, categorical\n",
    "* **dm**: diabetes mellitus, categorical \n",
    "* **cad**: coronary artery disease, categorical\n",
    "* **appet**: appetite, categorical\n",
    "* **pe**: pedal edema, categorical \n",
    "* **ane**: anemia, categorical\n",
    "* **class**: class, categorical\n",
    "\n",
    "Let's load the data in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>80</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>70</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>80</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  age  bp     sg al su     rbc        pc         pcc          ba  bgr  ...   \\\n",
       "0  48  80  1.020  1  0       ?    normal  notpresent  notpresent  121  ...    \n",
       "1   7  50  1.020  4  0       ?    normal  notpresent  notpresent    ?  ...    \n",
       "2  62  80  1.010  2  3  normal    normal  notpresent  notpresent  423  ...    \n",
       "3  48  70  1.005  4  0  normal  abnormal     present  notpresent  117  ...    \n",
       "4  51  80  1.010  2  0  normal    normal  notpresent  notpresent  106  ...    \n",
       "\n",
       "  pcv    wc   rc  htn   dm cad appet   pe  ane class  \n",
       "0  44  7800  5.2  yes  yes  no  good   no   no   ckd  \n",
       "1  38  6000    ?   no   no  no  good   no   no   ckd  \n",
       "2  31  7500    ?   no  yes  no  poor   no  yes   ckd  \n",
       "3  32  6700  3.9  yes   no  no  poor  yes  yes   ckd  \n",
       "4  35  7300  4.6   no   no  no  good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_columns = [\"age\",\"bp\",\"sg\",\"al\",\"su\",\"rbc\",\"pc\",\"pcc\",\"ba\",\"bgr\",\"bu\",\"sc\",\"sod\",\"pot\",\"hemo\",\"pcv\",\"wc\",\"rc\",\"htn\",\"dm\",\"cad\",\"appet\",\"pe\",\"ane\",\"class\"]\n",
    "kidney_data = pd.read_csv(\"../data/chronic_kidney_disease.csv\", header=None,names=kidney_columns)\n",
    "kidney_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like any cell with a missing value is marked with a `?`.\n",
    "\n",
    "Let's make **pandas** recognize that by specifying the `NaN` value type by passing in `?` into the `na_values` parameter of `read_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "     bgr  ...    pcv      wc   rc  htn   dm  cad  appet   pe  ane class  \n",
       "0  121.0  ...   44.0  7800.0  5.2  yes  yes   no   good   no   no   ckd  \n",
       "1    NaN  ...   38.0  6000.0  NaN   no   no   no   good   no   no   ckd  \n",
       "2  423.0  ...   31.0  7500.0  NaN   no  yes   no   poor   no  yes   ckd  \n",
       "3  117.0  ...   32.0  6700.0  3.9  yes   no   no   poor  yes  yes   ckd  \n",
       "4  106.0  ...   35.0  7300.0  4.6   no   no   no   good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_data = pd.read_csv(\"../data/chronic_kidney_disease.csv\",header=None,na_values=\"?\",names=kidney_columns)\n",
    "kidney_data.head() #na_values are marked as ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 25 columns):\n",
      "age      391 non-null float64\n",
      "bp       388 non-null float64\n",
      "sg       353 non-null float64\n",
      "al       354 non-null float64\n",
      "su       351 non-null float64\n",
      "rbc      248 non-null object\n",
      "pc       335 non-null object\n",
      "pcc      396 non-null object\n",
      "ba       396 non-null object\n",
      "bgr      356 non-null float64\n",
      "bu       381 non-null float64\n",
      "sc       383 non-null float64\n",
      "sod      313 non-null float64\n",
      "pot      312 non-null float64\n",
      "hemo     348 non-null float64\n",
      "pcv      329 non-null float64\n",
      "wc       294 non-null float64\n",
      "rc       269 non-null float64\n",
      "htn      398 non-null object\n",
      "dm       398 non-null object\n",
      "cad      398 non-null object\n",
      "appet    399 non-null object\n",
      "pe       399 non-null object\n",
      "ane      399 non-null object\n",
      "class    400 non-null object\n",
      "dtypes: float64(14), object(11)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "kidney_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at which cells have `NaN`'s in them by calling `isnull()` on the `kidney_data` `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age     bp     sg     al     su    rbc     pc    pcc     ba    bgr  \\\n",
       "0  False  False  False  False  False   True  False  False  False  False   \n",
       "1  False  False  False  False  False   True  False  False  False   True   \n",
       "2  False  False  False  False  False  False  False  False  False  False   \n",
       "3  False  False  False  False  False  False  False  False  False  False   \n",
       "4  False  False  False  False  False  False  False  False  False  False   \n",
       "\n",
       "   ...      pcv     wc     rc    htn     dm    cad  appet     pe    ane  class  \n",
       "0  ...    False  False  False  False  False  False  False  False  False  False  \n",
       "1  ...    False  False   True  False  False  False  False  False  False  False  \n",
       "2  ...    False  False   True  False  False  False  False  False  False  False  \n",
       "3  ...    False  False  False  False  False  False  False  False  False  False  \n",
       "4  ...    False  False  False  False  False  False  False  False  False  False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_data.isnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the total number of rows missing values per column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        9\n",
       "bp        12\n",
       "sg        47\n",
       "al        46\n",
       "su        49\n",
       "rbc      152\n",
       "pc        65\n",
       "pcc        4\n",
       "ba         4\n",
       "bgr       44\n",
       "bu        19\n",
       "sc        17\n",
       "sod       87\n",
       "pot       88\n",
       "hemo      52\n",
       "pcv       71\n",
       "wc       106\n",
       "rc       131\n",
       "htn        2\n",
       "dm         2\n",
       "cad        2\n",
       "appet      1\n",
       "pe         1\n",
       "ane        1\n",
       "class      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for number of missing values per column\n",
    "kidney_data.isnull().sum()\n",
    "# age has only 9 missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to have to handle the categorical and the numeric columns differently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age      float64\n",
       "bp       float64\n",
       "sg       float64\n",
       "al       float64\n",
       "su       float64\n",
       "rbc       object\n",
       "pc        object\n",
       "pcc       object\n",
       "ba        object\n",
       "bgr      float64\n",
       "bu       float64\n",
       "sc       float64\n",
       "sod      float64\n",
       "pot      float64\n",
       "hemo     float64\n",
       "pcv      float64\n",
       "wc       float64\n",
       "rc       float64\n",
       "htn       object\n",
       "dm        object\n",
       "cad       object\n",
       "appet     object\n",
       "pe        object\n",
       "ane       object\n",
       "class     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rearrange the numeric and categorical columns for easier access later, and lets remove the response column (`class`) into a separate `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names before rearranging:\n",
      " ['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'class']\n",
      "column names after rearranging:\n",
      " ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'class']\n"
     ]
    }
   ],
   "source": [
    "print(\"column names before rearranging:\\n\",kidney_columns)\n",
    "kidney_columns = kidney_columns[:5]+kidney_columns[9:18]+kidney_columns[5:9]+kidney_columns[18:]\n",
    "print(\"column names after rearranging:\\n\",kidney_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age      float64\n",
      "bp       float64\n",
      "sg       float64\n",
      "al       float64\n",
      "su       float64\n",
      "bgr      float64\n",
      "bu       float64\n",
      "sc       float64\n",
      "sod      float64\n",
      "pot      float64\n",
      "hemo     float64\n",
      "pcv      float64\n",
      "wc       float64\n",
      "rc       float64\n",
      "rbc       object\n",
      "pc        object\n",
      "pcc       object\n",
      "ba        object\n",
      "htn       object\n",
      "dm        object\n",
      "cad       object\n",
      "appet     object\n",
      "pe        object\n",
      "ane       object\n",
      "class     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>...</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su    bgr    bu   sc    sod  pot  ...         pc  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0  121.0  36.0  1.2    NaN  NaN  ...     normal   \n",
       "1   7.0  50.0  1.020  4.0  0.0    NaN  18.0  0.8    NaN  NaN  ...     normal   \n",
       "2  62.0  80.0  1.010  2.0  3.0  423.0  53.0  1.8    NaN  NaN  ...     normal   \n",
       "3  48.0  70.0  1.005  4.0  0.0  117.0  56.0  3.8  111.0  2.5  ...   abnormal   \n",
       "4  51.0  80.0  1.010  2.0  0.0  106.0  26.0  1.4    NaN  NaN  ...     normal   \n",
       "\n",
       "          pcc          ba  htn   dm cad appet   pe  ane class  \n",
       "0  notpresent  notpresent  yes  yes  no  good   no   no   ckd  \n",
       "1  notpresent  notpresent   no   no  no  good   no   no   ckd  \n",
       "2  notpresent  notpresent   no  yes  no  poor   no  yes   ckd  \n",
       "3     present  notpresent  yes   no  no  poor  yes  yes   ckd  \n",
       "4  notpresent  notpresent   no   no  no  good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_data = kidney_data[kidney_columns]\n",
    "target = kidney_data[\"class\"]\n",
    "print(kidney_data.dtypes)\n",
    "kidney_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that our data is arranged in a way that's amenable with dealing with the numeric and the categorical columns separately, let's work through the ways in which we can handle null values.\n",
    "\n",
    "The first thing we can do, is simply throw out any samples that have nulls in any column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of data kept:\n",
      " 0.395\n"
     ]
    }
   ],
   "source": [
    "kidney_data_nonnull = kidney_data.dropna()\n",
    "print(\"Fraction of data kept:\\n\",float(kidney_data_nonnull.shape[0])/kidney_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So throwing out ~60% of the data is no bueno. What else can we do?\n",
    "\n",
    "We can **impute** (fill in) the data on a per-column basis. The imputation strategy for categorical columns is usually one of the following:\n",
    "  1. fill in with the most common categorical value\n",
    "  2. fill in with a special \"missing\" category\n",
    "\n",
    "Let's do each in turn.\n",
    "\n",
    "Here's how we would do **1.**\n",
    "\n",
    "We are going to get the most common category per column, and store it in a `Series` first, then we will apply it per-column to those columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent value in each column:\n",
      " rbc          normal\n",
      "pc           normal\n",
      "pcc      notpresent\n",
      "ba       notpresent\n",
      "htn              no\n",
      "dm               no\n",
      "cad              no\n",
      "appet          good\n",
      "pe               no\n",
      "ane              no\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1. Fill in with the most common categorical value\n",
    "#function to return the most frequent value in a pandas Series\n",
    "def get_most_frequent_value(my_column):\n",
    "    return my_column.value_counts().index[0]\n",
    "\n",
    "most_frequent_values_per_column = kidney_data[kidney_columns[14:-1]].apply(get_most_frequent_value,axis=0)\n",
    "print(\"Most frequent value in each column:\\n\",most_frequent_values_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rbc        pc         pcc          ba  htn   dm cad appet   pe  ane\n",
       "0  normal    normal  notpresent  notpresent  yes  yes  no  good   no   no\n",
       "1  normal    normal  notpresent  notpresent   no   no  no  good   no   no\n",
       "2  normal    normal  notpresent  notpresent   no  yes  no  poor   no  yes\n",
       "3  normal  abnormal     present  notpresent  yes   no  no  poor  yes  yes\n",
       "4  normal    normal  notpresent  notpresent   no   no  no  good   no   no"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_most_frequent = kidney_data[kidney_columns[14:-1]].fillna(most_frequent_values_per_column,axis=0)\n",
    "categorical_most_frequent.head()  # for categorical data-- taking the most common value and filling the null values\n",
    "                                  # with those"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do **2.** (Which is much easier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missing</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>missing</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rbc        pc         pcc          ba  htn   dm cad appet   pe  ane\n",
       "0  missing    normal  notpresent  notpresent  yes  yes  no  good   no   no\n",
       "1  missing    normal  notpresent  notpresent   no   no  no  good   no   no\n",
       "2   normal    normal  notpresent  notpresent   no  yes  no  poor   no  yes\n",
       "3   normal  abnormal     present  notpresent  yes   no  no  poor  yes  yes\n",
       "4   normal    normal  notpresent  notpresent   no   no  no  good   no   no"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Fill in with a special \"missing\" category\n",
    "special_missing_category = kidney_data[kidney_columns[14:-1]].fillna(\"missing\")\n",
    "special_missing_category.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical columns, there are 3 common strategies for filling in missing values:\n",
    "\n",
    "1. Fill in using the mean\n",
    "2. Fill in using the median (when many outliers are present)\n",
    "3. Fill in with some default value (e.g. 0).\n",
    "\n",
    "Let's do each in turn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lots of missing data here:\n",
      "     age    bp     sg   al   su    bgr    bu   sc    sod  pot  hemo   pcv  \\\n",
      "0  48.0  80.0  1.020  1.0  0.0  121.0  36.0  1.2    NaN  NaN  15.4  44.0   \n",
      "1   7.0  50.0  1.020  4.0  0.0    NaN  18.0  0.8    NaN  NaN  11.3  38.0   \n",
      "2  62.0  80.0  1.010  2.0  3.0  423.0  53.0  1.8    NaN  NaN   9.6  31.0   \n",
      "3  48.0  70.0  1.005  4.0  0.0  117.0  56.0  3.8  111.0  2.5  11.2  32.0   \n",
      "4  51.0  80.0  1.010  2.0  0.0  106.0  26.0  1.4    NaN  NaN  11.6  35.0   \n",
      "\n",
      "       wc   rc  \n",
      "0  7800.0  5.2  \n",
      "1  6000.0  NaN  \n",
      "2  7500.0  NaN  \n",
      "3  6700.0  3.9  \n",
      "4  7300.0  4.6  \n",
      "Mean value per column:\n",
      " age       51.483376\n",
      "bp        76.469072\n",
      "sg         1.017408\n",
      "al         1.016949\n",
      "su         0.450142\n",
      "bgr      148.036517\n",
      "bu        57.425722\n",
      "sc         3.072454\n",
      "sod      137.528754\n",
      "pot        4.627244\n",
      "hemo      12.526437\n",
      "pcv       38.884498\n",
      "wc      8406.122449\n",
      "rc         4.707435\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#1. Fill in using the mean\n",
    "print(\"Lots of missing data here:\\n\",kidney_data[kidney_columns[:14]].head())\n",
    "mean_per_column = kidney_data[kidney_columns[:14]].apply(lambda x: x.mean(),axis=0)\n",
    "print(\"Mean value per column:\\n\",mean_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>15.4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.036517</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4.707435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>9.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>4.707435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>11.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su         bgr    bu   sc         sod       pot  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0  121.000000  36.0  1.2  137.528754  4.627244   \n",
       "1   7.0  50.0  1.020  4.0  0.0  148.036517  18.0  0.8  137.528754  4.627244   \n",
       "2  62.0  80.0  1.010  2.0  3.0  423.000000  53.0  1.8  137.528754  4.627244   \n",
       "3  48.0  70.0  1.005  4.0  0.0  117.000000  56.0  3.8  111.000000  2.500000   \n",
       "4  51.0  80.0  1.010  2.0  0.0  106.000000  26.0  1.4  137.528754  4.627244   \n",
       "\n",
       "   hemo   pcv      wc        rc  \n",
       "0  15.4  44.0  7800.0  5.200000  \n",
       "1  11.3  38.0  6000.0  4.707435  \n",
       "2   9.6  31.0  7500.0  4.707435  \n",
       "3  11.2  32.0  6700.0  3.900000  \n",
       "4  11.6  35.0  7300.0  4.600000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. cont'd.\n",
    "numeric_mean_filled = kidney_data[kidney_columns[:14]].fillna(mean_per_column,axis=0)\n",
    "numeric_mean_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age    bp     sg   al   su    bgr    bu   sc    sod  pot  hemo   pcv  \\\n",
      "0  48.0  80.0  1.020  1.0  0.0  121.0  36.0  1.2    NaN  NaN  15.4  44.0   \n",
      "1   7.0  50.0  1.020  4.0  0.0    NaN  18.0  0.8    NaN  NaN  11.3  38.0   \n",
      "2  62.0  80.0  1.010  2.0  3.0  423.0  53.0  1.8    NaN  NaN   9.6  31.0   \n",
      "3  48.0  70.0  1.005  4.0  0.0  117.0  56.0  3.8  111.0  2.5  11.2  32.0   \n",
      "4  51.0  80.0  1.010  2.0  0.0  106.0  26.0  1.4    NaN  NaN  11.6  35.0   \n",
      "\n",
      "       wc   rc  \n",
      "0  7800.0  5.2  \n",
      "1  6000.0  NaN  \n",
      "2  7500.0  NaN  \n",
      "3  6700.0  3.9  \n",
      "4  7300.0  4.6  \n",
      "Median per column:\n",
      " age       55.00\n",
      "bp        80.00\n",
      "sg         1.02\n",
      "al         0.00\n",
      "su         0.00\n",
      "bgr      121.00\n",
      "bu        42.00\n",
      "sc         1.30\n",
      "sod      138.00\n",
      "pot        4.40\n",
      "hemo      12.65\n",
      "pcv       40.00\n",
      "wc      8000.00\n",
      "rc         4.80\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#2. Fill in using the median (when many outliers are present)\n",
    "print(kidney_data[kidney_columns[:14]].head())\n",
    "median_per_column = kidney_data[kidney_columns[:14]].apply(lambda x: x.median(),axis=0)\n",
    "print(\"Median per column:\\n\",median_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>15.4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su    bgr    bu   sc    sod  pot  hemo   pcv  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0  121.0  36.0  1.2  138.0  4.4  15.4  44.0   \n",
       "1   7.0  50.0  1.020  4.0  0.0  121.0  18.0  0.8  138.0  4.4  11.3  38.0   \n",
       "2  62.0  80.0  1.010  2.0  3.0  423.0  53.0  1.8  138.0  4.4   9.6  31.0   \n",
       "3  48.0  70.0  1.005  4.0  0.0  117.0  56.0  3.8  111.0  2.5  11.2  32.0   \n",
       "4  51.0  80.0  1.010  2.0  0.0  106.0  26.0  1.4  138.0  4.4  11.6  35.0   \n",
       "\n",
       "       wc   rc  \n",
       "0  7800.0  5.2  \n",
       "1  6000.0  4.8  \n",
       "2  7500.0  4.8  \n",
       "3  6700.0  3.9  \n",
       "4  7300.0  4.6  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. cont'd.\n",
    "numeric_median_filled = kidney_data[kidney_columns[:14]].fillna(median_per_column,axis=0)\n",
    "numeric_median_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su    bgr    bu   sc    sod  pot  hemo   pcv  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0  121.0  36.0  1.2    0.0  0.0  15.4  44.0   \n",
       "1   7.0  50.0  1.020  4.0  0.0    0.0  18.0  0.8    0.0  0.0  11.3  38.0   \n",
       "2  62.0  80.0  1.010  2.0  3.0  423.0  53.0  1.8    0.0  0.0   9.6  31.0   \n",
       "3  48.0  70.0  1.005  4.0  0.0  117.0  56.0  3.8  111.0  2.5  11.2  32.0   \n",
       "4  51.0  80.0  1.010  2.0  0.0  106.0  26.0  1.4    0.0  0.0  11.6  35.0   \n",
       "\n",
       "       wc   rc  \n",
       "0  7800.0  5.2  \n",
       "1  6000.0  0.0  \n",
       "2  7500.0  0.0  \n",
       "3  6700.0  3.9  \n",
       "4  7300.0  4.6  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "default_value_per_column = kidney_data[kidney_columns[:14]].fillna(0.0)\n",
    "default_value_per_column.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these imputation methods will have distinct effects on classification accuracy.\n",
    "\n",
    "Much fancier methods for imputing values, including [EM (expectation maximization)](https://en.wikipedia.org/wiki/Expectationmaximization_algorithm), [multiple imputation](https://en.wikipedia.org/wiki/Imputation_%28statistics%29), etc. exist. \n",
    "\n",
    "These fancy imputation methods attempt to preserve the statistical relationships among the variables, and \"fill in\" the most likely values, given the values of all of the other columns (these are \"distributional\" imputation methods, as they attempt to keep the distributions of the columns as similar as possible after imputation to what they were prior to imputation). \n",
    "\n",
    "**However, they give really unstable/unreliable results when you have lots of missing data (>10% missing values), so I don't recommend using them when you have a dataset that is missing lots of values.**\n",
    "\n",
    "Look into these to find out more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time!!!\n",
    "\n",
    "1. Create a complete, filled in dataset of non-missing values using mean imputation per numeric column, most frequent value imputation for the categorical values, convert all of the categorical columns into numerical columns using `get_dummies`\n",
    "2. Do the same thing using median imputation for each numeric column.\n",
    "3. Compare test set errors when building a Logistic Regression model (`LogisticRegression()`) on the data and using train/test split (`train_test_split(random_state=123)`), predicting the `class` column. Which imputation method seems to perform better on this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating higher-order features: Polynomial Transformation\n",
    "\n",
    "Although some machine learning methods, like **Random Forests** implicitly model non-linear interactions between the features in your data, it can be helpful to generate the full complement of non-linear interaction terms quickly. A simple and common method to use is polynomial features, which can generate features higher-order and interaction terms.\n",
    "\n",
    "Let's take a look at the kidney data, so we can see how this can be done in practice using the preprocessing function `PolynomialFeatures`. Let's first fill in all of the nulls, then go forward with the exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc']\n",
      "['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
      "age      0\n",
      "bp       0\n",
      "sg       0\n",
      "al       0\n",
      "su       0\n",
      "bgr      0\n",
      "bu       0\n",
      "sc       0\n",
      "sod      0\n",
      "pot      0\n",
      "hemo     0\n",
      "pcv      0\n",
      "wc       0\n",
      "rc       0\n",
      "rbc      0\n",
      "pc       0\n",
      "pcc      0\n",
      "ba       0\n",
      "htn      0\n",
      "dm       0\n",
      "cad      0\n",
      "appet    0\n",
      "pe       0\n",
      "ane      0\n",
      "class    0\n",
      "dtype: int64\n",
      "    age    bp     sg   al   su    bgr    bu   sc    sod  pot  ...         pc  \\\n",
      "0  48.0  80.0  1.020  1.0  0.0  121.0  36.0  1.2  138.0  4.4  ...     normal   \n",
      "1   7.0  50.0  1.020  4.0  0.0  121.0  18.0  0.8  138.0  4.4  ...     normal   \n",
      "2  62.0  80.0  1.010  2.0  3.0  423.0  53.0  1.8  138.0  4.4  ...     normal   \n",
      "3  48.0  70.0  1.005  4.0  0.0  117.0  56.0  3.8  111.0  2.5  ...   abnormal   \n",
      "4  51.0  80.0  1.010  2.0  0.0  106.0  26.0  1.4  138.0  4.4  ...     normal   \n",
      "\n",
      "          pcc          ba  htn   dm cad appet   pe  ane class  \n",
      "0  notpresent  notpresent  yes  yes  no  good   no   no   ckd  \n",
      "1  notpresent  notpresent   no   no  no  good   no   no   ckd  \n",
      "2  notpresent  notpresent   no  yes  no  poor   no  yes   ckd  \n",
      "3     present  notpresent  yes   no  no  poor  yes  yes   ckd  \n",
      "4  notpresent  notpresent   no   no  no  good   no   no   ckd  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Let's first fill in all of the nulls, then go forward with the exploration:\n",
    "kidney_data_numeric_columns = kidney_data.columns.tolist()[:14]\n",
    "kidney_data_categorical_columns = kidney_data.columns.tolist()[14:-1]\n",
    "kidney_data_filled = kidney_data.copy()\n",
    "kidney_data_filled[kidney_data_numeric_columns] = numeric_median_filled\n",
    "kidney_data_filled[kidney_data_categorical_columns] = categorical_most_frequent\n",
    "print(kidney_data_numeric_columns)\n",
    "print(kidney_data_categorical_columns)\n",
    "print(kidney_data_filled.isnull().sum())\n",
    "print(kidney_data_filled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_fit = PolynomialFeatures(degree=3)\n",
    "fitted_degree3_numeric_kidneys = poly_fit.fit_transform(kidney_data_filled[kidney_data_numeric_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first few rows in this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.0000e+00,   4.8000e+01,   8.0000e+01, ...,   3.1637e+08,\n",
       "          2.1091e+05,   1.4061e+02],\n",
       "       [  1.0000e+00,   7.0000e+00,   5.0000e+01, ...,   1.7280e+08,\n",
       "          1.3824e+05,   1.1059e+02],\n",
       "       [  1.0000e+00,   6.2000e+01,   8.0000e+01, ...,   2.7000e+08,\n",
       "          1.7280e+05,   1.1059e+02],\n",
       "       [  1.0000e+00,   4.8000e+01,   7.0000e+01, ...,   1.7507e+08,\n",
       "          1.0191e+05,   5.9319e+01],\n",
       "       [  1.0000e+00,   5.1000e+01,   8.0000e+01, ...,   2.4513e+08,\n",
       "          1.5447e+05,   9.7336e+01]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_degree3_numeric_kidneys[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformation generates every possible pairwise combination of all of the numeric columns in the kidney dataset upto a degree of 3.\n",
    "\n",
    "So, if we had 3 columns, $X,Y,Z$, this transformation would generate:\n",
    "$$(1,X,Y,Z,XY,XZ,YZ,X^2,Y^2,Z^2,X^2Y,X^2Z,...,XYZ,X^3,Y^3,Z^3) $$\n",
    "\n",
    "However, this is complete overkill. What we usually want to generate is just the interactions ($XY, YZ$,etc. terms) not all of the polynomial degrees. In that case, we simply pass an extra Boolean parameter to the `PolynomialFeatures` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolynomialFeatures(degree=3, include_bias=True, interaction_only=True)\n",
      "[[      48.          80.           1.02  ...,     3523.52    624624.\n",
      "   1784640.   ]\n",
      " [       7.          50.           1.02  ...,     2061.12    325440.\n",
      "   1094400.   ]\n",
      " [      62.          80.           1.01  ...,     1428.48    345600.\n",
      "   1116000.   ]\n",
      " ..., \n",
      " [      12.          80.           1.02  ...,     4180.68    563112.\n",
      "   1746360.   ]\n",
      " [      17.          60.           1.025 ...,     4272.78    603216.\n",
      "   2166480.   ]\n",
      " [      58.          80.           1.025 ...,     5108.14    655384.\n",
      "   2198440.   ]]\n"
     ]
    }
   ],
   "source": [
    "poly_fit_3_interact = PolynomialFeatures(degree=3,interaction_only=True)\n",
    "#don't want the initial constant term, so only keep columns 1 to the end\n",
    "interactions_only_kidney_columns = poly_fit_3_interact.fit_transform(kidney_data_filled[kidney_data_numeric_columns])[:,1:]\n",
    "print(poly_fit_3_interact)\n",
    "print(interactions_only_kidney_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time!\n",
    "1. Generate the interactions-only degree-2 polynomial-fit features for the kidney_data null-filled dataset on the numeric columns only.\n",
    "2. Use train_test_split to predict the class with/without these polynomial features using `LogisticRegression()`. What happens to train/test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolynomialFeatures(degree=2, include_bias=True, interaction_only=True)\n",
      "[[     48.         80.          1.02  ...,  343200.        228.8     40560.   ]\n",
      " [      7.         50.          1.02  ...,  228000.        182.4     28800.   ]\n",
      " [     62.         80.          1.01  ...,  232500.        148.8     36000.   ]\n",
      " ..., \n",
      " [     12.         80.          1.02  ...,  323400.        264.6     35640.   ]\n",
      " [     17.         60.          1.025 ...,  367200.        300.9     42480.   ]\n",
      " [     58.         80.          1.025 ...,  360400.        323.3     41480.   ]]\n"
     ]
    }
   ],
   "source": [
    "#1. Generate the interactions-only degree-2 polynomial-fit features for the kidney_data null-filled dataset on the \n",
    "# numeric columns only.\n",
    "poly_fit_2_interact = PolynomialFeatures(degree=2,interaction_only=True)\n",
    "#don't want the initial constant term, so only keep columns 1 to the end\n",
    "interactions_only_kidney_columns_degree2 = poly_fit_2_interact.fit_transform(kidney_data_filled[kidney_data_numeric_columns])[:,1:]\n",
    "print(poly_fit_2_interact)\n",
    "print(interactions_only_kidney_columns_degree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: (280, 14)\n",
      "testing data size: (120, 14)\n",
      "total data size: (400, 14)\n",
      "size of y_mult: (400,)\n",
      "size of y_mult_train:  (280,)\n",
      "size of y_mult_test:  (120,)\n"
     ]
    }
   ],
   "source": [
    "#2 Use train_test_split to predict the class with/without these polynomial features using LogisticRegression(). \n",
    "# What happens to train/test accuracy?\n",
    "logreg = LogisticRegression()\n",
    "X = kidney_data_filled[kidney_data_numeric_columns]\n",
    "y = kidney_data_filled['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Split arrays or matrices into random train and test subsets\n",
    "# -- use random state for debugging purposes\n",
    "print(\"training data size:\",X_train.shape)\n",
    "print(\"testing data size:\",X_test.shape)\n",
    "print (\"total data size:\", X.shape)\n",
    "print(\"size of y_mult:\", y.shape)\n",
    "print(\"size of y_mult_train: \", y_train.shape)\n",
    "print(\"size of y_mult_test: \", y_test.shape)\n",
    "# test_size : float, int, or None (default is None): If float, should be between 0.0 and 1.0 and represent the \n",
    "# proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If \n",
    "# None, the value is automatically set to the complement of the train size. If train size is also None, test size is \n",
    "# set to 0.25.\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "\n",
    "logreg.fit(X_train, y_train)   # we fit logistic regression object on training data only\n",
    "# generate predictions on training set and evaluate\n",
    "outcome_pred_class_log_train = logreg.predict(X_train)\n",
    "# print(\"Training set RMSE:\",np.sqrt(metrics.mean_squared_error(y_train,outcome_pred_class_log_train)))\n",
    "# print(\"Training set MAE: \",metrics.mean_absolute_error(y_train, outcome_pred_class_log_train))\n",
    "# print(\"Training set MSE: \",metrics.mean_squared_error(y_train,outcome_pred_class_log_train))\n",
    "# # generate predictions on testing set and evaluate\n",
    "# outcome_pred_class_log_test = logreg.predict(X_test)\n",
    "# print(\"Test set RMSE:\",np.sqrt(metrics.mean_squared_error(y_test,outcome_pred_class_log_test)))\n",
    "# print(\"Training set MAE: \",metrics.mean_absolute_error(y_test, outcome_pred_class_log_test))\n",
    "# print(\"Training set MSE: \",metrics.mean_squared_error(y_test,outcome_pred_class_log_test))\n",
    "\n",
    "# Need to get back to this one later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to talk about better ways to measure model performance than train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation as many train/test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to motivate this discussion of cross-validation by trying to see if there are any drawbacks from just using train/test split. Specifically:\n",
    "  - What is the drawback of using the **train/test split** procedure for model evaluation?\n",
    "  - How does **K-fold cross-validation** overcome this limitation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:** We need a way to choose between several different machine learning models (or multiple versions of the same model). Our goal is **to estimate likely performance of a model on out-of-sample data**.\n",
    "\n",
    "**Initial approach:** Train/test split\n",
    "- Split the dataset into two pieces, so that the model can be trained and tested on **different data**.\n",
    "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance (because testing on the same data that you used to train the model causes **overfitting** and worse out-of-sample performance).\n",
    "- However, just using one train/test split provides a **high variance** estimate since changing which observations happen to be in the testing set can significantly change testing accuracy.\n",
    "\n",
    "What would be a better approach?\n",
    "\n",
    "**Better approach:** Create a bunch of train/test splits, calculate the testing accuracy for each, and average the results together.\n",
    "\n",
    "**This is the essense of cross-validation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation flow\n",
    "1. Split the dataset into K **equal** partitions (or \"folds\").\n",
    "2. Use fold 1 as the **testing set** and the union of the other folds as the **training set**.\n",
    "3. Calculate **testing accuracy**.\n",
    "4. Repeat steps 2 and 3 K times, using a **different fold** as the testing set each time.\n",
    "5. Use the **average testing accuracy** as the estimate of out-of-sample accuracy.\n",
    "\n",
    "**Here's an example diagram where K = 5 (5 fold cross-validation):**\n",
    "![5-fold cross-validation](../images/5-fold-cv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAFKCAIAAABkZxAAAABfTklEQVR42u3dd3yV5f3/8deZOdk7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\nYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import Image \n",
    "Image(filename='../images/5-fold-cv.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration                         Training set observations                          Testing set observations\n",
      "1 [ 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29] [0 1 2 3 4 5]\n",
      "2 [ 0  1  2  3  4  5 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29] [ 6  7  8  9 10 11]\n",
      "3 [ 0  1  2  3  4  5  6  7  8  9 10 11 18 19 20 21 22 23 24 25 26 27 28 29] [12 13 14 15 16 17]\n",
      "4 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 24 25 26 27 28 29] [18 19 20 21 22 23]\n",
      "5 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23] [24 25 26 27 28 29]\n"
     ]
    }
   ],
   "source": [
    "# simulate splitting a dataset of 30 observations into 5 folds\n",
    "kf = KFold(30, n_folds=5, shuffle=False)  # in some cases set shuffle to false, but in most cases you would\n",
    "# want to set shuffle to True (as is default case)\n",
    "\n",
    "# * Dataset contains 30 observations (numbered 0 through 29)\n",
    "# * 5-fold cross-validation, thus it runs for 5 iterations\n",
    "# * For each iteration, every observation is either in the training set or the testing set, but not both\n",
    "# * Every observation is in the testing set exactly once\n",
    "\n",
    "# -------------\n",
    "\n",
    "# Init signature: KFold(self, n, n_folds=3, shuffle=False, random_state=None)\n",
    "# Docstring:\n",
    "# K-Folds cross validation iterator.\n",
    "\n",
    "# Provides train/test indices to split data in train test sets. Split\n",
    "# dataset into k consecutive folds (without shuffling by default).\n",
    "\n",
    "# Each fold is then used a validation set once while the k - 1 remaining\n",
    "# fold form the training set.\n",
    "\n",
    "# Read more in the :ref:`User Guide <cross_validation>`.\n",
    "\n",
    "# Parameters\n",
    "# ----------\n",
    "# n : int\n",
    "#     Total number of elements.\n",
    "\n",
    "# n_folds : int, default=3\n",
    "#     Number of folds. Must be at least 2.\n",
    "\n",
    "# shuffle : boolean, optional\n",
    "#     Whether to shuffle the data before splitting into batches.\n",
    "\n",
    "# random_state : None, int or RandomState\n",
    "#     When shuffle=True, pseudo-random number generator state used for\n",
    "#     shuffling. If None, use default numpy RNG for shuffling.\n",
    "\n",
    "# Examples\n",
    "# --------\n",
    "# >>> from sklearn.cross_validation import KFold\n",
    "# >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "# >>> y = np.array([1, 2, 3, 4])\n",
    "# >>> kf = KFold(4, n_folds=2)\n",
    "# >>> len(kf)\n",
    "# 2\n",
    "# >>> print(kf)  # doctest: +NORMALIZE_WHITESPACE\n",
    "# sklearn.cross_validation.KFold(n=4, n_folds=2, shuffle=False,\n",
    "#                                random_state=None)\n",
    "# >>> for train_index, test_index in kf:\n",
    "# ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "# ...    X_train, X_test = X[train_index], X[test_index]\n",
    "# ...    y_train, y_test = y[train_index], y[test_index]\n",
    "# TRAIN: [2 3] TEST: [0 1]\n",
    "# TRAIN: [0 1] TEST: [2 3]\n",
    "\n",
    "# Notes\n",
    "# -----\n",
    "# The first n % n_folds folds have size n // n_folds + 1, other folds have\n",
    "# size n // n_folds.\n",
    "\n",
    "\n",
    "# print the contents of each training and testing set\n",
    "print('{} {:^74} {}'.format('Iteration', 'Training set observations', 'Testing set observations'))\n",
    "for iteration, data in enumerate(kf, start=1):\n",
    "    print('{} {} {}'.format(iteration, data[0], data[1]))\n",
    "    \n",
    "# It's common when iterating over a sequence to want to keep track of the index of the current item . Python has a\n",
    "# built-in function 'enumerate' which returns a sequence of (i, value) tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through this carefully:\n",
    "- Dataset contains **30 observations** (numbered 0 through 29)\n",
    "- 5-fold cross-validation, thus it runs for **5 iterations**\n",
    "- For each iteration, every observation is either in the training set or the testing set, **but not both**\n",
    "- Every observation is in the testing set **exactly once**\n",
    "\n",
    "Let's try this with real data and compare to just a single train/test split (we will use the vertebral column data we've used before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for split  0 :  0.806451612903\n",
      "Accuracy for split  1 :  0.774193548387\n",
      "Accuracy for split  2 :  0.935483870968\n",
      "Accuracy for split  3 :  0.774193548387\n",
      "Accuracy for split  4 :  0.903225806452\n",
      "Accuracy for split  5 :  0.838709677419\n",
      "Accuracy for split  6 :  0.806451612903\n",
      "Accuracy for split  7 :  0.935483870968\n",
      "Accuracy for split  8 :  0.645161290323\n",
      "Accuracy for split  9 :  0.838709677419\n",
      "Mean KF-accuracy: 0.825806451613\n",
      "Std of KF-accuracy: 0.0831232175918\n",
      "10-fold accuracies:\n",
      " [ 0.5484  0.6452  0.6774  0.8065  0.9032  0.8065  0.9355  1.      0.8387\n",
      "  0.871 ]\n",
      "Mean cv-accuracy: 0.803225806452\n",
      "Std of cv-accuracy: 0.133355010378\n"
     ]
    }
   ],
   "source": [
    "# read in the vertebral column data\n",
    "vertebral_data = pd.read_csv(\"../data/vertebral_column_2_categories.dat\", sep=\" \",\n",
    "                             names=[\"pelvic_incidence\",\"pelvic_tilt\",\"lumbar_lordosis_angle\",\"sacral_slope\",\"pelvic_radius\",\"spondy_grade\",\"outcome\"])\n",
    "#generate features, targets\n",
    "X = vertebral_data.ix[:,:-1]  # features\n",
    "y = vertebral_data.outcome    # target\n",
    "rf = RandomForestClassifier(n_estimators=50) #random forest with 50 trees\n",
    "\n",
    "#train/test split with 10% of data in each split:\n",
    "# kf = KFold(len(X), n_folds=10, shuffle=False)\n",
    "kf = KFold(len(X), n_folds=10, shuffle=True)\n",
    "kf_scores = []\n",
    "for i, (train_idx, test_idx) in enumerate(kf):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "#     X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.1)\n",
    "    rf_fit = rf.fit(X_train,y_train)\n",
    "    score = metrics.accuracy_score(y_test,rf_fit.predict(X_test))\n",
    "    print(\"Accuracy for split \",i,\": \", score)\n",
    "    kf_scores.append(score)\n",
    "\n",
    "print(\"Mean KF-accuracy:\",np.mean(kf_scores))\n",
    "print(\"Std of KF-accuracy:\",np.std(kf_scores))\n",
    "    \n",
    "#compute cross-validation score accuracy across 10 folds\n",
    "cross_val_scores = cross_val_score(rf,X,y,cv=10)\n",
    "print(\"10-fold accuracies:\\n\",cross_val_scores)\n",
    "print(\"Mean cv-accuracy:\",np.mean(cross_val_scores))\n",
    "print(\"Std of cv-accuracy:\",np.std(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time!!!\n",
    "\n",
    "* Compute cross-validated mean/std of accuracies when doing 20, 40, 50-fold cross-validation using `cross_val_score()`. What happens to the mean and standard deviation of the accuracies as you increase the number of folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for split  0 :  0.875\n",
      "Accuracy for split  1 :  1.0\n",
      "Accuracy for split  2 :  0.9375\n",
      "Accuracy for split  3 :  1.0\n",
      "Accuracy for split  4 :  0.8125\n",
      "Accuracy for split  5 :  0.625\n",
      "Accuracy for split  6 :  0.8125\n",
      "Accuracy for split  7 :  0.8125\n",
      "Accuracy for split  8 :  0.8125\n",
      "Accuracy for split  9 :  0.8125\n",
      "Accuracy for split  10 :  0.666666666667\n",
      "Accuracy for split  11 :  0.866666666667\n",
      "Accuracy for split  12 :  0.6\n",
      "Accuracy for split  13 :  0.666666666667\n",
      "Accuracy for split  14 :  0.933333333333\n",
      "Accuracy for split  15 :  0.866666666667\n",
      "Accuracy for split  16 :  0.933333333333\n",
      "Accuracy for split  17 :  0.933333333333\n",
      "Accuracy for split  18 :  0.866666666667\n",
      "Accuracy for split  19 :  0.933333333333\n",
      "Mean KF-accuracy: 0.838333333333\n",
      "Std of KF-accuracy: 0.115444491231\n",
      "20-fold accuracies:\n",
      " [ 0.625   0.5     0.625   0.6875  0.6875  0.8125  0.75    0.8125  0.875\n",
      "  0.875   0.9333  0.9333  0.8667  1.      1.      1.      0.8     0.8     1.\n",
      "  0.8   ]\n",
      "Mean cv-accuracy: 0.819166666667\n",
      "Std of cv-accuracy: 0.138433698531\n"
     ]
    }
   ],
   "source": [
    "# pass\n",
    "\n",
    "# For 20-fold cross-validation:\n",
    "\n",
    "kf_20 = KFold(len(X), n_folds=20, shuffle=True)\n",
    "kf_scores_20 = []\n",
    "for i, (train_idx_20, test_idx_20) in enumerate(kf_20):\n",
    "    X_train_20, X_test_20 = X.iloc[train_idx_20], X.iloc[test_idx_20]\n",
    "    y_train_20, y_test_20 = y.iloc[train_idx_20], y.iloc[test_idx_20]\n",
    "#     X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.1)\n",
    "    rf_fit_20 = rf.fit(X_train_20,y_train_20)\n",
    "    score_20 = metrics.accuracy_score(y_test_20,rf_fit_20.predict(X_test_20))\n",
    "    print(\"Accuracy for split \",i,\": \", score_20)\n",
    "    kf_scores_20.append(score_20)\n",
    "\n",
    "print(\"Mean KF-accuracy:\",np.mean(kf_scores_20))\n",
    "print(\"Std of KF-accuracy:\",np.std(kf_scores_20))\n",
    "    \n",
    "#compute cross-validation score accuracy across 20 folds\n",
    "cross_val_scores_20 = cross_val_score(rf,X,y,cv=20)\n",
    "print(\"20-fold accuracies:\\n\",cross_val_scores_20)\n",
    "print(\"Mean cv-accuracy:\",np.mean(cross_val_scores_20))\n",
    "print(\"Std of cv-accuracy:\",np.std(cross_val_scores_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for split  0 :  0.875\n",
      "Accuracy for split  1 :  1.0\n",
      "Accuracy for split  2 :  0.75\n",
      "Accuracy for split  3 :  1.0\n",
      "Accuracy for split  4 :  0.625\n",
      "Accuracy for split  5 :  0.875\n",
      "Accuracy for split  6 :  1.0\n",
      "Accuracy for split  7 :  0.875\n",
      "Accuracy for split  8 :  0.625\n",
      "Accuracy for split  9 :  0.875\n",
      "Accuracy for split  10 :  0.875\n",
      "Accuracy for split  11 :  0.875\n",
      "Accuracy for split  12 :  1.0\n",
      "Accuracy for split  13 :  0.875\n",
      "Accuracy for split  14 :  1.0\n",
      "Accuracy for split  15 :  0.875\n",
      "Accuracy for split  16 :  1.0\n",
      "Accuracy for split  17 :  0.875\n",
      "Accuracy for split  18 :  0.875\n",
      "Accuracy for split  19 :  0.625\n",
      "Accuracy for split  20 :  0.75\n",
      "Accuracy for split  21 :  0.625\n",
      "Accuracy for split  22 :  0.875\n",
      "Accuracy for split  23 :  0.75\n",
      "Accuracy for split  24 :  0.75\n",
      "Accuracy for split  25 :  0.75\n",
      "Accuracy for split  26 :  0.875\n",
      "Accuracy for split  27 :  0.875\n",
      "Accuracy for split  28 :  1.0\n",
      "Accuracy for split  29 :  0.625\n",
      "Accuracy for split  30 :  0.857142857143\n",
      "Accuracy for split  31 :  1.0\n",
      "Accuracy for split  32 :  0.714285714286\n",
      "Accuracy for split  33 :  0.857142857143\n",
      "Accuracy for split  34 :  0.857142857143\n",
      "Accuracy for split  35 :  0.714285714286\n",
      "Accuracy for split  36 :  1.0\n",
      "Accuracy for split  37 :  1.0\n",
      "Accuracy for split  38 :  0.857142857143\n",
      "Accuracy for split  39 :  1.0\n",
      "Mean KF-accuracy: 0.852678571429\n",
      "Std of KF-accuracy: 0.122014735435\n",
      "40-fold accuracies:\n",
      " [ 0.5556  0.6667  0.6667  0.4444  0.7778  0.8889  0.5556  0.6667  0.6667\n",
      "  0.5556  1.      0.625   0.875   0.875   0.75    0.75    1.      0.875\n",
      "  0.875   0.75    0.8571  1.      1.      1.      1.      1.      1.      1.\n",
      "  0.8571  1.      0.7143  0.8571  1.      0.7143  0.8571  1.      0.8571\n",
      "  0.8571  0.8571  1.    ]\n",
      "Mean cv-accuracy: 0.831200396825\n",
      "Std of cv-accuracy: 0.155275772024\n"
     ]
    }
   ],
   "source": [
    "# For 40-fold cross-validation:\n",
    "\n",
    "kf_40 = KFold(len(X), n_folds=40, shuffle=True)\n",
    "kf_scores_40 = []\n",
    "for i, (train_idx_40, test_idx_40) in enumerate(kf_40):\n",
    "    X_train_40, X_test_40 = X.iloc[train_idx_40], X.iloc[test_idx_40]\n",
    "    y_train_40, y_test_40 = y.iloc[train_idx_40], y.iloc[test_idx_40]\n",
    "#     X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.1)\n",
    "    rf_fit_40 = rf.fit(X_train_40,y_train_40)\n",
    "    score_40 = metrics.accuracy_score(y_test_40,rf_fit_40.predict(X_test_40))\n",
    "    print(\"Accuracy for split \",i,\": \", score_40)\n",
    "    kf_scores_40.append(score_40)\n",
    "\n",
    "print(\"Mean KF-accuracy:\",np.mean(kf_scores_40))\n",
    "print(\"Std of KF-accuracy:\",np.std(kf_scores_40))\n",
    "    \n",
    "#compute cross-validation score accuracy across 40 folds\n",
    "cross_val_scores_40 = cross_val_score(rf,X,y,cv=40)\n",
    "print(\"40-fold accuracies:\\n\",cross_val_scores_40)\n",
    "print(\"Mean cv-accuracy:\",np.mean(cross_val_scores_40))\n",
    "print(\"Std of cv-accuracy:\",np.std(cross_val_scores_40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for split  0 :  0.714285714286\n",
      "Accuracy for split  1 :  1.0\n",
      "Accuracy for split  2 :  0.857142857143\n",
      "Accuracy for split  3 :  0.857142857143\n",
      "Accuracy for split  4 :  0.857142857143\n",
      "Accuracy for split  5 :  1.0\n",
      "Accuracy for split  6 :  1.0\n",
      "Accuracy for split  7 :  0.857142857143\n",
      "Accuracy for split  8 :  0.857142857143\n",
      "Accuracy for split  9 :  1.0\n",
      "Accuracy for split  10 :  0.666666666667\n",
      "Accuracy for split  11 :  1.0\n",
      "Accuracy for split  12 :  1.0\n",
      "Accuracy for split  13 :  0.833333333333\n",
      "Accuracy for split  14 :  0.666666666667\n",
      "Accuracy for split  15 :  0.833333333333\n",
      "Accuracy for split  16 :  0.833333333333\n",
      "Accuracy for split  17 :  0.833333333333\n",
      "Accuracy for split  18 :  1.0\n",
      "Accuracy for split  19 :  1.0\n",
      "Accuracy for split  20 :  0.666666666667\n",
      "Accuracy for split  21 :  1.0\n",
      "Accuracy for split  22 :  0.666666666667\n",
      "Accuracy for split  23 :  0.833333333333\n",
      "Accuracy for split  24 :  0.833333333333\n",
      "Accuracy for split  25 :  1.0\n",
      "Accuracy for split  26 :  0.833333333333\n",
      "Accuracy for split  27 :  1.0\n",
      "Accuracy for split  28 :  0.833333333333\n",
      "Accuracy for split  29 :  0.833333333333\n",
      "Accuracy for split  30 :  0.666666666667\n",
      "Accuracy for split  31 :  0.833333333333\n",
      "Accuracy for split  32 :  0.833333333333\n",
      "Accuracy for split  33 :  0.666666666667\n",
      "Accuracy for split  34 :  0.666666666667\n",
      "Accuracy for split  35 :  1.0\n",
      "Accuracy for split  36 :  1.0\n",
      "Accuracy for split  37 :  0.666666666667\n",
      "Accuracy for split  38 :  1.0\n",
      "Accuracy for split  39 :  0.833333333333\n",
      "Accuracy for split  40 :  0.833333333333\n",
      "Accuracy for split  41 :  0.5\n",
      "Accuracy for split  42 :  0.833333333333\n",
      "Accuracy for split  43 :  0.666666666667\n",
      "Accuracy for split  44 :  0.833333333333\n",
      "Accuracy for split  45 :  0.833333333333\n",
      "Accuracy for split  46 :  0.833333333333\n",
      "Accuracy for split  47 :  0.833333333333\n",
      "Accuracy for split  48 :  1.0\n",
      "Accuracy for split  49 :  0.666666666667\n",
      "Mean KF-accuracy: 0.843333333333\n",
      "Std of KF-accuracy: 0.127871995236\n",
      "50-fold accuracies:\n",
      " [ 0.8571  0.5714  0.8571  0.4286  0.4286  0.7143  0.8571  0.5714  0.8571\n",
      "  1.      0.8333  0.8333  0.5     1.      0.6667  0.6667  1.      0.8333\n",
      "  0.8333  0.8333  1.      0.8333  0.6667  0.8333  1.      1.      0.8333\n",
      "  1.      1.      1.      0.8333  1.      1.      1.      1.      1.      1.\n",
      "  1.      1.      1.      0.6667  0.8333  1.      0.6667  1.      1.\n",
      "  0.8333  0.8333  0.6667  1.    ]\n",
      "Mean cv-accuracy: 0.852857142857\n",
      "Std of cv-accuracy: 0.164385063128\n"
     ]
    }
   ],
   "source": [
    "# For 50-fold cross-validation:\n",
    "\n",
    "kf_50 = KFold(len(X), n_folds=50, shuffle=True)\n",
    "kf_scores_50 = []\n",
    "for i, (train_idx_50, test_idx_50) in enumerate(kf_50):\n",
    "    X_train_50, X_test_50 = X.iloc[train_idx_50], X.iloc[test_idx_50]\n",
    "    y_train_50, y_test_50 = y.iloc[train_idx_50], y.iloc[test_idx_50]\n",
    "#     X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.1)\n",
    "    rf_fit_50 = rf.fit(X_train_50,y_train_50)\n",
    "    score_50 = metrics.accuracy_score(y_test_50,rf_fit_50.predict(X_test_50))\n",
    "    print(\"Accuracy for split \",i,\": \", score_50)\n",
    "    kf_scores_50.append(score_50)\n",
    "\n",
    "print(\"Mean KF-accuracy:\",np.mean(kf_scores_50))\n",
    "print(\"Std of KF-accuracy:\",np.std(kf_scores_50))\n",
    "    \n",
    "#compute cross-validation score accuracy across 50 folds\n",
    "cross_val_scores_50 = cross_val_score(rf,X,y,cv=50)\n",
    "print(\"50-fold accuracies:\\n\",cross_val_scores_50)\n",
    "print(\"Mean cv-accuracy:\",np.mean(cross_val_scores_50))\n",
    "print(\"Std of cv-accuracy:\",np.std(cross_val_scores_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv-accuracy for 20 folds: 0.819166666667\n",
      "Std of cv-accuracy for 20 folds: 0.138433698531\n",
      "Mean cv-accuracy for 40 folds: 0.831200396825\n",
      "Std of cv-accuracy for 40 folds: 0.155275772024\n",
      "Mean cv-accuracy for 50 folds: 0.852857142857\n",
      "Std of cv-accuracy for 50 folds: 0.164385063128\n",
      "We see that the mean and standard deviation of the cross-validated accuracies increase as we increase the number of folds\n"
     ]
    }
   ],
   "source": [
    "# In Summary:\n",
    "print(\"Mean cv-accuracy for 20 folds:\",np.mean(cross_val_scores_20))\n",
    "print(\"Std of cv-accuracy for 20 folds:\",np.std(cross_val_scores_20))\n",
    "print(\"Mean cv-accuracy for 40 folds:\",np.mean(cross_val_scores_40))\n",
    "print(\"Std of cv-accuracy for 40 folds:\",np.std(cross_val_scores_40))\n",
    "print(\"Mean cv-accuracy for 50 folds:\",np.mean(cross_val_scores_50))\n",
    "print(\"Std of cv-accuracy for 50 folds:\",np.std(cross_val_scores_50))\n",
    "print(\"We see that the mean and standard deviation of the cross-validated accuracies increase as we increase the number of folds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the advantages of **cross-validation:**\n",
    "- More accurate estimate of out-of-sample accuracy\n",
    "- More \"efficient\" use of data (every observation is used for both training and testing)\n",
    "\n",
    "However, there are some advantages to using **train/test split:**\n",
    "- Runs K times faster than K-fold cross-validation\n",
    "- Simpler to examine the detailed results of the testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve this basic cross-validation approach a bit more as follows:\n",
    "\n",
    "**Repeated cross-validation**\n",
    "\n",
    "- Repeat cross-validation multiple times (with **different random splits** of the data) and average the results\n",
    "- More reliable estimate of out-of-sample performance by **reducing the variance** associated with a single trial of cross-validation\n",
    "\n",
    "**Creating a hold-out set**\n",
    "\n",
    "- \"Hold out\" a portion of the data **before** beginning the model building process\n",
    "- Locate the best model using cross-validation on the remaining data, and test it **using the hold-out set**\n",
    "- More reliable estimate of out-of-sample performance since hold-out set is **truly out-of-sample**\n",
    "\n",
    "**Feature engineering and selection within cross-validation iterations**\n",
    "\n",
    "- Normally, feature engineering and selection occurs **before** cross-validation\n",
    "- Instead, you can perform all feature engineering and selection **within each cross-validation iteration**\n",
    "- This gives us a more reliable estimate of out-of-sample performance since it **better mimics** the application of the model to out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.cross_validation import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use 10-fold cross-validation to find best max_depth per-tree out of depth 2 or 3\n",
    "\n",
    "# try max_depth=2\n",
    "rf_2 = RandomForestClassifier(max_depth=2, random_state=1)\n",
    "print(\"Cross-validated mean accuracy for depth 2:\",cross_val_score(rf_2, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# try max_depth=3\n",
    "rf_3 = RandomForestClassifier(max_depth=3, random_state=1)\n",
    "print(\"Cross-validated mean accuracy for depth 3:\",cross_val_score(rf_3, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use GridSearchCV to automate the search across depths 1-10\n",
    "rf_grid = RandomForestClassifier(n_estimators=50,random_state=1,n_jobs=-1) #50 trees\n",
    "max_depth_range = range(1, 20, 2)\n",
    "param_grid = dict(max_depth=max_depth_range)\n",
    "print(param_grid)\n",
    "grid = GridSearchCV(rf_grid, param_grid, cv=3, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "\n",
    "# store the results of the grid search\n",
    "grid.grid_scores_\n",
    "grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the results\n",
    "sns.plt.plot(max_depth_range, grid_mean_scores)\n",
    "sns.plt.xlabel('Value of max_depth')\n",
    "sns.plt.ylabel('Cross-Validated Mean Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what was best model?\n",
    "grid.best_score_\n",
    "grid.best_params_\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# search multiple parameters simultaneously\n",
    "max_depth_range = range(1, 11)\n",
    "leaf_range = range(1, 11)\n",
    "param_grid2 = dict(max_depth=max_depth_range, min_samples_leaf=leaf_range)\n",
    "grid = GridSearchCV(rf_grid, param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "grid.grid_scores_\n",
    "grid.best_score_\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Exercise Time!!!\n",
    "\n",
    "I want you to use and test several different imputation methods, different feature transformations, and different model parameters using `GridSearchCV` for the kidney dataset.\n",
    "\n",
    "This will get you to use everything we've learned today on one dataset with several kinds of missing values, and using both categorical and numeric values.\n",
    "\n",
    "**Don't forget to transform the categories using `pd.get_dummies()` once you've filled in the missing data!**\n",
    "\n",
    "Remember there are other parameters you can tune for random forests than just the maximum depth. Look at the random forest lesson or the [random forest documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "Try to be systematic in your exploration. Your goal is to make as robust a model as you can (lowest average cross-validated test error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
