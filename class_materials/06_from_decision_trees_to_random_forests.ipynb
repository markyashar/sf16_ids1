{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Class 6 Agenda:\n",
    "  * **Decision Trees: Regression Trees**\n",
    "  * **What happens when a single tree is grown too deep?**\n",
    "  * **Decision Trees: Classification Trees**\n",
    "  * **Why Have Ensembles?**\n",
    "  * **Ensembles make excellent machine learning models**\n",
    "  * **Ensembles of Decision Trees: Random Forests**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In order to use several state-of-the-art machine learning methods, we need to be able to understand their core component: decision trees.\n",
    "\n",
    "Decision trees, like logistic and linear regression in lesson 5, have been used commonly for machine learning tasks for several decades. These models are fairly easy to understand and and are the basis of the state-of-the-art model that we will build up to today (Random Forests).\n",
    "\n",
    "Decision trees are especially interesting because they approach the machine learning problem in a way that is quite different from the linear methods we've used so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regression trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to motivate this exploration of individual decision trees by looking at another dataset from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Concrete+Slump+Test).\n",
    "\n",
    "This dataset is a collection of measurements of compositional properties of concrete and their effect on the concrete's durability.\n",
    "\n",
    "The dataset is composed of 7 input measurement features (kilograms per meter cubed of concrete):\n",
    "  * Cement\n",
    "  * Slag\t\n",
    "  * Fly ash\t\n",
    "  * Water\t\n",
    "  * SP\t\n",
    "  * Coarse Aggr.\t\n",
    "  * Fine Aggr.\n",
    "  \n",
    "And 3 output measurements:\n",
    "  * SLUMP (cm)\t\n",
    "  * FLOW (cm)\t\n",
    "  * 28-day Compressive Strength (Mpa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get all of the imports out of the way for the packages we will be working with today:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data handling/prediction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "#visualization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get the data directly off the web this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cement_data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/slump/slump_test.data\",index_col=0)\n",
    "#replace spaces and periods in column names with underscores\n",
    "cement_data.columns = cement_data.columns.str.lower().str.replace(\" \",\"_\").str.replace(\".\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to construct a model that predicts the last column (`compressive_strength`) using the 7 input columns.\n",
    "\n",
    "We are also going to remap the `compressive_strength` column to a few bins so that we can map ranges of output values to colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,y = cement_data.ix[:,:7],cement_data.ix[:,-1]\n",
    "feature_names_cem = X.columns.tolist()\n",
    "target_name = cement_data.columns.tolist()[-1]\n",
    "cement_data[\"compressive_strength_bins\"] = pd.cut(cement_data[target_name],5) #create 5 equally-sized bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our inputs and outputs in a scatter matrix to get a feel for the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(cement_data[feature_names_cem+['compressive_strength_bins']],hue=\"compressive_strength_bins\", palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's investigate one specific pair of columns that look like they are separable in terms of those bins, `cement`, and `fly_ash`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(cement_data, x_vars=['cement'], y_vars=[\"fly_ash\"],hue='compressive_strength_bins',size=6,palette=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build a model using just these two features that can give reasonable predictions on `compressive_strength`. We will build it as follows: \n",
    "  * Segment the whole space of `cement`/`fly_ash` possibilities into distinct regions\n",
    "  * Use the **mean compressive_strength in each region** as the predicted `compressive_strength` for that combination of `cement` to `fly_ash` for future concrete samples.\n",
    "  * Intuitively, we want to **maximize** the similarity (or \"homogeneity\") of `compressive_strength` within a given region, and **minimize** the similarity of `compressive_strength` between regions. So, more similar colors within a region, distinct colors across regions.\n",
    "\n",
    "We will follow some strict rules for segmenting the whole space:\n",
    "  * You can only use **straight lines**\n",
    "  * Your lines must either be **vertical or horizontal**.\n",
    "  * Every line **stops** when it hits an existing line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we build our model, lets generate train/test splits of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.4,random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets build our model and check its test error (using **RMSE**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeRegressor(max_depth=2)\n",
    "decision_tree.fit(X_train,y_train)\n",
    "print(\"Decision Tree RMSE:\",np.sqrt(mean_squared_error(y_test,decision_tree.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize our decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#This allows us to make a decision tree real fast directly in the notebook!\n",
    "dot_data = StringIO()  \n",
    "export_graphviz(decision_tree, out_file=dot_data,  \n",
    "                    feature_names=X_train.columns.tolist(),  \n",
    "                    filled=True, rounded=True,  \n",
    "                    special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Above is the decision tree created by sklearn and here is how you would read it:\n",
    "\n",
    "- $R_1$: concrete with **less than or equal to 160.1 $kg/m^3$ of cement and fly ash less than or equal to 136.5 $kg/m^3$**, is predicted to have a mean compressive_strength of **21.24**\n",
    "- $R_2$: concrete with **less than or equal to 160.1 $kg/m^3$ of cement and fly ash more than 136.5 $kg/m^3$**, is predicted to have a mean compressive_strength of **32.37**\n",
    "- $R_3$: concrete with **more than 160.1 $kg/m^3$ of cement and fly ash less than or equal to 115.5 $kg/m^3$**, is predicted to have a mean compressive_strength of **31.91**\n",
    "- $R_4$: concrete with **more than 160.1 $kg/m^3$ of cement and fly ash more than 115.5 $kg/m^3$**, is predicted to have a mean compressive_strength of **43.63**\n",
    "\n",
    "These regions are used to make predictions on **out-of-sample data**. Thus, there are only 4 possible predictions! (Is this different from how **linear regression** makes predictions?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(decision_tree.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time!!!\n",
    "  * Build a decision tree model to predict slump given the input features.\n",
    "  * What is the test set RMSE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the tree again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first split is **cement <= 160.1**, thus that split goes at the top of the tree. When a splitting rule is **True**, you follow the left branch. When a splitting rule is **False**, you follow the right branch.\n",
    "\n",
    "For concrete samples in the **left branch**, there is a further split on **fly_ash <= 136.5**, dividing the samples into 2 compressive_strength regions: 21.24 and 32.37.\n",
    "\n",
    "For concrete samples in the **right branch**, there is a further split on **fly_ash <= 115.5**, dividing the samples into 2 more compressive_strength regions: 31.91 and 43.63."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**What does this tree tell you about the cement data?**\n",
    "  * Cement is the most important factor determining compressive_strength, with lower cement concentration generally leading to lower compressive strength.\n",
    "  * However, fly_ash is an important secondary characteristic, again showing that lower fly_ash concentration leads to lower compressive_strength."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How does a computer build a regression tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Ideal approach:** Consider every possible partition of the feature space (computationally infeasible)\n",
    "\n",
    "**\"Good enough\" approach:** recursive binary splitting:\n",
    "  * Begin at the top of the tree.\n",
    "  * For **every feature**, examine **every possible cutpoint**, and choose the feature and cutpoint such that the resulting tree has the lowest possible mean squared error (MSE). Make that split.\n",
    "  * Examine the two resulting regions, and again make a **single split** (in one of the regions) to minimize the MSE.\n",
    "  * Keep repeating the previous step until a **stopping criterion** is met:\n",
    "    - maximum tree depth is reached (maximum number of splits required to arrive at a leaf, in our case it was 2)\n",
    "    - minimum number of observations in a leaf (default is 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What happens when we grow a tree too deep?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lets measure testing error as we add depth to our tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depths = range(1,11)\n",
    "train_rmse, test_rmse = [],[]\n",
    "for depth in depths:\n",
    "    decision_tree = DecisionTreeRegressor(max_depth=depth,random_state=10)\n",
    "    decision_tree.fit(X_train,y_train)\n",
    "    curr_train_rmse = np.sqrt(mean_squared_error(y_train,decision_tree.predict(X_train)))\n",
    "    curr_test_rmse = np.sqrt(mean_squared_error(y_test,decision_tree.predict(X_test)))\n",
    "    print(\"Decision Tree Train/Test RMSE:\",curr_train_rmse,\" \",curr_test_rmse)\n",
    "    train_rmse.append(curr_train_rmse)\n",
    "    test_rmse.append(curr_test_rmse)\n",
    "plt.plot(depths,train_rmse,label='train_rmse')\n",
    "plt.plot(depths,test_rmse,label='test_rmse')\n",
    "plt.xlabel(\"maximum tree depth\")\n",
    "plt.ylabel(\"rmse - lower is better\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The **training error** continues to go down as the tree size increases (due to overfitting), but the lowest **test error** occurs for a tree of depth 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time!!!\n",
    "  * Generate a train/test graph like the one above for the slump model you built earlier. Do the curves look similar to those we just generated above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# max_depth=3 was best, so fit a tree using that parameter\n",
    "best_single_tree = DecisionTreeRegressor(max_depth=3, random_state=1)\n",
    "best_single_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Feature Importance\n",
    "\n",
    "The way that we measure the importance of a given feature for a Regression Tree is by computing what is called the [gini importance/coefficient]() of each feature. This measures the normalized total reduction of error when including the given feature.\n",
    "\n",
    "We can extract the feature importances of any trained tree by extracting its `feature_importances_` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature':feature_names_cem, 'importance':best_single_tree.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time !!!\n",
    "  * Examine the feature importances of your slump model. Are they the same as those above? Is the order of the features in terms of their importances the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Understanding a tree diagram\n",
    "\n",
    "Lets take a look at our best decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_data2 = StringIO()  \n",
    "export_graphviz(best_single_tree, out_file=dot_data2,  \n",
    "                    feature_names=X_train.columns.tolist(),  \n",
    "                    filled=True, rounded=True,  \n",
    "                    special_characters=True)  \n",
    "graph_best = pydotplus.graph_from_dot_data(dot_data2.getvalue())  \n",
    "Image(graph_best.create_png())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How to interpret the internal nodes:\n",
    "\n",
    "- **samples:** number of observations in that node before splitting\n",
    "- **mse:** MSE calculated by comparing the actual response values in that node against the mean response value in that node\n",
    "- **rule:** rule used to split that node (go left if true, go right if false)\n",
    "\n",
    "Reading the leaves (bottom parts of the tree):\n",
    "\n",
    "- **samples:** number of observations in that node\n",
    "- **value:** mean response value in that node\n",
    "- **mse:** MSE calculated by comparing the actual response values in that node against \"value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making predictions for the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Question:** Using the tree diagram above, what predictions will the model make for each test sample observation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# use fitted model to make predictions on testing data\n",
    "y_pred = best_single_tree.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# calculate test set RMSE\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Famous Example:** Decision Tree Model to Predict whether Barack Obama or Hillary Clinton will win the Democratic primary in a particular county in 2008:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![Obama-Clinton decision tree](../images/obama_hillary_decision_tree.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Exercise Time!!!\n",
    "\n",
    "Please answer the following questions about the Obama diagram:\n",
    "  * What are the observations? How many observations are there?\n",
    "  - What is the response variable?\n",
    "  - What are the features?\n",
    "  - What is the most predictive feature?\n",
    "  - Why does the tree split on high school graduation rate twice?\n",
    "  - What is the class prediction for the following counties:\n",
    "    * 10% African-American, 50% high school graduation rate, located in the South, high poverty, high population density?\n",
    "    * 18% African-American, 95% high school graduation rate, located in the South, high poverty, high population density?\n",
    "  - What are the predicted probabilities for both of those counties?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Comparing regression trees and classification trees\n",
    "\n",
    "|regression trees|classification trees|\n",
    "|---|---|\n",
    "|predict a continuous response|predict a categorical response|\n",
    "|predict using mean response of each leaf|predict using most commonly occuring class of each leaf|\n",
    "|splits are chosen to minimize MSE|splits are chosen to minimize Gini index (discussed below)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Splitting criteria for classification trees\n",
    "\n",
    "Common options for the splitting criteria when generating classification trees:\n",
    "  * **classification error rate:** fraction of training observations in a region that don't belong to the most common class\n",
    "  - **Gini impurity:** measure of how often a randomly chosen element from the set would be incorrectly labeled if it were  randomly labeled according to the distribution of labels in the subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example of classification error rate\n",
    "\n",
    "Pretend we are predicting whether someone buys an free-standing house or a condo:\n",
    "  - At a particular node, there are **30 observations** (home buyers), of whom **10 bought free-standing homes and 20 bought condos**.\n",
    "  - Since the majority class is **condos**, that's our prediction for all 25 observations, and thus the classification error rate is **10/30 = 33%**.\n",
    "\n",
    "Our goal in making splits is to **reduce the classification error rate**.\n",
    "\n",
    "Let's try splitting on income:\n",
    "  - **Greater than 100k/year:** 8 free-standing and 3 condos, thus the predicted class is free-standing\n",
    "  - **Less than 100k/year:** 2 free-standing and 17 condos, thus the predicted class is condo\n",
    "  - Classification error rate after this split would be **5/30 = ~17%**\n",
    "  \n",
    "Compare that with a split on purchaser-type:\n",
    "  - **married:** 4 free-standing and 6 condos, thus the predicted class is condo\n",
    "  - **unmarried:** 6 free-standing and 14 condos, thus the predicted class is condo\n",
    "  - Classification error rate after this split would be **10/30 = ~33%** (it didnt change!)\n",
    "\n",
    "The decision tree algorithm will try **every possible split across all features**, and choose the split that **reduces the error rate the most.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example of Gini impurity\n",
    "\n",
    "Calculate Gini impurity before making a split:\n",
    "\n",
    "$$1 - \\left(\\frac {freestanding} {Total}\\right)^2 - \\left(\\frac {condo} {Total}\\right)^2 = 1 - \\left(\\frac {10} {30}\\right)^2 - \\left(\\frac {20} {30}\\right)^2 = 0.44$$\n",
    "\n",
    "- The **maximum value** of Gini impurity is 0.5, and occurs when the classes are perfectly balanced in a node.\n",
    "- The **minimum value** of Gini impurity is 0, and occurs when there is only one class represented in a node.\n",
    "- A node with a lower Gini impurity score is said to be more \"pure\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's evaluate the split on **income** using Gini index:\n",
    "$$\\text{more than 100k: } 1 - \\left(\\frac {8} {11}\\right)^2 - \\left(\\frac {3} {11}\\right)^2 = 0.40$$\n",
    "$$\\text{less than 100k: } 1 - \\left(\\frac {2} {19}\\right)^2 - \\left(\\frac {17} {19}\\right)^2 = 0.19$$\n",
    "$$\\text{Weighted Average: }  0.40 \\left(\\frac {11} {30}\\right) + 0.19 \\left(\\frac {19} {30}\\right) = 0.27$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Evaluating the split on **purchaser-type** using Gini impurity:\n",
    "$$\\text{married: } 1 - \\left(\\frac {4} {10}\\right)^2 - \\left(\\frac {6} {10}\\right)^2 = 0.48$$\n",
    "$$\\text{unmarried: } 1 - \\left(\\frac {6} {20}\\right)^2 - \\left(\\frac {14} {20}\\right)^2 = 0.42$$\n",
    "$$\\text{Weighted Average: } 0.48 \\left(\\frac {10} {30}\\right) + 0.42 \\left(\\frac {20} {30}\\right) = 0.44$$\n",
    "\n",
    "The decision tree algorithm will try **every possible split**, and will choose the split that **reduces the Gini impurity (and thus increases the \"node purity\") the most.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Comparing classification error rate and Gini impurity\n",
    "  - Gini impurity is generally preferred because it will make splits that **increase node purity**, even if that split does not change the classification error rate.\n",
    "  - Node purity is important because we're interested in the **class proportions** in each region, since that's how we calculate the **predicted probability** of each class.\n",
    "  - scikit-learn's default splitting criteria for classification trees is Gini impurity.\n",
    "  \n",
    "There is another common splitting criteria called **cross-entropy**. It's numerically very similar to Gini impurity, but significantly slower to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building a classification tree in scikit-learn\n",
    "We'll build a classification tree using some room-occupancy data recently published at the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+).\n",
    "\n",
    "The dataset is a collection of sensor readings within a given room and manually-validated occupancy checks taken from a camera at 1-minute intervals. If the room was occupied, occupancy is 1, otherwise it is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# read in the training data\n",
    "occupancy_data_train = pd.read_csv(\"../data/occupancy_data/datatraining.txt\",index_col=0)\n",
    "occupancy_data_train.date = pd.to_datetime(occupancy_data_train.date) # convert the date column to an actual pandas datetime object\n",
    "occupancy_data_train.columns = occupancy_data_train.columns.str.lower() #clean up column names by lowercasing them\n",
    "print(occupancy_data_train.head())\n",
    "\n",
    "# read in the testing data\n",
    "occupancy_data_test = pd.read_csv(\"../data/occupancy_data/datatest.txt\",index_col=0)\n",
    "occupancy_data_test.date = pd.to_datetime(occupancy_data_test.date) # convert the date column to an actual pandas datetime object\n",
    "occupancy_data_test.columns = occupancy_data_test.columns.str.lower() #clean up column names by lowercasing them\n",
    "print(occupancy_data_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# define X and y - dont use date column as a feature\n",
    "feature_cols_occ = [\"temperature\",\"humidity\",\"light\",\"co2\",\"humidityratio\"]\n",
    "X_occ_train = occupancy_data_train[feature_cols_occ]\n",
    "y_occ_train = occupancy_data_train.occupancy\n",
    "X_occ_test = occupancy_data_test[feature_cols_occ]\n",
    "y_occ_test = occupancy_data_test.occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# fit a classification tree with max_depth=3 on all of the training data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "occupancy_tree = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "occupancy_tree.fit(X_occ_train, y_occ_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#This allows us to make a decision tree real fast directly in the notebook!\n",
    "dot_data_occ = StringIO()  \n",
    "export_graphviz(occupancy_tree, out_file=dot_data_occ,  \n",
    "                    feature_names=X_occ_train.columns.tolist(),  \n",
    "                    filled=True, rounded=True,  \n",
    "                    special_characters=True)  \n",
    "occ_graph = pydotplus.graph_from_dot_data(dot_data_occ.getvalue())  \n",
    "Image(occ_graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time!!!\n",
    "  * Evaluate the model using `accuracy_score` on the testing data.\n",
    "  * Is the accuracy score above chance? What is chance accuracy here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now let's generate our feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# compute the feature importances\n",
    "pd.DataFrame({'feature':feature_cols_occ, 'importance':occupancy_tree.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing decision trees with other models\n",
    "**Advantages of decision trees:**\n",
    "  * Can be used for regression or classification\n",
    "  - Can be displayed graphically\n",
    "  - Highly interpretable\n",
    "  - Can be specified as a series of rules, and more closely approximate human decision-making than other models\n",
    "  - Prediction is fast\n",
    "  - Features don't need scaling\n",
    "  - Automatically learns feature interactions (they are non-linear models)\n",
    "  - Tend to ignore irrelevant features (especially when there are lots of features)\n",
    "  - Because decision trees are non-linear models they will outperform linear models if the relationship between features and response is highly non-linear\n",
    "**Disadvantages of decision trees:**\n",
    "  - Performance is (generally) not competitive with the best supervised learning methods\n",
    "  - Can easily overfit the training data (tuning is required)\n",
    "  - Small variations in the data can result in a completely different tree (they are high variance models)\n",
    "  - Recursive binary splitting makes \"locally optimal\" decisions that may not result in a globally optimal tree\n",
    "  - Don't tend to work well if the classes are highly unbalanced\n",
    "  - Don't tend to work well with very small datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles\n",
    "\n",
    "Consider:\n",
    "* instead of building a single model to solve a classification problem, \n",
    "* you created **five independent models**, \n",
    "* If you combined these models into an \"ensemble\" and used their **majority vote** as a prediction, \n",
    "* and each model was **correct about 70% of the time**. \n",
    "* *how often would the ensemble be correct?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(1234)\n",
    "\n",
    "# generate 5000 random numbers (between 0 and 1) for each model, representing 5000 observations\n",
    "mod1 = np.random.rand(5000)\n",
    "mod2 = np.random.rand(5000)\n",
    "mod3 = np.random.rand(5000)\n",
    "mod4 = np.random.rand(5000)\n",
    "mod5 = np.random.rand(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# each model independently predicts 1 (the \"correct response\") if random number was at least 0.3\n",
    "preds1 = np.where(mod1 > 0.3, 1, 0)\n",
    "preds2 = np.where(mod2 > 0.3, 1, 0)\n",
    "preds3 = np.where(mod3 > 0.3, 1, 0)\n",
    "preds4 = np.where(mod4 > 0.3, 1, 0)\n",
    "preds5 = np.where(mod5 > 0.3, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the first 20 predictions from each model\n",
    "print(preds1[:20])\n",
    "print(preds2[:20])\n",
    "print(preds3[:20])\n",
    "print(preds4[:20])\n",
    "print(preds5[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# average the predictions and then round to 0 or 1\n",
    "ensemble_preds = np.round((preds1 + preds2 + preds3 + preds4 + preds5)/5.0).astype(int)\n",
    "\n",
    "# print the ensemble's first 20 predictions\n",
    "print(ensemble_preds[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how accurate was each individual model?\n",
    "print(preds1.mean())\n",
    "print(preds2.mean())\n",
    "print(preds3.mean())\n",
    "print(preds4.mean())\n",
    "print(preds5.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how accurate was the ensemble?\n",
    "print(ensemble_preds.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensemble learning (or \"ensembling\")** is the process of combining several predictive models in order to produce a combined model that is more accurate than any individual model.\n",
    "\n",
    "- **Regression:** take the average of the predictions\n",
    "- **Classification:** take a vote and use the most common prediction, or take the average of the predicted probabilities\n",
    "\n",
    "For ensembling to work well, the models must have the following characteristics:\n",
    "\n",
    "- **Accurate:** they outperform random guessing\n",
    "- **Independent:** their predictions are generated using different processes\n",
    "\n",
    "**The big idea:** If you have a collection of individually imperfect (and independent) models, the \"one-off\" mistakes made by each model are probably not going to be made by the rest of the models, and thus the mistakes will be discarded when averaging the models.\n",
    "\n",
    "**Note:** As you add more models to the voting process, the probability of error decreases, which is known as [Condorcet's Jury Theorem](http://en.wikipedia.org/wiki/Condorcet%27s_jury_theorem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling methods\n",
    "\n",
    "There are two basic methods for ensembling:\n",
    "- Use a model that ensembles for you (What we will do when we use Random Forests)\n",
    "- Manually ensemble your individual models\n",
    "\n",
    "What makes a good \"manual ensemble\"?\n",
    "- Different types of models\n",
    "- Different combinations of features\n",
    "- Different tuning parameters\n",
    "\n",
    "Here's an example pipeline that uses ensembling (this is an extreme example):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ensemble Kaggle Example](../images/crazy_ensemble_kaggle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "The primary weakness of **decision trees** is that they don't tend to have the best predictive accuracy. This is partially due to **high variance**, meaning that different splits in the training data can lead to very different trees.\n",
    "\n",
    "**Bagging** is a general purpose procedure for reducing the variance of a machine learning method, but is particularly useful for decision trees. Bagging is short for **bootstrap aggregation**, meaning the aggregation of bootstrap samples.\n",
    "\n",
    "What is a **bootstrap sample**? A random sample with replacement. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(20)\n",
    "\n",
    "# create an array of 1 through 30\n",
    "nums = np.arange(1, 30)\n",
    "print(\"The original array:\",nums)\n",
    "\n",
    "# sample that array 15 times with replacement\n",
    "print(\"The 15 samples:\",np.random.choice(a=nums, size=15, replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here's how bagging works for decision trees:**\n",
    "  1. Grow *b* trees using *b* bootstrap samples from the training data.\n",
    "  2. Train each tree on its bootstrap sample and make predictions.\n",
    "  3. Combine the predictions:\n",
    "    * Average the predictions for **regression trees**\n",
    "    - Take a majority vote for **classification trees**\n",
    "    \n",
    "Keep in mind:\n",
    "  - **Each bootstrap sample** should be the same size as the original training set.\n",
    "  - **_b_** should be a large enough value that the error seems to have \"stabilized\".\n",
    "  - The trees are **grown deep** so that they have low bias/high variance.\n",
    "  \n",
    "Bagging increases predictive accuracy by **reducing the variance**, similar to how cross-validation reduces the variance associated with train/test split (for estimating out-of-sample error) by splitting many times and averaging the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually implementing bagged regression trees (with *b*=10)\n",
    "\n",
    "We are going to implement bagging using our original concrete slump test dataset.\n",
    "\n",
    "Let's generate our training and testing data, perform bagging on the training data, and compare the resulting RMSE on the test set to our original RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(1234)\n",
    "\n",
    "# create ten bootstrap samples (will be used to select rows from the DataFrame)\n",
    "\n",
    "samples = [np.random.choice(a=X_train.shape[0], size=X_train.shape[0], replace=True) for _ in range(1, 11)]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.iloc[samples[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grow each tree deep\n",
    "treereg = DecisionTreeRegressor(max_depth=None, random_state=123)\n",
    "\n",
    "# list for storing predicted compressive strength from each tree\n",
    "predictions = []\n",
    "\n",
    "# define testing data\n",
    "X_test_boot = X_test\n",
    "y_test_boot = y_test\n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for sample in samples:\n",
    "    X_train_boot = X_train.iloc[sample, :]\n",
    "    y_train_boot = y_train.iloc[sample]\n",
    "    treereg.fit(X_train_boot, y_train_boot)\n",
    "    y_pred_boot = treereg.predict(X_test_boot)\n",
    "    predictions.append(y_pred_boot)\n",
    "\n",
    "# convert predictions from list to NumPy array\n",
    "predictions = np.array(predictions)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# average the predictions\n",
    "np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate RMSE for bagged regression trees\n",
    "y_pred_boot = np.mean(predictions, axis=0)\n",
    "print(\"Bagged RMSE:\",np.sqrt(mean_squared_error(y_test_boot, y_pred_boot)))\n",
    "\n",
    "#calculate RMSE for single decision tree with same exact parameters as each tree in the bag\n",
    "single_tree = DecisionTreeRegressor(max_depth=None, random_state=123)\n",
    "single_tree.fit(X_train,y_train)\n",
    "y_pred_single = single_tree.predict(X_test)\n",
    "print(\"Single Tree RMSE:\",np.sqrt(mean_squared_error(y_test_boot, y_pred_single)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool, huh?\n",
    "\n",
    "Now let's implement this with much less code using scikit-learn (and lets make 500 trees, instead of 10):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bagreg = BaggingRegressor(DecisionTreeRegressor(), n_estimators=500, bootstrap=True, oob_score=True, random_state=1234)\n",
    "# fit and predict\n",
    "bagreg.fit(X_train, y_train)\n",
    "y_pred_bag = bagreg.predict(X_test)\n",
    "y_pred_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "print(\"Bagged RMSE with 500 trees:\",np.sqrt(mean_squared_error(y_test, y_pred_bag)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating out-of-sample error (no cross-validation needed!)\n",
    "\n",
    "For bagged models, out-of-sample error can be estimated without using **train/test split** or **cross-validation**!\n",
    "\n",
    "On average, each bagged tree uses about **two-thirds** of the observations. For each tree, the **remaining observations** are called \"out-of-bag\" observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show the first bootstrap sample\n",
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show the \"in-bag\" observations for each sample\n",
    "for sample in samples:\n",
    "    print(set(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show the \"out-of-bag\" observations for each sample\n",
    "all_samples = range(61) #the the sampled data was simply the 61 rows of the training dataset \n",
    "for sample in samples:\n",
    "    sample_difference = set(all_samples) - set(sample) #need to cast both samples into a set, take their set difference\n",
    "    print(\"Samples not in bootstrapped set:\",sorted(sample_difference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to calculate **\"out-of-bag error\":**\n",
    "  1. For every observation in the training data, predict its response value using **only** the trees in which that observation was out-of-bag. Average those predictions (for regression) or take a majority vote (for classification).\n",
    "  2. Compare all predictions to the actual response values in order to compute the out-of-bag error.\n",
    "\n",
    "When *b* is sufficiently large, the **out-of-bag error** is an accurate estimate of **out-of-sample error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute the out-of-bag R-squared score (not MSE, unfortunately!) for b=500\n",
    "bagreg.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating feature importance across many trees\n",
    "\n",
    "Bagging increases **predictive accuracy**, but decreases **model interpretability** because it's no longer possible to visualize the tree to understand the importance of each feature.\n",
    "\n",
    "However, we can still obtain an overall summary of **feature importance** from bagged models:\n",
    "  * **Bagged regression trees:** calculate the total amount that **MSE** is decreased due to splits over a given feature, average over all trees\n",
    "  - **Bagged classification trees:** calculate the total amount that **Gini index** is decreased due to splits over a given feature, average over all trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests are even better than Bagged Trees\n",
    "\n",
    "Random Forests are a **slight variation of bagged trees** that have even better performance:\n",
    "  - Just like bagging, we create an ensemble of decision trees using bootstrapped samples of the training set.\n",
    "  - However, when building each tree, each time a split is considered, a **random sample of _m_ features** is chosen as split candidates from the **full set of _p_ features**. The split is only allowed to use **one of those _m_ features**.\n",
    "    - A new random sample of features is chosen for **every single tree at every single split**.\n",
    "    - For **classification**, *m* is typically chosen to be the square root of *p* (the total number of features).\n",
    "    - For **regression**, *m* is typically chosen to be somewhere between *p*/3 and *p*.\n",
    "    \n",
    "Why do all of this fancy stuff?\n",
    "  - Lets suppose there is **one very predictive feature** in the data set. When using bagged trees, most of the trees will use that feature at the top split, resulting in an ensemble of trees that are **highly correlated**.\n",
    "  - Averaging highly correlated quantities does not significantly reduce variance (which is the entire goal of bagging).\n",
    "  - By randomly leaving out candidate features from each split, **Random Forests \"decorrelate\" the trees**, such that the averaging process reduces the variance of the resulting model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests vs. Bagged Trees vs. Single Tree\n",
    "\n",
    "Let's look back at the cement slump test data and compare the test data performance across the 3 methods we've talked about so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Our data\n",
    "X_cem = cement_data[feature_names_cem]\n",
    "y_cem = cement_data[target_name]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_cem,y_cem,test_size=0.4)\n",
    "#Single Tree\n",
    "best_single_tree = DecisionTreeRegressor(max_depth=3, random_state=123)\n",
    "best_single_tree.fit(X_train, y_train)\n",
    "y_pred_single = best_single_tree.predict(X_test)\n",
    "\n",
    "#Bag of 500 trees\n",
    "bagreg = BaggingRegressor(DecisionTreeRegressor(), n_estimators=500, bootstrap=True, oob_score=True, random_state=123)\n",
    "bagreg.fit(X_train, y_train)\n",
    "y_pred_bag = bagreg.predict(X_test)\n",
    "\n",
    "#Random forest of 500 trees\n",
    "rf = RandomForestRegressor(n_estimators=500, bootstrap=True, oob_score=True, random_state=123)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Single Tree RMSE:\",np.sqrt(mean_squared_error(y_test,y_pred_single)))\n",
    "print(\"Bag RMSE:\",np.sqrt(mean_squared_error(y_test,y_pred_bag)))\n",
    "print(\"Random Forest RMSE:\",np.sqrt(mean_squared_error(y_test,y_pred_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Random Forests: # of trees and maximum features used\n",
    "\n",
    "2 important parameters that should be tuned when creating a random forest model are:\n",
    "  * The number of trees to grow (called **n_estimators** in scikit-learn)\n",
    "  * The number of features that should be considered at each split (called **max_features** in scikit-learn)\n",
    "\n",
    "Lets tune each feature separately below, starting with **n_estimators**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of values to try for n_estimators\n",
    "estimator_range = range(20, 500, 20)\n",
    "\n",
    "# list to store the average RMSE for each value of n_estimators\n",
    "RMSE_scores = []\n",
    "\n",
    "for estimator in estimator_range:\n",
    "    rfreg = RandomForestRegressor(n_estimators=estimator, bootstrap=True, oob_score=True, random_state=1)\n",
    "    rfreg.fit(X_train,y_train)\n",
    "    preds = rfreg.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
    "    RMSE_scores.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot n_estimators (x-axis) versus RMSE (y-axis)\n",
    "plt.plot(estimator_range, RMSE_scores)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**n_estimators** should be a large enough value such that the error seems to be stable.\n",
    "\n",
    "Now lets do the same thing with **max_features**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of values to try for max_features\n",
    "feature_range = range(1, len(feature_names_cem)+1)\n",
    "\n",
    "# list to store the average RMSE for each value of max_features\n",
    "RMSE_scores = []\n",
    "\n",
    "for feature in feature_range:\n",
    "    rfreg = RandomForestRegressor(n_estimators=220, bootstrap=True, \n",
    "                                  oob_score=True, max_features=feature, random_state=1234)\n",
    "    rfreg.fit(X_train,y_train)\n",
    "    preds = rfreg.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
    "    RMSE_scores.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot n_estimators (x-axis) versus RMSE (y-axis)\n",
    "plt.plot(feature_range, RMSE_scores)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like using all of the features is best. Let's build the optimal classifier we can given what we know and see the overall performance on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfreg_best = RandomForestRegressor(n_estimators=500, max_features=7, bootstrap=True, oob_score=True, random_state=123)\n",
    "rfreg_best.fit(X_train,y_train)\n",
    "preds = rfreg_best.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
    "print(\"Best RMSE:\",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lets take a look at the feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute feature importances\n",
    "pd.DataFrame({'feature':feature_names_cem, 'importance':rfreg_best.feature_importances_}).sort_values(by='importance',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time\n",
    "  * Build a Random Forest Regression Model to predict Flow using the concrete slump test dataset.\n",
    "    * What is the test-set RMSE?\n",
    "    * What are the feature importances? Are they in a different ranked order than those for the compressive_strength model?\n",
    "  * Build a Random Forest Classification Model on the occupancy data, using the `datatraining.txt` data\n",
    "    * What is the test-set Accuracy when testing on `datatest.txt`? When testing on `datatest2.txt`?\n",
    "    * What are the feature importances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Random Forests with Single Decision Trees\n",
    "\n",
    "**Advantages of Random Forests:**\n",
    "  * Performance is competitive with the best supervised learning methods\n",
    "  - Provides a more reliable estimate of feature importance\n",
    "  - Allows you to estimate out-of-sample error without using train/test split or cross-validation\n",
    "\n",
    "**Disadvantages of Random Forests:**\n",
    "  - Less interpretable\n",
    "  - Slower to train\n",
    "  - Slower to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Ensembles to Individual Models\n",
    "**Advantages of ensembling:**\n",
    "  - Increases predictive accuracy\n",
    "  - Easy to get started (especially with Random Forests)\n",
    "\n",
    "**Disadvantages of ensembling:**\n",
    "  - Decreases interpretability\n",
    "  - Takes longer to train/predict\n",
    "  - More complex to automate and maintain\n",
    "  - Sometimes marginal gains in accuracy may not be worth the added complexity"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
