{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 5 Agenda:\n",
    "  * **Brief introduction to machine learning**\n",
    "  * **Linear Regression**\n",
    "  * **Model Evaluation using Train/Test split**\n",
    "  * **Logistic Regression** (next notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, we've just been exploring data. Generating statistical summaries of different rows and columns in our datasets is useful and helps us answer certain kinds of questions about historical trends we see, but it gets us nowhere when we want to **predict** something useful using our data in the future. We've been doing description, but now we are going to move on to prediction.\n",
    "\n",
    "Before we get started with actual machine learning, we need to understand some of the language used to describe the classes of problems that machine learning can be used to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Major types of machine learning:\n",
    "|             | **Supervised**     | **Unsupervised**      |\n",
    "|-------------|----------------|-------------------|\n",
    "| **Continuous**  | Regression     | Clustering, PCA   |\n",
    "| **Categorical** | Classification | Association Rules |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the machine learning universe the most common tasks are:\n",
    "  * **Supervised learning problems** involve constructing an accurate model that can **predict some kind of an outcome when past data has labels for those outcomes** [supervised learning wikipedia page](https://en.wikipedia.org/wiki/Supervised_learning)\n",
    "  * **Unsupervised learning problems** involve constructing models where labels on historical data are unavailable.[unsupervised learning wikipedia page](https://en.wikipedia.org/wiki/Unsupervised_learning)\n",
    "\n",
    "Today we will be talking about two **supervised learning** approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the universe of supervised machine learning problems, there exist two distinct classes of problems.\n",
    "\n",
    "These classes are based completely on the kind of value or values we are trying to predict:\n",
    "  * A **classification problem** is a **supervised learning problem** where the objective is to learn to predict a categorical value.\n",
    "  * A **regression problem** is a **supervised learning problem** where the objective is to learn to predict a continuous value.\n",
    "\n",
    "We will start with learning about **linear regression**, a machine learning modeling approach that has classically been used for **regression** problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression has been used extensively for a whole myriad of distinct regression problems in the past. \n",
    "\n",
    "Linear regression is the first model that we will learn because:\n",
    "  * it is widely used\n",
    "  * is very quick and easy to set up\n",
    "  * a trained linear regression model is very easy to understand.\n",
    "  \n",
    "Really, it's critical to understand linear regression because it is the foundational machine learning modeling approach on which many other methods are based.\n",
    "\n",
    "By the end of this notebook you will:\n",
    "\n",
    "- Have a working conceptual understanding of linear regression and become familiar with some key terminology\n",
    "- Be able to apply linear regression to a machine learning problem using scikit-learn\n",
    "- Be able to interpret linear regression model coefficients\n",
    "- Be able to apply three different evaluation metrics for regression\n",
    "- Be able to use train/test split to estimate model performance on unseen data \n",
    "- Be able to articulate the strengths and weaknesses of linear regression\n",
    "\n",
    "We will be using the default machine learning library in **Python**, [scikit-learn](http://scikit-learn.org/stable/), which has all of the functionality we will need to explore linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by importing all of the functionality we will need for this lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python 2 and 3 compatibility\n",
    "from __future__ import print_function\n",
    "\n",
    "# Data handling/modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Visualization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear regression on one variable (simple linear regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression on one variable (simple linear regression) is an approach for predicting a **continuous response** using a **single feature**. We assume our data can be represented with a function that looks like this:\n",
    "\n",
    "$y_i = \\beta_0 + \\beta_1x_i + \\epsilon_i$\n",
    "\n",
    "- $y_i$ is the response of a single observation\n",
    "- $x$ is one value of the feature\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for x\n",
    "- $\\epsilon$ is the error\n",
    "\n",
    "$\\beta_0$ and $\\beta_1$ are called the **model coefficients**. They are the values we are going to estimate, or learn, from our data to find the best fit model.\n",
    "\n",
    "$\\beta_0$ is also called the bias (its an offset), and is equivalent to the y-intercept of the model\n",
    "\n",
    "(remember $y = mx + b$ from school? $m=\\beta_1$ and $b=\\beta_0$ here).\n",
    "\n",
    "So, **our model must \"learn\" the values of these coefficients, and once we've learned these coefficients, we can use the model to predict mpg.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine how this happens by looking at some simple data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height = np.array([64, 69, 72, 73, 74, 76])\n",
    "shoe = np.array([8,  9, 10, 11, 12, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lineX = [7, 13]\n",
    "lineY = [62, 78]\n",
    "plt.plot(lineX, lineY, 'r')\n",
    "plt.plot(shoe, height, 'bo')\n",
    "plt.xlabel(\"Shoe Size\")\n",
    "plt.ylabel(\"Height\")\n",
    "plt.xlim(7.5,13.5)\n",
    "plt.ylim(62,78)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly this is not a perfect fit - and in practice it never will be. But we need a way to determine which line is best. We can do this be calculating the sum of the squared errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upper_error = [0.75,0,0,0,1.35,2]\n",
    "lower_error = [0,1.5,2,.35,0,0]\n",
    "asymmetric_error = [lower_error, upper_error]\n",
    "plt.plot(lineX, lineY, 'r')\n",
    "plt.errorbar(shoe, height, yerr=asymmetric_error, fmt='bo')\n",
    "plt.xlabel(\"Shoe Size\")\n",
    "plt.ylabel(\"Height\")\n",
    "plt.xlim(9.5,12.5)\n",
    "plt.ylim(69,76)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating (\"learning\") simple linear regression model coefficients\n",
    "\n",
    "Coefficients are estimated during the model fitting process using the **least squares criterion**.\n",
    "\n",
    "We will find the line which minimizes the **sum of squared errors**:\n",
    "\n",
    "$\\textrm{Total error} = \\sum\\limits_{\\textrm{all points}} (y_{actual} - y_{prediction})^2 = \\sum\\limits_{\\textrm{i}} (y_{i} - (\\beta_0 + \\beta_1x_i))^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now a calculus problem - finding the values that minimize an equation.\n",
    "\n",
    "One way to do this is called [Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the car dataset\n",
    "\n",
    "Now that we've got all of the libraries we need, lets get some data to work with.\n",
    "\n",
    "This data comes from the famous [UC Irvine Machine Learning Repository](http://archive.ics.uci.edu/ml/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data into a DataFrame\n",
    "data = pd.read_csv(\"../data/auto_mpg_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in this dataset, called an **observation** represents **one car model** (392 models in the dataset).\n",
    "\n",
    "Our goal will be to try to build a model that, when given some features describing a car model, can accurately predict the expected mpg of the vehicle.\n",
    "\n",
    "What are the **features**? (What data can we use to generate our prediction?)\n",
    "\n",
    "- **cylinders:** The number of cylinders in the model (numeric discrete)\n",
    "- **displacement:** [engine displacement](https://en.wikipedia.org/wiki/Engine_displacement) (continuous)\n",
    "- **horsepower:** horsepower of the model (continuous)\n",
    "- **weight:** total weight of the car (continuous)\n",
    "- **acceleration:** The vehicle acceleration rate of the model (continuous)\n",
    "\n",
    "What is the **response**? (What are we trying to predict?)\n",
    "\n",
    "- **mpg:** approximate miles per gallon of the model (continuous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You should immediately have questions about the data\n",
    "\n",
    "1. Is there a relationship between any of the properties of the car models in our dataset?\n",
    "2. How strong is that relationship?\n",
    "3. Do any of the properties of the cars seem to relate to its mpg?\n",
    "4. What is the effect of each car attribute on mpg?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize relationships among the features and the outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quickest, most effective way you can quickly see if any of the features correlate with your response is to use a **scatter plot** to visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data, x_vars=['cylinders','displacement','horsepower'], y_vars='mpg', size=6, aspect=0.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just tried to see if there was any relationship between cylinders/displacement/horsepower and mpg for each feature by itself. Looks like all 3 are negatively correlated with mpg.\n",
    "\n",
    "If we wanted to see what the simple linear regression on each feature by itself looks like (we will get to what that actually is shortly), we can plot a regression line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data, x_vars=['cylinders','displacement','horsepower'], y_vars='mpg', size=6, aspect=0.8, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a **correlation matrix** to compute the pairwise correlations between all numeric variables.\n",
    "\n",
    "Let's first just compute and inspect the correlation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto_correlations = data.corr()\n",
    "auto_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(auto_correlations);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, enough exploring, lets get to building some models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `scikit-learn` for the first time here and work through the process of training a scikit-learn model.\n",
    "\n",
    "Here's a link to the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These were already imported above, but I'm repeating them here for clarity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# create X and y\n",
    "feature_cols = ['displacement']\n",
    "X = data[feature_cols]\n",
    "y = data.mpg\n",
    "\n",
    "# instantiate and fit\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "# print the coefficients\n",
    "print(\"The y intercept:\", linreg.intercept_)\n",
    "print(\"The single coefficient:\", linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so what did we do here?\n",
    "\n",
    "1. We created a matrix `X` that held our features and a vector `y` that held our response variable across all the observations in our dataset.\n",
    "2. We then instantiated (created) a `LinearRegression` model. \n",
    "3. However, that model was initially untrained (didn't have our data fit to it). In order to do that, we had to call the `fit` method of the `LinearRegression` object `linreg` we had just created using our features `X` and outcome `y` as input parameters.\n",
    "4. After we called `fit` on our model, the simple linear regression model was fit. Following this, we inspected our two coefficients.\n",
    "  \n",
    "Just to hammer all of this home, let's take a look at what this \"visually\" looks like using `pairplot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data,x_vars=['displacement'],y_vars='mpg',size=7, aspect=1.2,kind='reg')\n",
    "sns.plt.xlim(0,)\n",
    "sns.plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to interpret model coefficients\n",
    "\n",
    "So, now that we've got a fitted linear regression model, how do we interpret the acceleration coefficient ($\\beta_1$)?\n",
    "\n",
    "A \"unit\" increase in displacement is **associated with** a -0.06 change in mpg.\n",
    "\n",
    "Keep in mind that this is not a statement of **causation**, but of **correlation**.\n",
    "\n",
    "What would the coefficient look like if an increase in displacement was associated with a **decrease** in mpg?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model for prediction\n",
    "\n",
    "Let's say that there was a new car model that had a displacement of 250. What would we predict the mpg of that model to be?\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x$$\n",
    "$$y = 35.12 - 0.06 \\times 250$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manually calculate it and confirm with the plot we created above. Does this value make sense?\n",
    "35.12 - 0.06 * 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict for a new observation, here where the displacement is 30\n",
    "linreg.predict(250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we would predict mpg of **~20.1** for a model with a displacement of 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the scale of the features matter?\n",
    "\n",
    "Let's say that displacement was measured in cubic milimeters, rather than cubic centimeters. How would that affect the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['displacement_cml'] = data.displacement * 1000\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['displacement_cml']\n",
    "X_2 = data[feature_cols]\n",
    "y = data.mpg\n",
    "\n",
    "# instantiate and fit\n",
    "linreg2 = LinearRegression()\n",
    "linreg2.fit(X_2, y)\n",
    "\n",
    "# print the coefficients\n",
    "print(linreg2.intercept_)\n",
    "print(linreg2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret the new displacement_cml coefficient ($\\beta_1$)?\n",
    "\n",
    "- A \"unit\" increase in displacement (in cubic mm) is **associated with** a 6e-5 decrease in mpg.\n",
    "- Which is equivalent to what we found in the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict for a new observation\n",
    "linreg2.predict(250*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what does this mean?\n",
    "\n",
    "**The scale of the features is irrelevant for linear regression models, since it will only affect the scale of the coefficients, and we simply change our _interpretation_ of the coefficients**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well does the model fit the data?\n",
    "\n",
    "R-squared is a very common way to evaluate the overall fit of a linear model.\n",
    "R-squared is defined as the **proportion of variance explained**, meaning the proportion of variance in the observed data that is explained by the model. This value is between 0 and 1, where the higher the value is, the better the model is.\n",
    "\n",
    "We can get r-squared from our model by getting the pearson-r coefficient from a fancy jointplot and squaring it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot('displacement', 'mpg',data, kind=\"reg\")\n",
    "print(\"R^2:\", stats.pearsonr(X.values.flatten(),y.values)[0]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm the R-squared value for our simple linear model using `scikit-learn's` prebuilt R-squared scorer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = linreg.predict(X)\n",
    "metrics.r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things to keep in mind when using R-squared:\n",
    "  * The threshold for a **\"good\" R-squared value** is highly dependent on the particular domain.\n",
    "  * R-squared is more useful as a tool for **comparing models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "\n",
    "Simple linear regression can easily be extended to include multiple features, which is called **multiple linear regression**:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$\n",
    "\n",
    "Each $x$ represents a different feature, and each feature has its own coefficient:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 \\times acceleration + \\beta_2 \\times displacement + \\beta_3 \\times horsepower$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create X and y except now with more columns in X\n",
    "mult_feature_cols = ['acceleration', 'displacement', 'horsepower']\n",
    "X_mult = data[mult_feature_cols]\n",
    "y_mult = data.mpg\n",
    "\n",
    "# instantiate and fit like last time\n",
    "multiple_linreg = LinearRegression()\n",
    "multiple_linreg.fit(X_mult, y_mult)\n",
    "\n",
    "coeffs = multiple_linreg.coef_\n",
    "intercept =  multiple_linreg.intercept_\n",
    "# print the coefficients like last time\n",
    "print(intercept)\n",
    "print(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pair the feature names with the coefficients\n",
    "zip(mult_feature_cols, multiple_linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model we can interpret the coefficients as follows:\n",
    "\n",
    "  * For a fixed amount of acceleration and engine displacement, an increase of 1 unit in **horsepower** is associated with a **decrease in mpg of the car of ~.09**.\n",
    "  * For a fixed amount of displacement and horsepower, an increase of 1 m/s^2 in **acceleration** is associated with a **decrease in mpg of ~.41**.\n",
    "  * For a fixed amount of acceleration and horsepower, an increase of 1 in **displacement** is associated with an **decrease in mpg of ~.04**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this model have a better R<sup>2</sup> value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_mult_pred = multiple_linreg.predict(X_mult)\n",
    "metrics.r2_score(y_mult, y_mult_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time\n",
    "* Create the multiple regression when you use every variable except for mpg to predict mpg.\n",
    "* What is this new r^2 value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics for regression problems\n",
    "\n",
    "In order to evaluate how good a given regression model is, we need evaluation metrics designed for comparing **continuous values**. We will cover 3 common evaluation metrics for regression models here.\n",
    "\n",
    "Let's create some example numeric predictions, and calculate the three most common evaluation metrics for regression problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define true and predicted response values\n",
    "fake_y_true = [101, 40, 30, 20]\n",
    "fake_y_pred = [90, 50, 50, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors/residuals:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"MAE for fake data:\",metrics.mean_absolute_error(fake_y_true, fake_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"MSE for fake data:\",metrics.mean_squared_error(fake_y_true,fake_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"RMSE for fake data:\",np.sqrt(metrics.mean_squared_error(fake_y_true, fake_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare these metrics in terms of their usefulness/interpretability:\n",
    "  * **MAE** is the easiest to understand, because it's the average error.\n",
    "  * **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
    "  * **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "All of these are what are called **loss functions**, because we want to minimize the **loss** (from getting stuff wrong)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time\n",
    "  * Calculate the MAE/MSE/RMSE of the simple linear regression model\n",
    "  * Calculate the MAE/MSE/RMSE of the 3 feature multiple regression model\n",
    "  * Calculate the MAE/MSE/RMSE of the model using all of the features\n",
    "  * What do you notice about all of these metrics as you keep adding features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using train/test split for model evaluation\n",
    "\n",
    "How do we know that our model will perform well on new data?\n",
    "\n",
    "Sure, we may know that our model has really low RMSE on all of the data we have on hand, but can we be sure that it will be exactly the same when we try to use our model in the real world?\n",
    "\n",
    "One way we can get an estimate of how the model will perform \"in the wild\" is by building the model on a portion of our data, and then testing it on the remainder that we have.\n",
    "\n",
    "So, we **act like we have one set of data for model building, and keep a separate set of data and treat it as if it were new.** We then test our model on this \"new\" data, and, **as long as the test data was taken in an unbiased way**, we can assume that the **loss** on the test data gives us a pretty good idea of what the error \"in the wild\" will be.\n",
    "\n",
    "So, let's try to use train/test split to estimate the model's accuracy on unseen data.\n",
    "\n",
    "The basic approach would be to randomly select a fraction of the data (>50% usually) for training, and the remainder (100-training%) for testing. We will use scikit-learn's `train_test_split` function to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_mult_train, X_mult_test, y_mult_train, y_mult_test = train_test_split(X_mult, y_mult, test_size=0.3, random_state=1)\n",
    "print(\"training data size:\",X_mult_train.shape)\n",
    "print(\"testing data size:\",X_mult_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we simply train on `X_mult_train` and `y_mult_train` and then generate predictions and evaluation metrics on `X_mult_test` and `y_mult_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train on training set\n",
    "mult_linreg2 = LinearRegression()\n",
    "mult_linreg2.fit(X_mult_train, y_mult_train)\n",
    "\n",
    "#generate predictions on training set and evaluate\n",
    "y_mult_pred_train = mult_linreg2.predict(X_mult_train)\n",
    "print(\"Training set RMSE:\",np.sqrt(metrics.mean_squared_error(y_mult_train, y_mult_pred_train)))\n",
    "\n",
    "#generate predictions on test set and evaluate\n",
    "y_mult_pred_test = mult_linreg2.predict(X_mult_test)\n",
    "print(\"Test set RMSE:\",np.sqrt(metrics.mean_squared_error(y_mult_test, y_mult_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the test set error is greater than the training set error. This should almost always be the case (why?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time\n",
    "  * Get MAE/MSE/RMSE training and test set predictions on the full linear regression model (using all features) with a test set of 30% of the data\n",
    "  * Get MAE/MSE/RMSE training and test set predictions on the full linear regression model (using all features) with a test set of 20% of the data\n",
    "  * Get MAE/MSE/RMSE training and test set predictions on the full linear regression model (using all features) with a test set of 10% of the data\n",
    "  * Anything you notice about the test set error metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting and Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we know when a model will perform well on new data? What is happening when a model doesn't generalize well?\n",
    "\n",
    "Let's create a new data set with many features.\n",
    "\n",
    "Here are a few new sklearn features:\n",
    "\n",
    "[PolynomialFeatures](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures) takes feature columns and generates new columns that are all features multiplied together up to the degree you specify. For 1 feature is generates x, x<sup>2</sup>, x<sup>3</sup>, ...\n",
    "\n",
    "[Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) is a convenience method that allows you to define a sequence of data transformations and then apply it to any data.\n",
    "\n",
    "The following code is adapted from [here](http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import cross_validation\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 30\n",
    "# Try different values for degree: 1, 5, 15\n",
    "degree = 1\n",
    "\n",
    "# Here's the data we are trying to fit\n",
    "true_fun = lambda X: np.cos(1.5 * np.pi * X)\n",
    "X = np.sort(np.random.rand(n_samples))\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "polynomial_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                     (\"linear_regression\", linear_regression)])\n",
    "pipeline.fit(X[:, np.newaxis], y)\n",
    "\n",
    "X_test = np.linspace(0, 1, 100)\n",
    "plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\")\n",
    "plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "plt.scatter(X, y, label=\"Samples\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-2, 2))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Polynomial degree {}\".format(degree))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity\n",
    "\n",
    "**This is general, not specific to linear regression!**\n",
    "\n",
    "If the model not complex enough -> then it doesn't really capture the behavior of the underlying function we are trying to learn. This is a high **bias** situation and the model is **underfit**.\n",
    "\n",
    "If the model is too complex -> then it has learned too much. It is \"fit to the noise\" and not the underlying function. This is called high **variance** or **overfit**.\n",
    "\n",
    "Bias and variance are two types of errors. In a well-fit model, they are roughly equal. There are several ways to test and combat these types of errors.\n",
    "\n",
    "1. Underfit: Build more features.\n",
    "2. Overfit: Reduce number of features, get more data.\n",
    "\n",
    "We'll also talk about model specific ways to control model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Test](../images/highvariance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of linear regression and comparison with other models (you will see in the future)\n",
    "\n",
    "There are some obvious advantages to linear regression models:\n",
    "  * These kinds of models are very simple to explain\n",
    "  * They are highly interpretable\n",
    "  * Model training and prediction is very fast\n",
    "  * Features do not need to be scaled (we will talk about feature scaling later)\n",
    "  * They can perform well with a small number of observations\n",
    "\n",
    "However, linear regression also has some significant disadvantages:\n",
    "  * It assumes a linear relationship between the features and the outcome. This isn't always (almost never) the case.\n",
    "  * Performance is (generally) not competitive with the best supervised learning methods\n",
    "  * When you have lots of features, this approach can become sensitive to useless features\n",
    "  * This approach can't automatically learn feature interactions (although you can code them into a linear regression, will show you how to do that soon!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
