{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 8 Agenda:\n",
    "  * **Feature Engineering: Standard Scaling/MinMaxScaling**\n",
    "  * **Feature Engineering: Handling Categorical Features**\n",
    "  * **Feature Engineering: Handling Missing Values**\n",
    "  * **Feature Engineering: Creating Derived Features - Polynomial Features**\n",
    "  * **Cross Validation vs. Train/Test Split**\n",
    "  * **Cross Validation for Parameter Tuning**\n",
    "  * **Searching over Parameters using GridSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to make a big step today in the sophistication and kinds of models we will be capable of building. We will talk about several common feature transformations that you can/should perform when preparing most data for machine learning models.\n",
    "\n",
    "We're also going to learn how to improve the evaluation of the performance of any supervised machine learning models we build using a much better (more accurate) method than train-test split, one that gives more reliable estimates of error on unseen data.\n",
    "\n",
    "#### Outcomes\n",
    "By the end of this lesson you will be able to:\n",
    "- articulate why feature scaling is important, and be able to do it using sklearn\n",
    "- use a variety of transformation methods to reduce non-normality in features\n",
    "- handle categorical features when building a machine learning model\n",
    "- handle null/missing values when building a machine learning model\n",
    "- use cross validation to accurately estimate model performance\n",
    "- articulate the strengths and weaknesses of basic cross validation\n",
    "- use cross validation to choose optimal model parameters by searching across many models simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "When we talk about feature engineering, we are really talking about two things:\n",
    "* transforming the values at our disposal into a representation that a given machine learning algorithm can use and understand\n",
    "* creating new, derived features from the available features (using domain expertise) and use them when training a model\n",
    "* dealing with missing values, as most ML algorithms can't handle unknown values. They must be filled in.\n",
    "\n",
    "We will begin with the first case, transformation, and talk about the three most common transformations necessary to get data into a state where it can be used to train most ML models:\n",
    "* **feature scaling**: making it so that all columns (features) range over the same values is very helpful for many (but not all) machine learning models. In some cases, scaling along samples is useful, as well.\n",
    "* **turning categorical values into numerical values**: machine learning algorithms only understand numbers, not categories.\n",
    "* **handling missing values**: Models break when you give them `NaN`s, what are some strategies to replace `NaN`s with \"good\" (i.e. useful) numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the basics (those things we've seen in the past) like always, and generate some fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division  # Python 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data handling, model creation/evaluation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "#make it so that we only show first 4 decimals for floats\n",
    "np.set_printoptions(precision=4,suppress=True)\n",
    "\n",
    "# visualization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fake data\n",
    "train = pd.DataFrame({'target':[0,1,2], 'length':[0.9,0.3,0.6], 'mass':[0.1,0.2,0.8], 'rings':[40,50,60]})\n",
    "test = pd.DataFrame({'length':[0.59], 'mass':[0.79], 'rings':[54.9]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "## Standardization:\n",
    "Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "For instance, many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) assume that all features are centered around zero and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\n",
    "\n",
    "\n",
    "### Scaling to a range: MinMax Scaler\n",
    "simplest method is to rescale the feature range to [0,1] or [-1, 1]  \n",
    "\\begin{equation}\n",
    "X^\\prime = \\frac{X - min(X)}{max(X) - min(X)}\n",
    "\\end{equation}\n",
    "\n",
    "### Scaling to zero mean, unit variance: Standard Scaler \n",
    "calculating the z-score rescale to zero mean and unit variance\n",
    "\\begin{equation}\n",
    "X^\\prime = \\frac{X - \\bar{X}}{\\sigma}\n",
    "\\end{equation}\n",
    "\n",
    "### Scaling to unit length: Normalization\n",
    "rescale to unit length: useful in vector space models\n",
    "\\begin{equation}\n",
    "X^\\prime = \\frac{X}{\\left|\\left| X \\right| \\right|}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Note: save the scaler object that was applied on the training set, to be later re-applied on the testing set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to predict the `id` of each sample using the `length`, `mass`, and `rings` columns without doing any feature scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['length', 'mass', 'rings']\n",
    "X = train[feature_cols]\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate this, we are going to be using a different classifier from the one's we've learned about so far. \n",
    "\n",
    "This algorithm is called [K-nearest-neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) and simply selects either the category (classification) or average of the K closest samples to it (computed using Euclidean distance).\n",
    "\n",
    "We are going to use K-nearest-neighbors where k=1 (the single nearest neighbor, so it will simply assume the output of that sample):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "    length  mass  rings  target\n",
      "0     0.9   0.1     40       0\n",
      "1     0.3   0.2     50       1\n",
      "2     0.6   0.8     60       2 \n",
      "\n",
      "Single test sample:\n",
      "    length  mass  rings\n",
      "0    0.59  0.79   54.9\n"
     ]
    }
   ],
   "source": [
    "# KNN with k=1\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "\n",
    "print(\"Training data:\\n\",train,\"\\n\")\n",
    "print(\"Single test sample:\\n\",test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**what id \"should\" the classifier predict?**\n",
    "\n",
    "Hopefully, you said id 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction: \",knn.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier predicts id `1` instead of id `2` because the portion of the distance in the `rings` column **dominates** all of the other distances (it varies over ~10 units, whereas both of the other features vary over ~1 unit).\n",
    "\n",
    "How to get around this?\n",
    "\n",
    "**You scale all of the features so that they all range over the same values.**\n",
    "\n",
    "There are lots of ways to do this, we will talk about/use **Standard Scaling**. \n",
    "\n",
    "We simply compute the mean and standard deviation of each column, and for every value, subtract the mean of that column from the value, and divide by the standard deviation:\n",
    "$$zscore(x_i)=\\frac {x_i-\\mu}{\\sigma}$$\n",
    "\n",
    "Let's do that using `sklearn`'s `StandardScaler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original values:\n",
      " [[  0.9   0.1  40. ]\n",
      " [  0.3   0.2  50. ]\n",
      " [  0.6   0.8  60. ]] \n",
      "\n",
      "scaled values:\n",
      " [[ 1.2247 -0.8627 -1.2247]\n",
      " [-1.2247 -0.5392  0.    ]\n",
      " [ 0.      1.4018  1.2247]] \n",
      "\n",
      "Mean of each column:\n",
      " [  0.6      0.3667  50.    ] \n",
      "\n",
      "standard deviation of each column:\n",
      " [ 0.2449  0.3091  8.165 ] \n",
      "\n",
      "Z-scoring the values by hand to make sure we arent crazy:\n",
      " [[ 1.2247 -0.8627 -1.2247]\n",
      " [-1.2247 -0.5392  0.    ]\n",
      " [ 0.      1.4018  1.2247]]\n",
      "Final Means of scaled data, per column:\n",
      " [ 0. -0.  0.]\n",
      "Final SD's of scaled data, per column:\n",
      " [ 1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() # create a scaler object\n",
    "scaler.fit(X) # fit the scaler\n",
    "X_scaled = scaler.transform(X) #transform the data with it\n",
    "\n",
    "# compare original to standardized\n",
    "print(\"original values:\\n\",X.values,\"\\n\")\n",
    "print(\"scaled values:\\n\",X_scaled,\"\\n\")\n",
    "\n",
    "# figure out how the standardization worked\n",
    "print(\"Mean of each column:\\n\",scaler.mean_,\"\\n\")\n",
    "print(\"standard deviation of each column:\\n\",scaler.scale_,\"\\n\")\n",
    "print(\"Z-scoring the values by hand to make sure we arent crazy:\\n\",(X.values - scaler.mean_) / scaler.scale_)\n",
    "print(\"Final Means of scaled data, per column:\\n\",X_scaled.mean(axis=0))\n",
    "print(\"Final SD's of scaled data, per column:\\n\",X_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also scale the data to an arbitrary range of values (instead of scaling them to have 0 mean and unit variance), we specify the minimum and maximum values that the column can take on, using `MinMaxScaler`. By default, `MinMaxScaler` scales the data to the range (0,1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original values:\n",
      " [[  0.9   0.1  40. ]\n",
      " [  0.3   0.2  50. ]\n",
      " [  0.6   0.8  60. ]] \n",
      "\n",
      "scaled values:\n",
      " [[ 1.      0.      0.    ]\n",
      " [ 0.      0.1429  0.5   ]\n",
      " [ 0.5     1.      1.    ]] \n",
      "\n",
      "min and max of scaled values:\n",
      " 0.0 \n",
      " 1.0\n",
      "Mean of min/max scaled columns:\n",
      " [ 0.5    0.381  0.5  ]\n",
      "Std of min/max scaled columns:\n",
      " [ 0.4082  0.4416  0.4082]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax= MinMaxScaler()\n",
    "\n",
    "minmax.fit(X) #fit the scaler\n",
    "X_scaled_minmax = minmax.transform(X) #transform the data with it\n",
    "\n",
    "# compare original to standardized\n",
    "print(\"original values:\\n\",X.values,\"\\n\")\n",
    "print(\"scaled values:\\n\",X_scaled_minmax,\"\\n\")\n",
    "\n",
    "print(\"min and max of scaled values:\\n\",X_scaled_minmax.min(),\"\\n\",X_scaled_minmax.max())\n",
    "print(\"Mean of min/max scaled columns:\\n\", X_scaled_minmax.mean(axis=0))\n",
    "print(\"Std of min/max scaled columns:\\n\", X_scaled_minmax.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other scaling approaches may be more appropriate in different circumstances, you can read about them here: [preprocessing and scaling data in scikit-learn](http://scikit-learn.org/stable/modules/preprocessing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that is very important to keep in mind when scaling: \n",
    "\n",
    "**When you're creating a scaling object, you should first \"fit\" it to the training data, then transform both the training and testing data using the \"fit\" scaler. If you try to fit the training and testing data separately, you will get inaccurate results.**\n",
    "\n",
    "(Why?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCI Wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class label  Alcohol  Malic acid\n",
       "0            1    14.23        1.71\n",
       "1            1    13.20        1.78\n",
       "2            1    13.16        2.36\n",
       "3            1    14.37        1.95\n",
       "4            1    13.24        2.59"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.io.parsers.read_csv(\n",
    "    'http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',\n",
    "     header=None,\n",
    "     usecols=[0,1,2]\n",
    "    )\n",
    "\n",
    "df.columns=['Class label', 'Alcohol', 'Malic acid']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the table above, the features **Alcohol (percent/volumne)** and **Malic acid (g/l)** are measured on different scales, so that **Feature Scaling** is necessary and an important prior to any comparison or combination of these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(df[['Alcohol', 'Malic acid']])\n",
    "df_std = std_scale.transform(df[['Alcohol', 'Malic acid']])\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler().fit(df[['Alcohol', 'Malic acid']])\n",
    "df_minmax = minmax_scale.transform(df[['Alcohol', 'Malic acid']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean after standardization:\n",
      "Alcohol=-0.00, Malic acid=-0.00\n",
      "\n",
      "Standard deviation after standardization:\n",
      "Alcohol=1.00, Malic acid=1.00\n"
     ]
    }
   ],
   "source": [
    "print('Mean after standardization:\\nAlcohol={:.2f}, Malic acid={:.2f}'\n",
    "      .format(df_std[:,0].mean(), df_std[:,1].mean()))\n",
    "print('\\nStandard deviation after standardization:\\nAlcohol={:.2f}, Malic acid={:.2f}'\n",
    "      .format(df_std[:,0].std(), df_std[:,1].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGlCAYAAAACmwdGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkYKgoEZEREQKgoIaERERKQj/H0jI8bLrFLiqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1154c1470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot():\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    plt.scatter(df['Alcohol'], df['Malic acid'],\n",
    "            color='green', label='input scale', alpha=0.5)\n",
    "\n",
    "    plt.scatter(df_std[:,0], df_std[:,1], color='red',\n",
    "            label='Standardized [$ N  (\\mu=0, \\; \\sigma=1) $]', alpha=0.3)\n",
    "    \n",
    "    plt.scatter(df_minmax[:,0], df_minmax[:,1],\n",
    "        color='blue', label='min-max scaled [min=0, max=1]', alpha=0.3)\n",
    "\n",
    "    plt.title('Alcohol and Malic Acid content of the wine dataset')\n",
    "    plt.xlabel('Alcohol')\n",
    "    plt.ylabel('Malic Acid')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time!!!\n",
    "\n",
    "* load in the wine data located [here](http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data). The columns for the data are as follows:\n",
    "    1. Label\n",
    "    2. Alcohol\n",
    "    3. Malic acid\n",
    "    4. Ash\n",
    "    5. Alcalinity of ash  \n",
    "    6. Magnesium\n",
    "\t7. Total phenols\n",
    "    8. Flavonoids\n",
    "    9. Nonflavanoid phenols\n",
    "    10. Proanthocyanins\n",
    "    11. Color intensity\n",
    "    12. Hue\n",
    "    13. OD280/OD315 of diluted wines\n",
    "    14. Proline\n",
    "    \n",
    "* build a knn model with 3 nearest neighbors to predict the wine's `label` from the remaining columns. Don't scale the data, and check the test error when using 80/20 train/test split. (use `KNeighborsClassifier(n_neighbors=3)`)\n",
    "* now, build the same model, with the same train/test split, but scale the data using `StandardScaler` and `MinMaxScaler`. What is the test error for each of these scaled datasets (for `train_test_split use random_state=1234` for reproducibility)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic</th>\n",
       "      <th>ash</th>\n",
       "      <th>ash_alcalinity</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavonoids</th>\n",
       "      <th>nonflavonoids</th>\n",
       "      <th>proanth</th>\n",
       "      <th>color</th>\n",
       "      <th>hue</th>\n",
       "      <th>dilute</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  alcohol  malic   ash  ash_alcalinity  magnesium  total_phenols  \\\n",
       "0      1    14.23   1.71  2.43            15.6        127           2.80   \n",
       "1      1    13.20   1.78  2.14            11.2        100           2.65   \n",
       "2      1    13.16   2.36  2.67            18.6        101           2.80   \n",
       "3      1    14.37   1.95  2.50            16.8        113           3.85   \n",
       "4      1    13.24   2.59  2.87            21.0        118           2.80   \n",
       "\n",
       "   flavonoids  nonflavonoids  proanth  color   hue  dilute  proline  \n",
       "0        3.06           0.28     2.29   5.64  1.04    3.92     1065  \n",
       "1        2.76           0.26     1.28   4.38  1.05    3.40     1050  \n",
       "2        3.24           0.30     2.81   5.68  1.03    3.17     1185  \n",
       "3        3.49           0.24     2.18   7.80  0.86    3.45     1480  \n",
       "4        2.69           0.39     1.82   4.32  1.04    2.93      735  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "column_names = [\"label\",\"alcohol\",\"malic\",\"ash\",\"ash_alcalinity\",\"magnesium\",\"total_phenols\",\n",
    "                \"flavonoids\",\"nonflavonoids\",\"proanth\",\"color\",\"hue\",\"dilute\",\"proline\"]\n",
    "wine_features = column_names[1:]\n",
    "wine_target = column_names[0]\n",
    "wine_data = pd.read_csv(url,names=column_names)\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code below here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical Features\n",
    "\n",
    "scikit-learn expects all features to be numeric. So how do we include categorical columns (features) in our model? Before we decide how to encode categorical features, we need to understand the kind of categorical features we have:\n",
    "\n",
    "- **Ordered categories:** transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
    "- **Unordered categories:** use dummy encoding\n",
    "\n",
    "We will look at one case of unordered categorical columns here:\n",
    "- **unordered categories with more than 2 levels**\n",
    "\n",
    "Let's work with another dataset from the UCI ML repository, the [abalone dataset](http://archive.ics.uci.edu/ml/datasets/Abalone), which contains 9 columns:\n",
    "1. **Sex:** M, F, and I (infant)\n",
    "2. **Length:** Longest shell measurement\n",
    "3. **Diameter:** Perpendicular to length\n",
    "4. **Height:** Height with with meat in shell\n",
    "5. **Whole weight:** Whole abalone weight\n",
    "6. **Shucked weight:** Weight of meat only\n",
    "7. **Viscera weight:** Gut weight (after bleeding)\n",
    "8. **Shell weight:** Weight after being dried\n",
    "9. **Rings:** This value +1.5 gives the abalone's age in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diam</th>\n",
       "      <th>height</th>\n",
       "      <th>whole</th>\n",
       "      <th>shucked</th>\n",
       "      <th>viscera</th>\n",
       "      <th>shell</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex  length   diam  height   whole  shucked  viscera  shell  age\n",
       "0   M   0.455  0.365   0.095  0.5140   0.2245   0.1010  0.150   15\n",
       "1   M   0.350  0.265   0.090  0.2255   0.0995   0.0485  0.070    7\n",
       "2   F   0.530  0.420   0.135  0.6770   0.2565   0.1415  0.210    9\n",
       "3   M   0.440  0.365   0.125  0.5160   0.2155   0.1140  0.155   10\n",
       "4   I   0.330  0.255   0.080  0.2050   0.0895   0.0395  0.055    7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"sex\",\"length\",\"diam\",\"height\",\"whole\",\"shucked\",\"viscera\",\"shell\",\"age\"]\n",
    "abalone_data = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\",names=columns)\n",
    "abalone_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we include an unordered categorical feature with more than two levels, like **sex**? We can't simply encode it as F=1, I=2, M=3, because that would imply an **ordered relationship** in which I is somehow \"double\" F and M is somehow \"triple\" F.\n",
    "\n",
    "Instead, we create **additional dummy variables** and append them to the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>I</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F  I  M\n",
       "0  0  0  1\n",
       "1  0  0  1\n",
       "2  1  0  0\n",
       "3  0  0  1\n",
       "4  0  1  0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_dummies = pd.get_dummies(abalone_data.sex).astype(int)\n",
    "sex_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we actually only need **two dummy variables, not three**. Why? Because two dummies capture all of the \"information\" about the **sex** feature, and implicitly defines M as the **baseline level** (0 for both F and I implies M):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F  I\n",
       "0  0  0\n",
       "1  0  0\n",
       "2  1  0\n",
       "3  0  0\n",
       "4  0  1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_dummies = sex_dummies[[\"F\",\"I\"]]\n",
    "sex_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we interpret the encoding:\n",
    "\n",
    "- F is encoded as F=1 and I=0\n",
    "- I is encoded as F=0 and I=1\n",
    "- M is encoded as F=0 and I=0\n",
    "\n",
    "If this is confusing, think about why we only needed one dummy variable for a hypothetical binary categorical variable, not two dummy variables. In general, if you have a categorical feature with **k levels** (k distinct values that it takes on), you create **k-1 dummy variables**.\n",
    "\n",
    "Let's reappend these features to the original abalone dataset and drop the original `sex` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diam</th>\n",
       "      <th>height</th>\n",
       "      <th>whole</th>\n",
       "      <th>shucked</th>\n",
       "      <th>viscera</th>\n",
       "      <th>shell</th>\n",
       "      <th>age</th>\n",
       "      <th>F</th>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length   diam  height   whole  shucked  viscera  shell  age  F  I\n",
       "0   0.455  0.365   0.095  0.5140   0.2245   0.1010  0.150   15  0  0\n",
       "1   0.350  0.265   0.090  0.2255   0.0995   0.0485  0.070    7  0  0\n",
       "2   0.530  0.420   0.135  0.6770   0.2565   0.1415  0.210    9  1  0\n",
       "3   0.440  0.365   0.125  0.5160   0.2155   0.1140  0.155   10  0  0\n",
       "4   0.330  0.255   0.080  0.2050   0.0895   0.0395  0.055    7  0  1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_data = pd.concat([abalone_data,sex_dummies],axis=1) #remember that concatenating columns means axis=1!\n",
    "abalone_data.drop(\"sex\",inplace=True,axis=1)\n",
    "abalone_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    "scikit-learn models expect that all values are **numeric types** and **hold some meaning**. Thus, missing values are not allowed by scikit-learn (or by most machine learning algorithms).\n",
    "\n",
    "Let's use an example dataset that contains missing values to explore some strategies for how they can be handled. This dataset is called the [Chronic Kidney Disease Dataset](https://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease) and can be used to create a model that predicts whether someone has CKD (chronic kidney disease) or not.\n",
    "\n",
    "The columns in the dataset are as follows:\n",
    "\n",
    "* **age**: subject age, numeric\n",
    "* **bp**: blood pressure,  numeric\n",
    "* **sg**: specific gravity, numeric but discrete\n",
    "* **al**: albumin, numeric but discrete\n",
    "* **su**: sugar, numeric but discrete\n",
    "* **rbc**: red blood cells, categorical\n",
    "* **pc**: pus cell, categorical \n",
    "* **pcc**: pus cell clumps, categorical\n",
    "* **ba**: bacteria, categorical\n",
    "* **bgr**: blood glucose random, numeric\n",
    "* **bu**: blood urea, numeric\n",
    "* **sc**: serum creatinine, numeric \n",
    "* **sod**: sodium, numeric \n",
    "* **pot**: potassium, numeric \n",
    "* **hemo**: hemoglobin, numeric\n",
    "* **pcv**: packed cell volume, numeric\n",
    "* **wc**: white blood cell count, numeric\n",
    "* **rc**: red blood cell count, numeric\n",
    "* **htn**: hypertension, categorical\n",
    "* **dm**: diabetes mellitus, categorical \n",
    "* **cad**: coronary artery disease, categorical\n",
    "* **appet**: appetite, categorical\n",
    "* **pe**: pedal edema, categorical \n",
    "* **ane**: anemia, categorical\n",
    "* **class**: class, categorical\n",
    "\n",
    "Let's load the data in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>80</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>70</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>80</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  age  bp     sg al su     rbc        pc         pcc          ba  bgr  ...   \\\n",
       "0  48  80  1.020  1  0       ?    normal  notpresent  notpresent  121  ...    \n",
       "1   7  50  1.020  4  0       ?    normal  notpresent  notpresent    ?  ...    \n",
       "2  62  80  1.010  2  3  normal    normal  notpresent  notpresent  423  ...    \n",
       "3  48  70  1.005  4  0  normal  abnormal     present  notpresent  117  ...    \n",
       "4  51  80  1.010  2  0  normal    normal  notpresent  notpresent  106  ...    \n",
       "\n",
       "  pcv    wc   rc  htn   dm cad appet   pe  ane class  \n",
       "0  44  7800  5.2  yes  yes  no  good   no   no   ckd  \n",
       "1  38  6000    ?   no   no  no  good   no   no   ckd  \n",
       "2  31  7500    ?   no  yes  no  poor   no  yes   ckd  \n",
       "3  32  6700  3.9  yes   no  no  poor  yes  yes   ckd  \n",
       "4  35  7300  4.6   no   no  no  good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_columns = [\"age\",\"bp\",\"sg\",\"al\",\"su\",\"rbc\",\"pc\",\"pcc\",\"ba\",\"bgr\",\"bu\",\"sc\",\"sod\",\"pot\",\"hemo\",\"pcv\",\"wc\",\"rc\",\"htn\",\"dm\",\"cad\",\"appet\",\"pe\",\"ane\",\"class\"]\n",
    "kidney_data = pd.read_csv(\"../data/chronic_kidney_disease.csv\", header=None,names=kidney_columns)\n",
    "kidney_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like any cell with a missing value is marked with a `?`.\n",
    "\n",
    "Let's make **pandas** recognize that by specifying the `NaN` value type by passing in `?` into the `na_values` parameter of `read_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "     bgr  ...    pcv      wc   rc  htn   dm  cad  appet   pe  ane class  \n",
       "0  121.0  ...   44.0  7800.0  5.2  yes  yes   no   good   no   no   ckd  \n",
       "1    NaN  ...   38.0  6000.0  NaN   no   no   no   good   no   no   ckd  \n",
       "2  423.0  ...   31.0  7500.0  NaN   no  yes   no   poor   no  yes   ckd  \n",
       "3  117.0  ...   32.0  6700.0  3.9  yes   no   no   poor  yes  yes   ckd  \n",
       "4  106.0  ...   35.0  7300.0  4.6   no   no   no   good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_data = pd.read_csv(\"../data/chronic_kidney_disease.csv\",header=None,na_values=\"?\",names=kidney_columns)\n",
    "kidney_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at which cells have `NaN`'s in them by calling `isnull()` on the `kidney_data` `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age     bp     sg     al     su    rbc     pc    pcc     ba    bgr  \\\n",
       "0  False  False  False  False  False   True  False  False  False  False   \n",
       "1  False  False  False  False  False   True  False  False  False   True   \n",
       "2  False  False  False  False  False  False  False  False  False  False   \n",
       "3  False  False  False  False  False  False  False  False  False  False   \n",
       "4  False  False  False  False  False  False  False  False  False  False   \n",
       "\n",
       "   ...      pcv     wc     rc    htn     dm    cad  appet     pe    ane  class  \n",
       "0  ...    False  False  False  False  False  False  False  False  False  False  \n",
       "1  ...    False  False   True  False  False  False  False  False  False  False  \n",
       "2  ...    False  False   True  False  False  False  False  False  False  False  \n",
       "3  ...    False  False  False  False  False  False  False  False  False  False  \n",
       "4  ...    False  False  False  False  False  False  False  False  False  False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_data.isnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the total number of rows missing values per column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        9\n",
       "bp        12\n",
       "sg        47\n",
       "al        46\n",
       "su        49\n",
       "rbc      152\n",
       "pc        65\n",
       "pcc        4\n",
       "ba         4\n",
       "bgr       44\n",
       "bu        19\n",
       "sc        17\n",
       "sod       87\n",
       "pot       88\n",
       "hemo      52\n",
       "pcv       71\n",
       "wc       106\n",
       "rc       131\n",
       "htn        2\n",
       "dm         2\n",
       "cad        2\n",
       "appet      1\n",
       "pe         1\n",
       "ane        1\n",
       "class      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for number of missing values per column\n",
    "kidney_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to have to handle the categorical and the numeric columns differently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age      float64\n",
       "bp       float64\n",
       "sg       float64\n",
       "al       float64\n",
       "su       float64\n",
       "rbc       object\n",
       "pc        object\n",
       "pcc       object\n",
       "ba        object\n",
       "bgr      float64\n",
       "bu       float64\n",
       "sc       float64\n",
       "sod      float64\n",
       "pot      float64\n",
       "hemo     float64\n",
       "pcv      float64\n",
       "wc       float64\n",
       "rc       float64\n",
       "htn       object\n",
       "dm        object\n",
       "cad       object\n",
       "appet     object\n",
       "pe        object\n",
       "ane       object\n",
       "class     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rearrange the numeric and categorical columns for easier access later, and lets remove the response column (`class`) into a separate `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names before rearranging:\n",
      " ['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'class']\n",
      "column names after rearranging:\n",
      " ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'class']\n"
     ]
    }
   ],
   "source": [
    "print(\"column names before rearranging:\\n\",kidney_columns)\n",
    "kidney_columns = kidney_columns[:5]+kidney_columns[9:18]+kidney_columns[5:9]+kidney_columns[18:]\n",
    "print(\"column names after rearranging:\\n\",kidney_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age      float64\n",
      "bp       float64\n",
      "sg       float64\n",
      "al       float64\n",
      "su       float64\n",
      "bgr      float64\n",
      "bu       float64\n",
      "sc       float64\n",
      "sod      float64\n",
      "pot      float64\n",
      "hemo     float64\n",
      "pcv      float64\n",
      "wc       float64\n",
      "rc       float64\n",
      "rbc       object\n",
      "pc        object\n",
      "pcc       object\n",
      "ba        object\n",
      "htn       object\n",
      "dm        object\n",
      "cad       object\n",
      "appet     object\n",
      "pe        object\n",
      "ane       object\n",
      "class     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>...</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su    bgr    bu   sc    sod  pot  ...         pc  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0  121.0  36.0  1.2    NaN  NaN  ...     normal   \n",
       "1   7.0  50.0  1.020  4.0  0.0    NaN  18.0  0.8    NaN  NaN  ...     normal   \n",
       "2  62.0  80.0  1.010  2.0  3.0  423.0  53.0  1.8    NaN  NaN  ...     normal   \n",
       "3  48.0  70.0  1.005  4.0  0.0  117.0  56.0  3.8  111.0  2.5  ...   abnormal   \n",
       "4  51.0  80.0  1.010  2.0  0.0  106.0  26.0  1.4    NaN  NaN  ...     normal   \n",
       "\n",
       "          pcc          ba  htn   dm cad appet   pe  ane class  \n",
       "0  notpresent  notpresent  yes  yes  no  good   no   no   ckd  \n",
       "1  notpresent  notpresent   no   no  no  good   no   no   ckd  \n",
       "2  notpresent  notpresent   no  yes  no  poor   no  yes   ckd  \n",
       "3     present  notpresent  yes   no  no  poor  yes  yes   ckd  \n",
       "4  notpresent  notpresent   no   no  no  good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_data = kidney_data[kidney_columns]\n",
    "target = kidney_data[\"class\"]\n",
    "print(kidney_data.dtypes)\n",
    "kidney_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that our data is arranged in a way that's amenable with dealing with the numeric and the categorical columns separately, let's work through the ways in which we can handle null values.\n",
    "\n",
    "The first thing we can do, is simply throw out any samples that have nulls in any column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of data kept:\n",
      " 0.395\n"
     ]
    }
   ],
   "source": [
    "kidney_data_nonnull = kidney_data.dropna()\n",
    "print(\"Fraction of data kept:\\n\",float(kidney_data_nonnull.shape[0])/kidney_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So throwing out ~60% of the data is no bueno. What else can we do?\n",
    "\n",
    "We can **impute** (fill in) the data on a per-column basis. The imputation strategy for categorical columns is usually one of the following:\n",
    "  1. fill in with the most common categorical value\n",
    "  2. fill in with a special \"missing\" category\n",
    "\n",
    "Let's do each in turn.\n",
    "\n",
    "Here's how we would do **1.**\n",
    "\n",
    "We are going to get the most common category per column, and store it in a `Series` first, then we will apply it per-column to those columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent value in each column:\n",
      " rbc          normal\n",
      "pc           normal\n",
      "pcc      notpresent\n",
      "ba       notpresent\n",
      "htn              no\n",
      "dm               no\n",
      "cad              no\n",
      "appet          good\n",
      "pe               no\n",
      "ane              no\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#function to return the most frequent value in a pandas Series\n",
    "def get_most_frequent_value(my_column):\n",
    "    return my_column.value_counts().index[0]\n",
    "\n",
    "most_frequent_values_per_column = kidney_data[kidney_columns[14:-1]].apply(get_most_frequent_value,axis=0)\n",
    "print(\"Most frequent value in each column:\\n\",most_frequent_values_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rbc        pc         pcc          ba  htn   dm cad appet   pe  ane\n",
       "0  normal    normal  notpresent  notpresent  yes  yes  no  good   no   no\n",
       "1  normal    normal  notpresent  notpresent   no   no  no  good   no   no\n",
       "2  normal    normal  notpresent  notpresent   no  yes  no  poor   no  yes\n",
       "3  normal  abnormal     present  notpresent  yes   no  no  poor  yes  yes\n",
       "4  normal    normal  notpresent  notpresent   no   no  no  good   no   no"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_most_frequent = kidney_data[kidney_columns[14:-1]].fillna(most_frequent_values_per_column,axis=0)\n",
    "categorical_most_frequent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do **2.** (Which is much easier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>missing</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>missing</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rbc        pc         pcc          ba  htn   dm cad appet   pe  ane\n",
       "0  missing    normal  notpresent  notpresent  yes  yes  no  good   no   no\n",
       "1  missing    normal  notpresent  notpresent   no   no  no  good   no   no\n",
       "2   normal    normal  notpresent  notpresent   no  yes  no  poor   no  yes\n",
       "3   normal  abnormal     present  notpresent  yes   no  no  poor  yes  yes\n",
       "4   normal    normal  notpresent  notpresent   no   no  no  good   no   no"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_missing_category = kidney_data[kidney_columns[14:-1]].fillna(\"missing\")\n",
    "special_missing_category.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical columns, there are 3 common strategies for filling in missing values:\n",
    "\n",
    "1. Fill in using the mean\n",
    "2. Fill in using the median (when many outliers are present)\n",
    "3. Fill in with some default value (e.g. 0).\n",
    "\n",
    "Let's do each in turn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lots of missing data here:\n",
      "     age    bp     sg   al   su    bgr    bu   sc    sod  pot  hemo   pcv  \\\n",
      "0  48.0  80.0  1.020  1.0  0.0  121.0  36.0  1.2    NaN  NaN  15.4  44.0   \n",
      "1   7.0  50.0  1.020  4.0  0.0    NaN  18.0  0.8    NaN  NaN  11.3  38.0   \n",
      "2  62.0  80.0  1.010  2.0  3.0  423.0  53.0  1.8    NaN  NaN   9.6  31.0   \n",
      "3  48.0  70.0  1.005  4.0  0.0  117.0  56.0  3.8  111.0  2.5  11.2  32.0   \n",
      "4  51.0  80.0  1.010  2.0  0.0  106.0  26.0  1.4    NaN  NaN  11.6  35.0   \n",
      "\n",
      "       wc   rc  \n",
      "0  7800.0  5.2  \n",
      "1  6000.0  NaN  \n",
      "2  7500.0  NaN  \n",
      "3  6700.0  3.9  \n",
      "4  7300.0  4.6  \n",
      "Mean value per column:\n",
      " age       51.483376\n",
      "bp        76.469072\n",
      "sg         1.017408\n",
      "al         1.016949\n",
      "su         0.450142\n",
      "bgr      148.036517\n",
      "bu        57.425722\n",
      "sc         3.072454\n",
      "sod      137.528754\n",
      "pot        4.627244\n",
      "hemo      12.526437\n",
      "pcv       38.884498\n",
      "wc      8406.122449\n",
      "rc         4.707435\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#1.\n",
    "print(\"Lots of missing data here:\\n\",kidney_data[kidney_columns[:14]].head())\n",
    "mean_per_column = kidney_data[kidney_columns[:14]].apply(lambda x: x.mean(),axis=0)\n",
    "print(\"Mean value per column:\\n\",mean_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>15.4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.036517</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4.707435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>9.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>4.707435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>11.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>137.528754</td>\n",
       "      <td>4.627244</td>\n",
       "      <td>11.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su         bgr    bu   sc         sod       pot  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0  121.000000  36.0  1.2  137.528754  4.627244   \n",
       "1   7.0  50.0  1.020  4.0  0.0  148.036517  18.0  0.8  137.528754  4.627244   \n",
       "2  62.0  80.0  1.010  2.0  3.0  423.000000  53.0  1.8  137.528754  4.627244   \n",
       "3  48.0  70.0  1.005  4.0  0.0  117.000000  56.0  3.8  111.000000  2.500000   \n",
       "4  51.0  80.0  1.010  2.0  0.0  106.000000  26.0  1.4  137.528754  4.627244   \n",
       "\n",
       "   hemo   pcv      wc        rc  \n",
       "0  15.4  44.0  7800.0  5.200000  \n",
       "1  11.3  38.0  6000.0  4.707435  \n",
       "2   9.6  31.0  7500.0  4.707435  \n",
       "3  11.2  32.0  6700.0  3.900000  \n",
       "4  11.6  35.0  7300.0  4.600000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. cont'd.\n",
    "numeric_mean_filled = kidney_data[kidney_columns[:14]].fillna(mean_per_column,axis=0)\n",
    "numeric_mean_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age    bp     sg   al   su    bgr    bu   sc    sod  pot  hemo   pcv  \\\n",
      "0  48.0  80.0  1.020  1.0  0.0  121.0  36.0  1.2    NaN  NaN  15.4  44.0   \n",
      "1   7.0  50.0  1.020  4.0  0.0    NaN  18.0  0.8    NaN  NaN  11.3  38.0   \n",
      "2  62.0  80.0  1.010  2.0  3.0  423.0  53.0  1.8    NaN  NaN   9.6  31.0   \n",
      "3  48.0  70.0  1.005  4.0  0.0  117.0  56.0  3.8  111.0  2.5  11.2  32.0   \n",
      "4  51.0  80.0  1.010  2.0  0.0  106.0  26.0  1.4    NaN  NaN  11.6  35.0   \n",
      "\n",
      "       wc   rc  \n",
      "0  7800.0  5.2  \n",
      "1  6000.0  NaN  \n",
      "2  7500.0  NaN  \n",
      "3  6700.0  3.9  \n",
      "4  7300.0  4.6  \n",
      "Median per column:\n",
      " age       55.00\n",
      "bp        80.00\n",
      "sg         1.02\n",
      "al         0.00\n",
      "su         0.00\n",
      "bgr      121.00\n",
      "bu        42.00\n",
      "sc         1.30\n",
      "sod      138.00\n",
      "pot        4.40\n",
      "hemo      12.65\n",
      "pcv       40.00\n",
      "wc      8000.00\n",
      "rc         4.80\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#2.\n",
    "print(kidney_data[kidney_columns[:14]].head())\n",
    "median_per_column = kidney_data[kidney_columns[:14]].apply(lambda x: x.median(),axis=0)\n",
    "print(\"Median per column:\\n\",median_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>15.4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su    bgr    bu   sc    sod  pot  hemo   pcv  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0  121.0  36.0  1.2  138.0  4.4  15.4  44.0   \n",
       "1   7.0  50.0  1.020  4.0  0.0  121.0  18.0  0.8  138.0  4.4  11.3  38.0   \n",
       "2  62.0  80.0  1.010  2.0  3.0  423.0  53.0  1.8  138.0  4.4   9.6  31.0   \n",
       "3  48.0  70.0  1.005  4.0  0.0  117.0  56.0  3.8  111.0  2.5  11.2  32.0   \n",
       "4  51.0  80.0  1.010  2.0  0.0  106.0  26.0  1.4  138.0  4.4  11.6  35.0   \n",
       "\n",
       "       wc   rc  \n",
       "0  7800.0  5.2  \n",
       "1  6000.0  4.8  \n",
       "2  7500.0  4.8  \n",
       "3  6700.0  3.9  \n",
       "4  7300.0  4.6  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. cont'd.\n",
    "numeric_median_filled = kidney_data[kidney_columns[:14]].fillna(median_per_column,axis=0)\n",
    "numeric_median_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su    bgr    bu   sc    sod  pot  hemo   pcv  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0  121.0  36.0  1.2    0.0  0.0  15.4  44.0   \n",
       "1   7.0  50.0  1.020  4.0  0.0    0.0  18.0  0.8    0.0  0.0  11.3  38.0   \n",
       "2  62.0  80.0  1.010  2.0  3.0  423.0  53.0  1.8    0.0  0.0   9.6  31.0   \n",
       "3  48.0  70.0  1.005  4.0  0.0  117.0  56.0  3.8  111.0  2.5  11.2  32.0   \n",
       "4  51.0  80.0  1.010  2.0  0.0  106.0  26.0  1.4    0.0  0.0  11.6  35.0   \n",
       "\n",
       "       wc   rc  \n",
       "0  7800.0  5.2  \n",
       "1  6000.0  0.0  \n",
       "2  7500.0  0.0  \n",
       "3  6700.0  3.9  \n",
       "4  7300.0  4.6  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_value_per_column = kidney_data[kidney_columns[:14]].fillna(0.0)\n",
    "default_value_per_column.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these imputation methods will have distinct effects on classification accuracy.\n",
    "\n",
    "Much fancier methods for imputing values, including [EM (expectation maximization)](https://en.wikipedia.org/wiki/Expectation–maximization_algorithm), [multiple imputation](https://en.wikipedia.org/wiki/Imputation_%28statistics%29), etc. exist. \n",
    "\n",
    "These fancy imputation methods attempt to preserve the statistical relationships among the variables, and \"fill in\" the most likely values, given the values of all of the other columns (these are \"distributional\" imputation methods, as they attempt to keep the distributions of the columns as similar as possible after imputation to what they were prior to imputation). \n",
    "\n",
    "**However, they give really unstable/unreliable results when you have lots of missing data (>10% missing values), so I don't recommend using them when you have a dataset that is missing lots of values.**\n",
    "\n",
    "Look into these to find out more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time!!!\n",
    "\n",
    "1. Create a complete, filled in dataset of non-missing values using mean imputation per numeric column, most frequent value imputation for the categorical values, convert all of the categorical columns into numerical columns using `get_dummies`\n",
    "2. Do the same thing using median imputation for each numeric column.\n",
    "3. Compare test set errors when building a Logistic Regression model (`LogisticRegression()`) on the data and using train/test split (`train_test_split(random_state=123)`), predicting the `class` column. Which imputation method seems to perform better on this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating higher-order features: Polynomial Transformation\n",
    "\n",
    "Although some machine learning methods, like **Random Forests** implicitly model non-linear interactions between the features in your data, it can be helpful to generate the full complement of non-linear interaction terms quickly. A simple and common method to use is polynomial features, which can generate features’ higher-order and interaction terms.\n",
    "\n",
    "Let's take a look at the kidney data, so we can see how this can be done in practice using the preprocessing function `PolynomialFeatures`. Let's first fill in all of the nulls, then go forward with the exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age      0\n",
       "bp       0\n",
       "sg       0\n",
       "al       0\n",
       "su       0\n",
       "bgr      0\n",
       "bu       0\n",
       "sc       0\n",
       "sod      0\n",
       "pot      0\n",
       "hemo     0\n",
       "pcv      0\n",
       "wc       0\n",
       "rc       0\n",
       "rbc      0\n",
       "pc       0\n",
       "pcc      0\n",
       "ba       0\n",
       "htn      0\n",
       "dm       0\n",
       "cad      0\n",
       "appet    0\n",
       "pe       0\n",
       "ane      0\n",
       "class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_data_numeric_columns = kidney_data.columns.tolist()[:14]\n",
    "kidney_data_categorical_columns = kidney_data.columns.tolist()[14:-1]\n",
    "kidney_data_filled = kidney_data.copy()\n",
    "kidney_data_filled[kidney_data_numeric_columns] = numeric_median_filled\n",
    "kidney_data_filled[kidney_data_categorical_columns] = categorical_most_frequent\n",
    "kidney_data_filled.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_fit = PolynomialFeatures(degree=3)\n",
    "fitted_degree3_numeric_kidneys = poly_fit.fit_transform(kidney_data_filled[kidney_data_numeric_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first few rows in this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.0000e+00,   4.8000e+01,   8.0000e+01, ...,   3.1637e+08,\n",
       "          2.1091e+05,   1.4061e+02],\n",
       "       [  1.0000e+00,   7.0000e+00,   5.0000e+01, ...,   1.7280e+08,\n",
       "          1.3824e+05,   1.1059e+02],\n",
       "       [  1.0000e+00,   6.2000e+01,   8.0000e+01, ...,   2.7000e+08,\n",
       "          1.7280e+05,   1.1059e+02],\n",
       "       [  1.0000e+00,   4.8000e+01,   7.0000e+01, ...,   1.7507e+08,\n",
       "          1.0191e+05,   5.9319e+01],\n",
       "       [  1.0000e+00,   5.1000e+01,   8.0000e+01, ...,   2.4513e+08,\n",
       "          1.5447e+05,   9.7336e+01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_degree3_numeric_kidneys[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformation generates every possible pairwise combination of all of the numeric columns in the kidney dataset upto a degree of 3.\n",
    "\n",
    "So, if we had 3 columns, $X,Y,Z$, this transformation would generate:\n",
    "$$(1,X,Y,Z,XY,XZ,YZ,X^2,Y^2,Z^2,X^2Y,X^2Z,...,XYZ,X^3,Y^3,Z^3) $$\n",
    "\n",
    "However, this is complete overkill. What we usually want to generate is just the interactions ($XY, YZ$,etc. terms) not all of the polynomial degrees. In that case, we simply pass an extra Boolean parameter to the `PolynomialFeatures` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poly_fit_3_interact = PolynomialFeatures(degree=3,interaction_only=True)\n",
    "#don't want the initial constant term, so only keep columns 1 to the end\n",
    "interactions_only_kidney_columns = poly_fit_3_interact.fit_transform(kidney_data_filled[kidney_data_numeric_columns])[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time!\n",
    "1. Generate the interactions-only degree-2 polynomial-fit features for the kidney_data null-filled dataset on the numeric columns only.\n",
    "2. Use train_test_split to predict the class with/without these polynomial features using `LogisticRegression()`. What happens to train/test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to talk about better ways to measure model performance than train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation as many train/test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to motivate this discussion of cross-validation by trying to see if there are any drawbacks from just using train/test split. Specifically:\n",
    "  - What is the drawback of using the **train/test split** procedure for model evaluation?\n",
    "  - How does **K-fold cross-validation** overcome this limitation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:** We need a way to choose between several different machine learning models (or multiple versions of the same model). Our goal is **to estimate likely performance of a model on out-of-sample data**.\n",
    "\n",
    "**Initial approach:** Train/test split\n",
    "- Split the dataset into two pieces, so that the model can be trained and tested on **different data**.\n",
    "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance (because testing on the same data that you used to train the model causes **overfitting** and worse out-of-sample performance).\n",
    "- However, just using one train/test split provides a **high variance** estimate since changing which observations happen to be in the testing set can significantly change testing accuracy.\n",
    "\n",
    "What would be a better approach?\n",
    "\n",
    "**Better approach:** Create a bunch of train/test splits, calculate the testing accuracy for each, and average the results together.\n",
    "\n",
    "**This is the essense of cross-validation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation flow\n",
    "1. Split the dataset into K **equal** partitions (or \"folds\").\n",
    "2. Use fold 1 as the **testing set** and the union of the other folds as the **training set**.\n",
    "3. Calculate **testing accuracy**.\n",
    "4. Repeat steps 2 and 3 K times, using a **different fold** as the testing set each time.\n",
    "5. Use the **average testing accuracy** as the estimate of out-of-sample accuracy.\n",
    "\n",
    "**Here's an example diagram where K = 5 (5 fold cross-validation):**\n",
    "![5-fold cross-validation](../images/5-fold-cv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration                         Training set observations                          Testing set observations\n",
      "1 [ 4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] [0 1 2 3]\n",
      "2 [ 0  1  2  3  8  9 10 11 12 13 14 15 16 17 18 19] [4 5 6 7]\n",
      "3 [ 0  1  2  3  4  5  6  7 12 13 14 15 16 17 18 19] [ 8  9 10 11]\n",
      "4 [ 0  1  2  3  4  5  6  7  8  9 10 11 16 17 18 19] [12 13 14 15]\n",
      "5 [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15] [16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "# simulate splitting a dataset of 30 observations into 5 folds\n",
    "kf = KFold(20, n_folds=5, shuffle=False)\n",
    "\n",
    "# print the contents of each training and testing set\n",
    "print('{} {:^74} {}'.format('Iteration', 'Training set observations', 'Testing set observations'))\n",
    "for iteration, data in enumerate(kf, start=1):\n",
    "    print('{} {} {}'.format(iteration, data[0], data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through this carefully:\n",
    "- Dataset contains **30 observations** (numbered 0 through 29)\n",
    "- 5-fold cross-validation, thus it runs for **5 iterations**\n",
    "- For each iteration, every observation is either in the training set or the testing set, **but not both**\n",
    "- Every observation is in the testing set **exactly once**\n",
    "\n",
    "Let's try this with real data and compare to just a single train/test split (we will use the vertebral column data we've used before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for split  0 :  0.451612903226\n",
      "Accuracy for split  1 :  0.451612903226\n",
      "Accuracy for split  2 :  0.967741935484\n",
      "Accuracy for split  3 :  0.967741935484\n",
      "Accuracy for split  4 :  1.0\n",
      "Accuracy for split  5 :  1.0\n",
      "Accuracy for split  6 :  0.967741935484\n",
      "Accuracy for split  7 :  0.612903225806\n",
      "Accuracy for split  8 :  0.677419354839\n",
      "Accuracy for split  9 :  0.58064516129\n",
      "Mean KF-accuracy: 0.767741935484\n",
      "Std of KF-accuracy: 0.222463737414\n",
      "10-fold accuracies:\n",
      " [ 0.6129  0.6129  0.7097  0.8065  0.9355  0.8387  0.9677  1.      0.8065\n",
      "  0.871 ]\n",
      "Mean cv-accuracy: 0.816129032258\n",
      "Std of cv-accuracy: 0.129876271866\n"
     ]
    }
   ],
   "source": [
    "# read in the vertebral column data\n",
    "vertebral_data = pd.read_csv(\"../data/vertebral_column_2_categories.dat\", sep=\" \",\n",
    "                             names=[\"pelvic_incidence\",\"pelvic_tilt\",\"lumbar_lordosis_angle\",\"sacral_slope\",\"pelvic_radius\",\"spondy_grade\",\"outcome\"])\n",
    "#generate features, targets\n",
    "X = vertebral_data.ix[:,:-1]\n",
    "y = vertebral_data.outcome\n",
    "rf = RandomForestClassifier(n_estimators=50) #random forest with 50 trees\n",
    "\n",
    "#train/test split with 10% of data in each split:\n",
    "kf = KFold(len(X), n_folds=10, shuffle=False)\n",
    "kf_scores = []\n",
    "for i, (train_idx, test_idx) in enumerate(kf):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "#     X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.1)\n",
    "    rf_fit = rf.fit(X_train,y_train)\n",
    "    score = metrics.accuracy_score(y_test,rf_fit.predict(X_test))\n",
    "    print(\"Accuracy for split \",i,\": \", score)\n",
    "    kf_scores.append(score)\n",
    "\n",
    "print(\"Mean KF-accuracy:\",np.mean(kf_scores))\n",
    "print(\"Std of KF-accuracy:\",np.std(kf_scores))\n",
    "    \n",
    "#compute cross-validation score accuracy across 10 folds\n",
    "cross_val_scores = cross_val_score(rf,X,y,cv=10)\n",
    "print(\"10-fold accuracies:\\n\",cross_val_scores)\n",
    "print(\"Mean cv-accuracy:\",np.mean(cross_val_scores))\n",
    "print(\"Std of cv-accuracy:\",np.std(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise Time!!!\n",
    "\n",
    "* Compute cross-validated mean/std of accuracies when doing 20, 40, 50-fold cross-validation using `cross_val_score()`. What happens to the mean and standard deviation of the accuracies as you increase the number of folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the advantages of **cross-validation:**\n",
    "- More accurate estimate of out-of-sample accuracy\n",
    "- More \"efficient\" use of data (every observation is used for both training and testing)\n",
    "\n",
    "However, there are some advantages to using **train/test split:**\n",
    "- Runs K times faster than K-fold cross-validation\n",
    "- Simpler to examine the detailed results of the testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve this basic cross-validation approach a bit more as follows:\n",
    "\n",
    "**Repeated cross-validation**\n",
    "\n",
    "- Repeat cross-validation multiple times (with **different random splits** of the data) and average the results\n",
    "- More reliable estimate of out-of-sample performance by **reducing the variance** associated with a single trial of cross-validation\n",
    "\n",
    "**Creating a hold-out set**\n",
    "\n",
    "- \"Hold out\" a portion of the data **before** beginning the model building process\n",
    "- Locate the best model using cross-validation on the remaining data, and test it **using the hold-out set**\n",
    "- More reliable estimate of out-of-sample performance since hold-out set is **truly out-of-sample**\n",
    "\n",
    "**Feature engineering and selection within cross-validation iterations**\n",
    "\n",
    "- Normally, feature engineering and selection occurs **before** cross-validation\n",
    "- Instead, you can perform all feature engineering and selection **within each cross-validation iteration**\n",
    "- This gives us a more reliable estimate of out-of-sample performance since it **better mimics** the application of the model to out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated mean accuracy for depth 2: 0.761290322581\n",
      "Cross-validated mean accuracy for depth 3: 0.787096774194\n"
     ]
    }
   ],
   "source": [
    "# use 10-fold cross-validation to find best max_depth per-tree out of depth 2 or 3\n",
    "\n",
    "# try max_depth=2\n",
    "rf_2 = RandomForestClassifier(max_depth=2, random_state=1)\n",
    "print(\"Cross-validated mean accuracy for depth 2:\",cross_val_score(rf_2, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# try max_depth=3\n",
    "rf_3 = RandomForestClassifier(max_depth=3, random_state=1)\n",
    "print(\"Cross-validated mean accuracy for depth 3:\",cross_val_score(rf_3, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': range(1, 20, 2)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rameshsampath/miniconda2/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py:662: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/rameshsampath/miniconda2/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py:662: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# use GridSearchCV to automate the search across depths 1-10\n",
    "rf_grid = RandomForestClassifier(n_estimators=50,random_state=1,n_jobs=-1) #50 trees\n",
    "max_depth_range = range(1, 20, 2)\n",
    "param_grid = dict(max_depth=max_depth_range)\n",
    "print(param_grid)\n",
    "grid = GridSearchCV(rf_grid, param_grid, cv=3, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "\n",
    "# store the results of the grid search\n",
    "grid.grid_scores_\n",
    "grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11974b860>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAFkCAYAAADFZ4k9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4gH+P466Hqil5UjEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119741a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "sns.plt.plot(max_depth_range, grid_mean_scores)\n",
    "sns.plt.xlabel('Value of max_depth')\n",
    "sns.plt.ylabel('Cross-Validated Mean Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=9, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=50, n_jobs=-1, oob_score=False, random_state=1,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what was best model?\n",
    "grid.best_score_\n",
    "grid.best_params_\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rameshsampath/miniconda2/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py:662: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search multiple parameters simultaneously\n",
    "max_depth_range = range(1, 11)\n",
    "leaf_range = range(1, 11)\n",
    "param_grid2 = dict(max_depth=max_depth_range, min_samples_leaf=leaf_range)\n",
    "grid = GridSearchCV(rf_grid, param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "grid.grid_scores_\n",
    "grid.best_score_\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Exercise Time!!!\n",
    "\n",
    "I want you to use and test several different imputation methods, different feature transformations, and different model parameters using `GridSearchCV` for the kidney dataset.\n",
    "\n",
    "This will get you to use everything we've learned today on one dataset with several kinds of missing values, and using both categorical and numeric values.\n",
    "\n",
    "**Don't forget to transform the categories using `pd.get_dummies()` once you've filled in the missing data!**\n",
    "\n",
    "Remember there are other parameters you can tune for random forests than just the maximum depth. Look at the random forest lesson or the [random forest documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "Try to be systematic in your exploration. Your goal is to make as robust a model as you can (lowest average cross-validated test error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
