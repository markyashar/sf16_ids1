{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "try:\n",
    "    from sklearn.model_selection import cross_val_score, train_test_split\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "#data handling/modeling\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "import scipy.stats as stats\n",
    "\n",
    "# visualization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = [\"These debates are boring\", \"we want more debates\", \"debates are useful\"]\n",
    "target = [0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "tweet_X = vect.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0],\n",
       "       [0, 1, 0, 1],\n",
       "       [0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boring', 'debates', 'useful', 'want']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boring</th>\n",
       "      <th>debates</th>\n",
       "      <th>useful</th>\n",
       "      <th>want</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   boring  debates  useful  want\n",
       "0       1        1       0     0\n",
       "1       0        1       0     1\n",
       "2       0        1       1     0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tweet_X.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(path, target):\n",
    "    reviews = []\n",
    "    for file in glob(path):\n",
    "        review = open(file).read()\n",
    "        reviews.append({\n",
    "                \"target\": target,\n",
    "                \"review\": review\n",
    "            })\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = load_data(\"../data/review_polarity/txt_sentoken/neg/*\", \"neg\") + \\\n",
    "    load_data(\"../data/review_polarity/txt_sentoken/pos/*\", \"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>movies about teenagers and teenage culture rar...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>the plot of big momma's house is martin lawren...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>my friend here in film school just made a two ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>capsule : dumb dud of an entry in the body hea...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>weighed down by tired plot lines and spielberg...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>there are two things the american film industr...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>seen at the 21st portland international film f...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>when it comes to the average teenage romantic ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>dora ( fernanda montenegro ) sits behind a mak...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>i came to an epiphany while watching the bache...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review target\n",
       "483   movies about teenagers and teenage culture rar...    neg\n",
       "935   the plot of big momma's house is martin lawren...    neg\n",
       "787   my friend here in film school just made a two ...    neg\n",
       "360   capsule : dumb dud of an entry in the body hea...    neg\n",
       "761   weighed down by tired plot lines and spielberg...    neg\n",
       "62    there are two things the american film industr...    neg\n",
       "1423  seen at the 21st portland international film f...    pos\n",
       "45    when it comes to the average teenage romantic ...    neg\n",
       "1036  dora ( fernanda montenegro ) sits behind a mak...    pos\n",
       "659   i came to an epiphany while watching the bache...    neg"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['review'], data['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968    while watching loser , it occurred to me that ...\n",
       "240    georges polti once wrote a paper called \" the ...\n",
       "819    sylvester stallone has made some crap films in...\n",
       "692    attention moviegoers : you are about to enter ...\n",
       "420    plot : something about a bunch of kids going i...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english')  # instantiate the model\n",
    "X_train_vect = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1600x35944 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 390595 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()   # define the logistic regression\n",
    "logreg.fit(X_train_vect, y_train)   # we fit it\n",
    "# outcome_pred_class_log = logreg.predict(X_test)   # we make (class) predictions based on the data that we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_vect = vect.transform(X_test)   # this is an import step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83250000000000002"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test_vect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=logreg.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[164,  35],\n",
       "       [ 32, 169]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "confusion_matrix(y_test, y_pred)   # What is the confusion matrix telling us here? Instructor explained but\n",
    "                                   # I seemed to have missed it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos'\n",
      " 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos'\n",
      " 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg'\n",
      " 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos'\n",
      " 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg'\n",
      " 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg'\n",
      " 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'neg'\n",
      " 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos'\n",
      " 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg'\n",
      " 'neg' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos'\n",
      " 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos'\n",
      " 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos'\n",
      " 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg'\n",
      " 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos'\n",
      " 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos'\n",
      " 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg'\n",
      " 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg'\n",
      " 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'pos'\n",
      " 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg'\n",
      " 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg'\n",
      " 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos'\n",
      " 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos'\n",
      " 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos'\n",
      " 'neg' 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos'\n",
      " 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos'\n",
      " 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos'\n",
      " 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos'\n",
      " 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos'\n",
      " 'neg' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg'\n",
      " 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'neg'\n",
      " 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos'\n",
      " 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos'\n",
      " 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'neg' 'neg' 'neg'\n",
      " 'pos' 'pos' 'neg' 'neg']\n",
      "1860    pos\n",
      "353     neg\n",
      "1333    pos\n",
      "905     neg\n",
      "1289    pos\n",
      "1273    pos\n",
      "938     neg\n",
      "1731    pos\n",
      "65      neg\n",
      "1323    pos\n",
      "56      neg\n",
      "1292    pos\n",
      "1118    pos\n",
      "584     neg\n",
      "374     neg\n",
      "275     neg\n",
      "746     neg\n",
      "128     neg\n",
      "1646    pos\n",
      "1852    pos\n",
      "674     neg\n",
      "1664    pos\n",
      "1981    pos\n",
      "1083    pos\n",
      "1922    pos\n",
      "99      neg\n",
      "1179    pos\n",
      "964     neg\n",
      "792     neg\n",
      "29      neg\n",
      "       ... \n",
      "1543    pos\n",
      "1803    pos\n",
      "67      neg\n",
      "1737    pos\n",
      "1592    pos\n",
      "1563    pos\n",
      "480     neg\n",
      "1756    pos\n",
      "1912    pos\n",
      "1440    pos\n",
      "1460    pos\n",
      "887     neg\n",
      "422     neg\n",
      "1674    pos\n",
      "1449    pos\n",
      "764     neg\n",
      "519     neg\n",
      "1431    pos\n",
      "613     neg\n",
      "1530    pos\n",
      "1782    pos\n",
      "1658    pos\n",
      "453     neg\n",
      "730     neg\n",
      "534     neg\n",
      "965     neg\n",
      "1284    pos\n",
      "1739    pos\n",
      "261     neg\n",
      "535     neg\n",
      "Name: target, dtype: object\n",
      "  (0, 709)\t1\n",
      "  (0, 773)\t1\n",
      "  (0, 837)\t1\n",
      "  (0, 878)\t1\n",
      "  (0, 921)\t1\n",
      "  (0, 1134)\t1\n",
      "  (0, 1348)\t1\n",
      "  (0, 1536)\t1\n",
      "  (0, 1719)\t5\n",
      "  (0, 1834)\t1\n",
      "  (0, 1840)\t1\n",
      "  (0, 1999)\t1\n",
      "  (0, 2051)\t2\n",
      "  (0, 2953)\t3\n",
      "  (0, 2988)\t8\n",
      "  (0, 3113)\t1\n",
      "  (0, 3186)\t1\n",
      "  (0, 3206)\t1\n",
      "  (0, 3383)\t1\n",
      "  (0, 3546)\t1\n",
      "  (0, 3557)\t1\n",
      "  (0, 3705)\t1\n",
      "  (0, 3953)\t1\n",
      "  (0, 4097)\t1\n",
      "  (0, 4349)\t2\n",
      "  :\t:\n",
      "  (399, 30620)\t1\n",
      "  (399, 30750)\t1\n",
      "  (399, 30864)\t2\n",
      "  (399, 30928)\t1\n",
      "  (399, 30968)\t1\n",
      "  (399, 32115)\t1\n",
      "  (399, 32267)\t1\n",
      "  (399, 32809)\t1\n",
      "  (399, 32948)\t1\n",
      "  (399, 33207)\t1\n",
      "  (399, 33452)\t1\n",
      "  (399, 33471)\t1\n",
      "  (399, 33819)\t1\n",
      "  (399, 34034)\t1\n",
      "  (399, 34040)\t1\n",
      "  (399, 34061)\t1\n",
      "  (399, 34788)\t1\n",
      "  (399, 34789)\t1\n",
      "  (399, 34792)\t1\n",
      "  (399, 34913)\t2\n",
      "  (399, 35009)\t1\n",
      "  (399, 35378)\t1\n",
      "  (399, 35430)\t1\n",
      "  (399, 35544)\t1\n",
      "  (399, 35783)\t1\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_test)\n",
    "print(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The word 'movie' adds noise because it occurs in all sentences in the review and is therefore useless.\n",
    "vect = TdidfVectorizer(stop_words='english')  # instantiate the model\n",
    "X_train_vect = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kbest = SelectKBest(k=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_best = kbest.fit_transform(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()   # define the logistic regression\n",
    "logreg.fit(X_train_best, y_train);   # we fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_vect = vect.transform(X_test)   # this is an import step\n",
    "X_test_best = kbest.transform(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81000000000000005"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test_best, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[160,  39],\n",
       "       [ 37, 164]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
